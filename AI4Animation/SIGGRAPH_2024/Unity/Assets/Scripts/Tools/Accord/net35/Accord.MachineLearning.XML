<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Accord.MachineLearning</name>
    </assembly>
    <members>
        <member name="T:Accord.MachineLearning.Boosting.Learners.ThresholdLearning">
            <summary>
              Learning algorithm for <see cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump"/>s.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Boosting.AdaBoost`1" />
            <seealso cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump" />
            
            <example>
            <para>
              The <see cref="T:Accord.MachineLearning.Boosting.Learners.ThresholdLearning"/> algorithm is mostly intended to be used to create 
              <see cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump"/> weak classifiers in the context of an <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> 
              learning algorithm. Please refer to the <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> class for more examples
              on using the classifier in this scenario. A simple example is shown below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\AdaBoostTest.cs" region="doc_learn" />
              
            <para>
              It is also possible to use the <see cref="T:Accord.MachineLearning.Boosting.Learners.ThresholdLearning"/> as a standalone learning algorithm. 
              An example is given below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\DecisionStumpTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.ThresholdLearning.Model">
            <summary>
              Gets or sets the model being trained.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.ThresholdLearning.Learn(System.Double[][],System.Int32[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.ThresholdLearning.Learn(System.Double[][],System.Boolean[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.ThresholdLearning.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.ThresholdLearning.Learn(System.Double[][],System.Boolean[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Learners.NamespaceDoc">
            <summary>
             Contains Boosting related techniques for creating classifier ensembles and other composition models.
            </summary>
            
            <remarks>
            <para>
              The namespace class diagram is shown below. </para>
              <img src="..\diagrams\classes\Accord.MachineLearning.Boosting.png" />
            </remarks>
            
            <seealso cref="N:Accord.MachineLearning.Boosting"/>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Learners.Weak`1">
            <summary>
              Adapter for models that do not implement a .Decide function.
            </summary>
            
            <typeparam name="TModel">The type for the weak classifier model.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.Weak`1.Model">
            <summary>
              Gets or sets the weak decision model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.Weak`1.Function">
            <summary>
              Gets or sets the decision function used by the <see cref="P:Accord.MachineLearning.Boosting.Learners.Weak`1.Model"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.Weak`1.#ctor(`0,System.Func{`0,System.Double[],System.Int32})">
            <summary>
              Creates a new Weak classifier given a 
              classification model and its decision function.
            </summary>
            
            <param name="model">The classifier.</param>
            <param name="function">The classifier decision function.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.Weak`1.Compute(System.Double[])">
            <summary>
              Computes the classifier decision for a given input.
            </summary>
            
            <param name="inputs">The input vector.</param>
            
            <returns>The model's decision label.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.Weak`1.Decide(System.Double[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Learners.DecisionStump">
            <summary>
              Simple classifier that based on decision margins that
              are perpendicular to one of the space dimensions.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Boosting.Learners.ThresholdLearning"/>
            <seealso cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/>
            
            <example>
            <para>
              The <see cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump"/> classifier is mostly intended to be used as a weak classifier
              in the context of an <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> learning algorithm. Please refer to the
              <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> class for more examples on using the classifier in this scenario.
              A simple example is shown below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\AdaBoostTest.cs" region="doc_learn" />
              
            <para>
              It is also possible to use the <see cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump"/> as a standalone classifier through
              the <see cref="T:Accord.MachineLearning.Boosting.Learners.ThresholdLearning"/> algorithm. An example is given below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\DecisionStumpTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.DecisionStump.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump"/> class.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.DecisionStump.Threshold">
            <summary>
              Gets the decision threshold for this linear classifier.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.DecisionStump.Index">
            <summary>
              Gets the index of the attribute which this
              classifier will use to compare against
              <see cref="P:Accord.MachineLearning.Boosting.Learners.DecisionStump.Threshold"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.DecisionStump.Comparison">
            <summary>
              Gets or sets the comparison to be performed.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.DecisionStump.Decide(System.Double[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.DecisionStump.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Learners.DecisionStump"/> class.
            </summary>
            
            <param name="inputs">The number of inputs for this classifier.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Learners.DecisionStump.Sign">
            <summary>
              Gets the direction of the comparison 
              (if greater than or less than).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.DecisionStump.Compute(System.Double[])">
            <summary>
              Computes the output class label for a given input.
            </summary>
            
            <param name="inputs">The input vector.</param>
            
            <returns>
              The most likely class label for the given input.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Learners.DecisionStump.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Teaches the stump classifier to recognize
              the class labels of the given input samples.
            </summary>
            
            <param name="inputs">The input vectors.</param>
            <param name="outputs">The class labels corresponding to each input vector.</param>
            <param name="weights">The weights associated with each input vector.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.NamespaceDoc">
            <summary>
             Contains Boosting related techniques for creating classifier ensembles and other composition models.
            </summary>
            
            <remarks>
            <para>
              The namespace class diagram is shown below. </para>
              <img src="..\diagrams\classes\Accord.MachineLearning.Boosting.png" />
            </remarks>
            
            <seealso cref="N:Accord.MachineLearning.Boosting.Learners"/>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.ModelConstructor`1">
            <summary>
              Model construction (fitting) delegate.
            </summary>
            
            <typeparam name="TModel">The type of the model to be created.</typeparam>
            <param name="weights">The current weights for the input samples.</param>
            <returns>A model trained over the weighted samples.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.AdaBoostParameters">
            <summary>
              Extra parameters that can be passed to AdaBoost's model learning function.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.AdaBoost`1">
            <summary>
              AdaBoost learning algorithm.
            </summary>
            
            <typeparam name="TModel">The type of the model to be trained.</typeparam>
            
            <remarks>
            <para>
              AdaBoost, short for "Adaptive Boosting", is a machine learning meta-algorithm
              formulated by Yoav Freund and Robert Schapire who won the Gödel Prize in 2003
              for their work. It can be used in conjunction with many other types of learning
              algorithms to improve their performance. The output of the other learning algorithms 
              ('weak learners') is combined into a weighted sum that represents the final output of
              the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners
              are tweaked in favor of those instances misclassified by previous classifiers. AdaBoost
              is sensitive to noisy data and outliers. In some problems it can be less susceptible to
              the overfitting problem than other learning algorithms. The individual learners can be 
              weak, but as long as the performance of each one is slightly better than random guessing 
              (e.g., their error rate is smaller than 0.5 for binary classification), the final model
              can be proven to converge to a strong learner.</para>
            <para>
              Every learning algorithm will tend to suit some problem types better than others, and will 
              typically have many different parameters and configurations to be adjusted before achieving
              optimal performance on a dataset, AdaBoost(with decision trees as the weak learners) is often
              referred to as the best out-of-the-box classifier. When used with decision tree learning,
              information gathered at each stage of the AdaBoost algorithm about the relative 'hardness' 
              of each training sample is fed into the tree growing algorithm such that later trees tend 
              to focus on harder-to-classify examples.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="https://en.wikipedia.org/wiki/AdaBoost">
                   Wikipedia contributors. "AdaBoost." Wikipedia, The Free Encyclopedia. Wikipedia, The 
                   Free Encyclopedia, 10 Aug. 2017. Web. 7 Sep. 2017 </a></description></item>
              </list></para>
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\AdaBoostTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\AdaBoostTest.cs" region="doc_learn_lr" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Boosting\AdaBoostTest.cs" region="doc_learn_dt" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.#ctor(Accord.MachineLearning.Boosting.Boost{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> class.
            </summary>
            
            <param name="model">The model to be learned.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.#ctor(Accord.MachineLearning.Boosting.Boost{`0},Accord.MachineLearning.Boosting.ModelConstructor{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/> class.
            </summary>
            
            <param name="model">The model to be learned.</param>
            <param name="creationFunction">The model fitting function.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Model">
            <summary>
              Gets or sets the model being trained.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations
              performed by the learning algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Iterations">
            <summary>
              Please use MaxIterations instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Tolerance">
            <summary>
              Gets or sets the relative tolerance used to 
              detect convergence of the learning algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Threshold">
            <summary>
              Gets or sets the error limit before learning stops. Default is 0.5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Creation">
            <summary>
              Gets or sets the fitting function which creates
              and trains a model given a weighted data set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Learner">
            <summary>
              Gets or sets a function that takes a set of parameters and creates
              a learning algorithm for learning each stage of the boosted classsifier.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.AdaBoost`1.Token">
            <summary>
              Gets or sets a cancellation token that can be used to 
              stop the learning algorithm while it is running.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.Learn(System.Double[][],System.Int32[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.Learn(System.Double[][],System.Boolean[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.Learn(System.Double[][],System.Boolean[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.Run(System.Double[][],System.Int32[])">
            <summary>
              Runs the learning algorithm.
            </summary>
            
            <param name="inputs">The input samples.</param>
            <param name="outputs">The corresponding output labels.</param>
            
            <returns>The classifier error.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.Run(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Runs the learning algorithm.
            </summary>
            
            <param name="inputs">The input samples.</param>
            <param name="outputs">The corresponding output labels.</param>
            <param name="sampleWeights">The weights for each of the samples.</param>
            
            <returns>The classifier error.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.AdaBoost`1.ComputeError(System.Double[][],System.Int32[])">
            <summary>
              Computes the error ratio, the number of
              misclassifications divided by the total
              number of samples in a dataset.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Weighted`1">
            <summary>
              Weighted Weak Classifier.
            </summary>
            
            <typeparam name="TModel">The type of the weak classifier.</typeparam>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Weighted`2">
            <summary>
              Weighted Weak Classifier.
            </summary>
            
            <typeparam name="TModel">The type of the weak classifier.</typeparam>
            <typeparam name="TInput">The type of the input vectors accepted by the classifier.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Weighted`2.Weight">
            <summary>
              Gets or sets the weight associated
              with the weak <see cref="P:Accord.MachineLearning.Boosting.Weighted`2.Model"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.Weighted`2.Model">
            <summary>
              Gets or sets the <see cref="T:Accord.MachineLearning.Boosting.IWeakClassifier">weak
              classifier</see> associated with the <see cref="P:Accord.MachineLearning.Boosting.Weighted`2.Weight"/>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Boost`1">
            <summary>
              Boosted classification model.
            </summary>
            
            <typeparam name="TModel">The type of the weak classifier.</typeparam>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Boost`1.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Boost`1"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Boost`1.#ctor(System.Collections.Generic.IList{System.Double},System.Collections.Generic.IList{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Boost`1"/> class.
            </summary>
            
            <param name="weights">The initial boosting weights.</param>
            <param name="models">The initial weak classifiers.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Boost`1.Compute(System.Double[])">
            <summary>
              Computes the output class label for a given input.
            </summary>
            
            <param name="input">The input vector.</param>
            
            <returns>The most likely class label for the given input.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.Boost`2">
             <summary>
               Boosted classification model.
             </summary>
             
             <typeparam name="TModel">The type of the weak classifier.</typeparam>
             <typeparam name="TInput">The type of the input vectors accepted by the classifier.</typeparam>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Boost`2.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Boost`1"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.Boost`2.#ctor(System.Collections.Generic.IList{System.Double},System.Collections.Generic.IList{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Boost`1"/> class.
            </summary>
            
            <param name="weights">The initial boosting weights.</param>
            <param name="models">The initial weak classifiers.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.BoostBase`3">
            <summary>
              Boosted classification model.
            </summary>
            
            <typeparam name="TModel">The type of the weak classifier.</typeparam>
            <typeparam name="TWeighted">The type of the weighted classifier.</typeparam>
            <typeparam name="TInput">The type of the input vectors accepted by the classifier.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.BoostBase`3.Models">
            <summary>
              Gets the list of weighted weak models
              contained in this boosted classifier.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.BoostBase`3.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Boost`1"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.BoostBase`3.#ctor(System.Collections.Generic.IList{System.Double},System.Collections.Generic.IList{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Boosting.Boost`1"/> class.
            </summary>
            
            <param name="weights">The initial boosting weights.</param>
            <param name="models">The initial weak classifiers.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.BoostBase`3.Decide(`2)">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Boosting.BoostBase`3.Add(System.Double,`0)">
            <summary>
              Adds a new weak classifier and its corresponding
              weight to the end of this boosted classifier.
            </summary>
            
            <param name="weight">The weight of the weak classifier.</param>
            <param name="model">The weak classifier</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Boosting.BoostBase`3.Item(System.Int32)">
            <summary>
              Gets or sets the <see cref="T:Accord.MachineLearning.Boosting.Weighted`1"/> at the specified index.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.BoostBase`3.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through this collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.BoostBase`3.System#Collections#IEnumerable#GetEnumerator">
            <summary>
              Returns an enumerator that iterates through this collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Boosting.IWeakClassifier">
            <summary>
              Common interface for Weak classifiers
              used in Boosting mechanisms.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Boosting.AdaBoost`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.Boosting.IWeakClassifier.Compute(System.Double[])">
            <summary>
              Computes the output class label for a given input.
            </summary>
            
            <param name="inputs">The input vector.</param>
            
            <returns>The most likely class label for the given input.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.CentroidCluster`3">
            <summary>
              Data cluster.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`3.ClusterCollection.#ctor(`0,System.Int32,Accord.Math.Distances.IDistance{`1})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.KMeansClusterCollection"/> class.
            </summary>
            
            <param name="collection">The collection that contains this instance as a field.</param>
            <param name="k">The number of clusters K.</param>
            <param name="distance">The distance metric to consider.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`3.ClusterCollection.Randomize(`1[],Accord.MachineLearning.Seeding)">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            
            <param name="points">The data to randomize the algorithm.</param>
            <param name="strategy">The seeding strategy to be used. Default is <see cref="F:Accord.MachineLearning.Seeding.KMeansPlusPlus"/>.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`3.ClusterCollection.Randomize(`1[],Accord.MachineLearning.Seeding,Accord.Compat.ParallelOptions)">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            
            <param name="points">The data to randomize the algorithm.</param>
            <param name="strategy">The seeding strategy to be used. Default is <see cref="F:Accord.MachineLearning.Seeding.KMeansPlusPlus"/>.</param>
            <param name="parallelOptions">The parallelization options for this procedure.
            Only relevant for the <see cref="F:Accord.MachineLearning.Seeding.PamBuild"/>. </param>
            
        </member>
        <member name="T:Accord.MachineLearning.CentroidCluster`4">
            <summary>
              Data cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CentroidCluster`4.Centroid">
            <summary>
              Gets the cluster's centroid.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`4.Distortion(`1[])">
            <summary>
              Computes the distortion of the cluster, measured
              as the average distance between the cluster points
              and its centroid.
            </summary>
            
            <param name="data">The input points.</param>
            
            <returns>The average distance between all points
            in the cluster and the cluster centroid.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`4.ClusterCollection.#ctor(`0,System.Int32,Accord.Math.Distances.IDistance{`1,`2})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.KMeansClusterCollection"/> class.
            </summary>
            
            <param name="collection">The collection that contains this instance as a field.</param>
            <param name="k">The number of clusters K.</param>
            <param name="distance">The distance metric to consider.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.CentroidCluster`4.ClusterCollection.Distance">
            <summary>
              Gets or sets the distance function used to measure the distance
              between a point and the cluster centroid in this clustering definition.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CentroidCluster`4.ClusterCollection.Centroids">
            <summary>
              Gets or sets the clusters' centroids.
            </summary>
            
            <value>The clusters' centroids.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`4.ClusterCollection.Distortion(`1[],System.Int32[],System.Double[])">
            <summary>
              Calculates the average square distance from the data points 
              to the nearest clusters' centroids.
            </summary>
            
            <remarks>
              The average distance from centroids can be used as a measure
              of the "goodness" of the clustering. The more the data are 
              aggregated around the centroids, the less the average distance.
            </remarks>
            
            <returns>
              The average square distance from the data points to the nearest 
              clusters' centroids.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`4.ClusterCollection.Transform(`1[],System.Int32[],System.Double[],System.Double[])">
            <summary>
              Transform data points into feature vectors containing the 
              distance between each point and each of the clusters.
            </summary>
            
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            
            <returns>A vector containing the distance between the input points and the clusters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.CentroidCluster`4.ClusterCollection.Transform(`1[],System.Double[],System.Double[][])">
            <summary>
              Transform data points into feature vectors containing the 
              distance between each point and each of the clusters.
            </summary>
            
            <param name="points">The input points.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            
            <returns>A vector containing the distance between the input points and the clusters.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.IClusterCollectionEx`2">
            <summary>
              Common interface for collections of clusters (i.e. <see cref="T:Accord.MachineLearning.KMeansClusterCollection"/>,
              <see cref="T:Accord.MachineLearning.GaussianClusterCollection"/>, <see cref="T:Accord.MachineLearning.MeanShiftClusterCollection"/>).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusterCollectionEx`2.Count">
            <summary>
              Gets the number of clusters in the collection.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusterCollectionEx`2.Clusters">
            <summary>
              Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusterCollectionEx`2.Proportions">
            <summary>
            Gets the proportion of samples in each cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusterCollectionEx`2.Item(System.Int32)">
            <summary>
              Gets the cluster at the given index.
            </summary>
            
            <param name="index">The index of the cluster. This should also be the class label of the cluster.</param>
            
            <returns>An object holding information about the selected cluster.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.ICentroidClusterCollection`3">
            <summary>
              Common interface for clusters that contains centroids, where the centroid data type might be different 
              from the data type of the data bring clustered (i.e. <see cref="T:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster"/>).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.ICentroidClusterCollection`3.Centroids">
            <summary>
              Gets or sets the clusters' centroids.
            </summary>
            
            <value>The clusters' centroids.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.ICentroidClusterCollection`3.Distance">
            <summary>
              Gets or sets the distance function used to measure the distance
              between a point and the cluster centroid in this clustering definition.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.ICentroidClusterCollection`3.Distortion(`0[],System.Int32[],System.Double[])">
            <summary>
              Calculates the average square distance from the data points 
              to the nearest clusters' centroids.
            </summary>
            
            <remarks>
              The average distance from centroids can be used as a measure
              of the "goodness" of the clustering. The more the data are 
              aggregated around the centroids, the less the average distance.
            </remarks>
            
            <returns>
              The average square distance from the data points to the nearest 
              clusters' centroids.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.ICentroidClusterCollection`3.Transform(`0[],System.Double[],System.Double[][])">
            <summary>
              Transform data points into feature vectors containing the 
              distance between each point and each of the clusters.
            </summary>
            
            <param name="points">The input points.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            
            <returns>A vector containing the distance between the input points and the clusters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.ICentroidClusterCollection`3.Transform(`0[],System.Int32[],System.Double[],System.Double[])">
            <summary>
              Transform data points into feature vectors containing the 
              distance between each point and each of the clusters.
            </summary>
            
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            
            <returns>A vector containing the distance between the input points and the clusters.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.ICentroidClusterCollection`2">
            <summary>
              Common interface for clusters that contains centroids which are of the same data type 
              as the clustered data types (i.e. <see cref="T:Accord.MachineLearning.KMeansClusterCollection.KMeansCluster"/>).
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.BalancedKMeans">
            <summary>
              Balanced K-Means algorithm. Note: The balanced clusters will be
              available in the <see cref="P:Accord.MachineLearning.BalancedKMeans.Labels"/> property of this instance!
            </summary>
            
            <remarks>
            <para>
              The Balanced k-Means algorithm attempts to find a clustering where each cluster
              has approximately the same number of data points. The Balanced k-Means implementation
              used in the framework uses the <see cref="T:Accord.Math.Optimization.Munkres"/> algorithm to solve the assignment
              problem thus enforcing balance between the clusters.</para>
              
            <para>
              Note: the <see cref="M:Accord.MachineLearning.BalancedKMeans.Learn(System.Double[][],System.Double[])"/> method of this class will
              return the centroids of balanced clusters, but please note that these centroids
              cannot be used to obtain balanced clusterings for another (or even the same) data 
              set. Instead, in order to inspect the balanced clustering that has been obtained
              after calling <see cref="M:Accord.MachineLearning.BalancedKMeans.Learn(System.Double[][],System.Double[])"/>, please take a look at the
              contents of the <see cref="P:Accord.MachineLearning.BalancedKMeans.Labels"/> property.</para>
            </remarks>
            
            <para>
              References:
              <list type="bullet">
                <item><description>
                  M. I. Malinen and P.Fränti, "Balanced K-means for Clustering", Joint Int.Workshop on Structural, Syntactic, 
                  and Statistical Pattern Recognition (S+SSPR 2014), LNCS 8621, 32-41, Joensuu, Finland, August 2014. </description></item>
                <item><description>
                  M. I. Malinen, "New alternatives for k-Means clustering." PhD thesis. Available in:
                  http://cs.uef.fi/sipu/pub/PhD_Thesis_Mikko_Malinen.pdf </description></item>
              </list></para>
            
            
            <example>
              How to perform clustering with Balanced K-Means.
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\BalancedKMeansTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.BinarySplit"/>
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="P:Accord.MachineLearning.BalancedKMeans.Labels">
            <summary>
              Gets the labels assigned for each data point in the last 
              call to <see cref="M:Accord.MachineLearning.BalancedKMeans.Learn(System.Double[][],System.Double[])"/>.
            </summary>
            
            <value>The labels.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.BalancedKMeans.#ctor(System.Int32,Accord.Math.Distances.IDistance{System.Double[]})">
            <summary>
              Initializes a new instance of the Balanced K-Means algorithm.
            </summary>
            
            <param name="k">The number of clusters to divide the input data into.</param>    
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BalancedKMeans.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the Balanced K-Means algorithm.
            </summary>
            
            <param name="k">The number of clusters to divide the input data into.</param>    
            
        </member>
        <member name="M:Accord.MachineLearning.BalancedKMeans.Learn(System.Double[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the desired outputs. Note:
              the model created by this function will not be able to produce balanced
              clusterings. To retrieve the balanced labels, check the <see cref="P:Accord.MachineLearning.BalancedKMeans.Labels"/> 
              property of this class after calling this function.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            
            <returns>A model that has learned how to produce suitable outputs
              given the input data <paramref name="x" />.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.MiniBatchKMeans">
             <summary>
               Fast k-means clustering algorithm.
             </summary>
             
             <remarks>
             <para>
               The Mini-Batch K-Means clustering algorithm is a modification of the K-Means
               algorithm. </para>
             <para>
               In each iteration, it uses only a portion of data to update the cluster centroids with the gradient step.
               The subsets of data are called mini-batches and are randomly sampled from the whole dataset in each iteration.
             </para> 
             <para>
               Mini-Batch K-Means is faster than k-means for large datasets since batching reduces computational time of the algorithm. 
             </para>
             <para>
               The algorithm is composed of the following steps:
               <list type="number">
                 <item><description>
                     Place K points into the space represented by the objects that are
                     being clustered. These points represent initial group centroids.
                 </description></item>
                 <item><description>
                     Form a batch by choosing B objects from the whole input dataset.
                     For each object in the batch, determine the group that has the closest centroid.
                     Then, update the centroid with a gradient step.
                 </description></item>
                 <item><description>
                     Repeat step 2 until the centroids converge or the maximal number of iterations has been performed.
                 </description></item>
               </list></para>
             
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   D. Sculley. Web-Scale K-Means Clustering. Available on:
                   https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf </description></item>
               </list></para>
             </remarks>
             
             <example>
                 <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\MiniBatchKMeansTest.cs" region="doc_learn" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.KMeans"/>
            
        </member>
        <member name="P:Accord.MachineLearning.MiniBatchKMeans.Labels">
            <summary>
              Gets the labels assigned for each data point in the last 
              call to <see cref="M:Accord.MachineLearning.MiniBatchKMeans.Learn(System.Double[][],System.Double[])"/>.
            </summary>
            
            <value>The labels.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.MiniBatchKMeans.#ctor(System.Int32,System.Int32,Accord.Math.Distances.IDistance{System.Double[]})">
            <summary>
              Initializes a new instance of Mini-Batch K-Means algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>
            <param name="batchSize">The size of batches.</param>       
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> Euclidean distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.MiniBatchKMeans.#ctor(System.Int32,System.Int32)">
            <summary>
              Initializes a new instance of KMeans algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>       
            <param name="batchSize">The size of batches.</param> 
            
        </member>
        <member name="P:Accord.MachineLearning.MiniBatchKMeans.InitializationBatchSize">
             <summary>
               Gets or sets the size of the batch used during initialization.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MiniBatchKMeans.NumberOfInitializations">
             <summary>
             Gets or sets the number of different initializations of the centroids.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MiniBatchKMeans.BatchSize">
             <summary>
               Gets or sets the size of batches.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MiniBatchKMeans.Learn(System.Double[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.MiniBatchKMeans.MakeBatch(System.Int32,System.Int32)">
            <summary>
            Creates a random batch.
            </summary>
            <param name="totalNumberOfPoints">The size of the model input dataset.</param>
            <param name="batchSize">The size of the batch.</param>
            <returns>An array of indices of the input objects which the created batch contains.</returns>
        </member>
        <member name="M:Accord.MachineLearning.MiniBatchKMeans.InitializeCentroids(System.Double[][],System.Double[])">
            <summary>
            Initializes the centroids.
            </summary>
            <param name="data">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
        </member>
        <member name="T:Accord.MachineLearning.KMedoidsClusterCollection`1">
            <summary>
              k-Medoids cluster collection.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.KMedoids`1"/>
            
        </member>
        <member name="T:Accord.MachineLearning.KMedoidsClusterCollection`1.KMedoidsCluster">
            <summary>
              k-Medoids' cluster.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.KMedoids`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.#ctor(System.Int32,Accord.Math.Distances.IDistance{`0[]})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.KMedoidsClusterCollection`1"/> class.
            </summary>
            
            <param name="k">The number of clusters K.</param>
            <param name="distance">The distance metric to use.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoidsClusterCollection`1.Centroids">
            <summary>
            Gets or sets the clusters' centroids.
            </summary>
            <value>The clusters' centroids.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMedoidsClusterCollection`1.Distance">
            <summary>
            Gets or sets the distance function used to measure the distance
            between a point and the cluster centroid in this clustering definition.
            </summary>
            <value>The distance.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMedoidsClusterCollection`1.Clusters">
            <summary>
            Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            <value>The clusters.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMedoidsClusterCollection`1.Proportions">
            <summary>
            Gets the proportion of samples in each cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoidsClusterCollection`1.Count">
            <summary>
            Gets the number of clusters in the collection.
            </summary>
            <value>The count.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMedoidsClusterCollection`1.Item(System.Int32)">
            <summary>
            Gets the <see cref="T:Accord.MachineLearning.KMedoidsClusterCollection`1.KMedoidsCluster"/> at the specified index.
            </summary>
            <param name="index">The index.</param>
            <returns>GaussianCluster.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.Randomize(`0[][],Accord.MachineLearning.Seeding,Accord.Compat.ParallelOptions)">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            
            <param name="points">The data to randomize the algorithm.</param>
            <param name="strategy">The seeding strategy to be used. Default is <see cref="F:Accord.MachineLearning.Seeding.PamBuild"/>.</param>
            <param name="parallelOptions">The parallelization options for this procedure.
            Only relevant for the <see cref="F:Accord.MachineLearning.Seeding.PamBuild"/>. </param>
            <returns>Array of point indices, if clusters were binded to points, null otherwise.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.Distortion(`0[][],System.Int32[],System.Double[])">
            <summary>
            Calculates the average square distance from the data points
            to the nearest clusters' centroids.
            </summary>
            <param name="data">The data.</param>
            <param name="labels">The labels.</param>
            <param name="weights">The weights.</param>
            <returns>The average square distance from the data points to the nearest
            clusters' centroids.</returns>
            <remarks>The average distance from centroids can be used as a measure
            of the "goodness" of the clustering. The more the data are
            aggregated around the centroids, the less the average distance.</remarks>
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.Transform(`0[][],System.Double[],System.Double[][])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.Transform(`0[][],System.Int32[],System.Double[],System.Double[])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMedoidsClusterCollection`1.Score(`0[],System.Int32)">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <returns>System.Double.</returns>
        </member>
        <member name="T:Accord.MachineLearning.KMedoids`1">
            <summary>
              k-Medoids clustering using PAM (Partition Around Medoids) algorithm.
            </summary>
            
            <remarks>
            <para> From Wikipedia:</para>
            <para>
            The k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift
            algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups)
            and both attempt to minimize the distance between points labeled to be in a cluster and a point designated
            as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers
            (medoids or exemplars) and works with a generalization of the Manhattan Norm to define distance between
            datapoints instead of L2. This method was proposed in 1987[1] for the work with L1 norm and other distances.
            </para>
            <para>
            The most common realisation of k-medoid clustering is the Partitioning Around Medoids (PAM) algorithm.
            PAM uses a greedy search which may not find the optimum solution, but it is faster than exhaustive search.
            </para>
            <para>
            [1] Kaufman, L. and Rousseeuw, P.J. (1987), Clustering by means of Medoids, in Statistical Data Analysis 
            Based on the L1–Norm and Related Methods, edited by Y. Dodge, North-Holland, 405–416.
            </para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.KMedoids"/>
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.MeanShift"/>
            
            <example>
              How to perform K-Medoids clustering with PAM algorithm.
              <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\KMedoidsPAMTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Clusters">
            <summary>
              Gets the clusters found by k-Medoids.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.K">
            <summary>
              Gets the number of clusters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Dimension">
            <summary>
              Gets the dimensionality of the data space.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.ComputeError">
            <summary>
              Gets or sets whether the clustering distortion error (the
              average distance between all data points and the cluster
              centroids) should be computed at the end of the algorithm.
              The result will be stored in <see cref="P:Accord.MachineLearning.KMedoids`1.Error"/>. Default is true.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Distance">
            <summary>
              Gets or sets the distance function used
              as a distance metric between data points.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations to
              be performed by the method. If set to zero, no
              iteration limit will be imposed. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Tolerance">
            <summary>
              Gets or sets the relative convergence threshold
              for stopping the algorithm. Default is 1e-5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Iterations">
            <summary>
              Gets the number of iterations performed in the
              last call to this class' Compute methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Error">
            <summary>
              Gets the cluster distortion error (the average distance 
              between data points and the cluster centroids) after the 
              last call to this class' Compute methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMedoids`1.Initialization">
            <summary>
              Gets or sets the strategy used to initialize the
              centroids of the clustering algorithm. Default is
              <see cref="F:Accord.MachineLearning.Seeding.PamBuild"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KMedoids`1.#ctor(System.Int32,Accord.Math.Distances.IDistance{`0[]})">
            <summary>
              Initializes a new instance of PartitioningAroundMedoids algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>
            <param name="distance">The distance function to use. Default is to
              use the <see cref="M:Accord.Math.Distance.Euclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KMedoids`1.Learn(`0[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
            <exception cref="T:System.ArgumentNullException">points</exception>
            <exception cref="T:System.ArgumentException">Not enough points. There should be more points than the number K of clusters.</exception>
        </member>
        <member name="M:Accord.MachineLearning.KMedoids`1.Compute(`0[][],System.Int32[],System.Int32[])">
            <summary>
              Implementation of the PAM algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.KMedoids">
            <summary>
              k-Medoids clustering using PAM (Partition Around Medoids) algorithm.
            </summary>
            
            <remarks>
            <para> From Wikipedia:</para>
            <para>
            The k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift
            algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups)
            and both attempt to minimize the distance between points labeled to be in a cluster and a point designated
            as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers
            (medoids or exemplars) and works with a generalization of the Manhattan Norm to define distance between
            datapoints instead of L2. This method was proposed in 1987[1] for the work with L1 norm and other distances.
            </para>
            <para>
            The most common realisation of k-medoid clustering is the Partitioning Around Medoids (PAM) algorithm.
            PAM uses a greedy search which may not find the optimum solution, but it is faster than exhaustive search.
            </para>
            <para>
            [1] Kaufman, L. and Rousseeuw, P.J. (1987), Clustering by means of Medoids, in Statistical Data Analysis 
            Based on the L1–Norm and Related Methods, edited by Y. Dodge, North-Holland, 405–416.
            </para>
            <para>
              This is the specialized, non-generic version of the k-Medoids algorithm
              that is set to work on <see cref="T:System.Double32"/> arrays.
            </para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.KMedoids`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.KMedoids.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of k-Medoids algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>    
            
        </member>
        <member name="T:Accord.MachineLearning.VoronoiIteration`1">
            <summary>
              k-Medoids clustering using Voronoi iteration algorithm.
            </summary>
            
            <remarks>
            <para> From Wikipedia:</para>
            <para>
            The k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift
            algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups)
            and both attempt to minimize the distance between points labeled to be in a cluster and a point designated
            as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers
            (medoids or exemplars) and works with a generalization of the Manhattan Norm to define distance between
            datapoints instead of L2. This method was proposed in 1987[1] for the work with L1 norm and other distances.
            </para>
            <para>
            Voronoi iteration algorithm (or Lloyd algorithm) is one of possible implementations of the k-medoids
            clustering. It was suggested in the [2] and [3].
            </para>
            <para>
            [1] Kaufman, L. and Rousseeuw, P.J. (1987), Clustering by means of Medoids, in Statistical Data Analysis 
            Based on the L1–Norm and Related Methods, edited by Y. Dodge, North-Holland, 405–416.
            [2] T. Hastie, R. Tibshirani, and J.Friedman.The Elements of Statistical Learning, Springer (2001), 468–469.
            [3] H.S.Park , C.H.Jun, A simple and fast algorithm for K-medoids clustering, Expert Systems with Applications,
            36, (2) (2009), 3336–3341.
            </para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.VoronoiIteration"/>
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.MeanShift"/>
            
            <example>
              How to perform K-Medoids clustering with Voronoi iteration algorithm.
              <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\KMedoidsVITest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VoronoiIteration`1.#ctor(System.Int32,Accord.Math.Distances.IDistance{`0[]})">
            <summary>
              Initializes a new instance of VoronoiIteration algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.Manhattan(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VoronoiIteration`1.ClusterInfo">
            <summary>
            Helper class - cluster infromation.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VoronoiIteration`1.ClusterInfo.MedoidIndex">
            <summary>
            Index of the medoid point for this cluster.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VoronoiIteration`1.ClusterInfo.Cost">
            <summary>
            Cost of this cluster, i.e. sum of distances of all
            cluster member points to the medoid point.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VoronoiIteration`1.ClusterInfo.PointIndices">
            <summary>
            Set of member point indices.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VoronoiIteration`1.ClusterInfo.#ctor(System.Int32)">
            <summary>
            Initializes new ClusterInfo object.
            </summary>
            <param name="medoidIndex"></param>
        </member>
        <member name="M:Accord.MachineLearning.VoronoiIteration`1.ClusterInfo.Reset">
            <summary>
            Reset object to the initial state.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VoronoiIteration`1.Compute(`0[][],System.Int32[],System.Int32[])">
            <summary>
              Implementation of the Voronoi Iteration algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VoronoiIteration">
            <summary>
              k-Medoids clustering using Voronoi iteration algorithm.
            </summary>
            
            <remarks>
            <para> From Wikipedia:</para>
            <para>
            The k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift
            algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups)
            and both attempt to minimize the distance between points labeled to be in a cluster and a point designated
            as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers
            (medoids or exemplars) and works with a generalization of the Manhattan Norm to define distance between
            datapoints instead of L2. This method was proposed in 1987[1] for the work with L1 norm and other distances.
            </para>
            <para>
            Voronoi iteration algorithm (or Lloyd algorithm) is one of possible implementations of the k-medoids
            clustering. It was suggested in the [2] and [3].
            </para>
            <para>
            [1] Kaufman, L. and Rousseeuw, P.J. (1987), Clustering by means of Medoids, in Statistical Data Analysis 
            Based on the L1–Norm and Related Methods, edited by Y. Dodge, North-Holland, 405–416.
            [2] T. Hastie, R. Tibshirani, and J.Friedman.The Elements of Statistical Learning, Springer (2001), 468–469.
            [3] H.S.Park , C.H.Jun, A simple and fast algorithm for K-medoids clustering, Expert Systems with Applications,
            36, (2) (2009), 3336–3341.
            </para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.VoronoiIteration`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VoronoiIteration.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of k-Medoids algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>    
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase">
            <summary>
              Base class for tree inducing (learning) algorithms.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.MaxHeight">
            <summary>
              Gets or sets the maximum allowed height when learning a tree. If 
              set to zero, the tree can have an arbitrary length. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.MaxVariables">
            <summary>
              Gets or sets the maximum number of variables that
              can enter the tree. A value of zero indicates there
              is no limit. Default is 0 (there is no limit on the
              number of variables).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.Attributes">
            <summary>
              Gets or sets the collection of attributes to 
              be processed by the induced decision tree.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.Join">
            <summary>
              Gets or sets how many times one single variable can be integrated into the decision process. In the original
              ID3 algorithm, a variable can join only one time per decision path (path from the root to a leaf). If set to
              zero, a single variable can participate as many times as needed. Default is 1.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.Model">
            <summary>
              Gets or sets the decision trees being learned.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.AttributeUsageCount">
            <summary>
              Gets how many times each attribute has already been used in the current path.
              In the original C4.5 and ID3 algorithms, attributes could be re-used only once,
              but in the framework implementation this behaviour can be adjusted by setting 
              the <see cref="P:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.Join"/> property.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.#ctor(Accord.MachineLearning.DecisionTrees.DecisionVariable[])">
            <param name="attributes">The attributes to be processed by the induced tree.</param>
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.Add(Accord.MachineLearning.DecisionTrees.DecisionVariable)">
            <summary>
              Adds the specified variable to the list of <see cref="T:System.Attribute"/>s.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.DecisionTreeLearningBase.SplitInformation(System.Int32,System.Collections.Generic.IList{System.Int32}[],System.Collections.Generic.List{System.Int32})">
            <summary>
              Computes the split information measure.
            </summary>
            
            <param name="samples">The total number of samples.</param>
            <param name="partitions">The partitioning.</param>
            <param name="missing">An extra partition containing only missing values.</param>
            
            <returns>The split information for the given partitions.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Learning.NamespaceDoc">
            <summary>
             Contains learning algorithms for inducing 
             <see cref="N:Accord.MachineLearning.DecisionTrees">Decision Trees</see>.
            </summary>
            
            <seealso cref="N:Accord.MachineLearning.DecisionTrees"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Prunning"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Rules"/>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning">
             <summary>
               C4.5 Learning algorithm for <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree">Decision Trees</see>.
             </summary>
             
             <remarks>
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   Quinlan, J. R. C4.5: Programs for Machine Learning. Morgan
                   Kaufmann Publishers, 1993.</description></item>
                 <item><description>
                   Quinlan, J. R. C4.5: Programs for Machine Learning. Morgan
                   Kaufmann Publishers, 1993.</description></item>
                 <item><description>
                   Quinlan, J. R. Improved use of continuous attributes in c4.5. Journal
                   of Artificial Intelligence Research, 4:77-90, 1996.</description></item>
                 <item><description>
                   Mitchell, T. M. Machine Learning. McGraw-Hill, 1997. pp. 55-58. </description></item>
                 <item><description><a href="http://en.wikipedia.org/wiki/ID3_algorithm">
                   Wikipedia, the free encyclopedia. ID3 algorithm. Available on 
                   http://en.wikipedia.org/wiki/ID3_algorithm </a></description></item>
               </list>
             </para>   
             </remarks>
            
             <example>
             <para>
               This example shows the simplest way to induce a decision tree with continuous variables.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_simplest" />
             
             <para>
               This is the same example as above, but the decision variables are specified manually.</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_iris" />
             
             <para>
               This example shows how to handle missing values in the training data.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_missing" />
             
             <para>
               The next example shows how to induce a decision tree for a more complicated example, again
               using a <see cref="T:Accord.Statistics.Filters.Codification">codebook</see> to manage how input 
               variables should be encoded. It also shows how to obtain a compiled version of the decision
               tree for deciding the class labels for new samples with maximum performance.</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_nursery" />
             <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_nursery_native" />
             
             <para>
               The next example shows how to estimate the true performance of a decision tree model using cross-validation:</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
               
             <para>
               The next example shows how to find the best parameters for a decision tree using grid-search cross-validation:</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_tree_cv" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>
             <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning"/>
             <seealso cref="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning"/>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.SplitStep">
            <summary>
              Gets or sets the step at which the samples will
              be divided when dividing continuous columns in
              binary classes. Default is 1.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.#ctor">
            <summary>
              Creates a new C4.5 learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionVariable[])">
            <summary>
              Creates a new C4.5 learning algorithm.
            </summary>
            
            <param name="attributes">The attributes to be processed by the induced tree.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionTree)">
            <summary>
              Creates a new C4.5 learning algorithm.
            </summary>
            
            <param name="tree">The decision tree to be generated.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.Learn(System.Nullable{System.Int32}[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.Learn(System.Int32[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.Run(System.Double[][],System.Int32[])">
            <summary>
              Runs the learning algorithm, creating a decision
              tree modeling the given inputs and outputs.
            </summary>
            
            <param name="inputs">The inputs.</param>
            <param name="outputs">The corresponding outputs.</param>
            
            <returns>The error of the generated tree.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.C45Learning.ComputeError(System.Double[][],System.Int32[])">
            <summary>
              Computes the prediction error for the tree
              over a given set of input and outputs.
            </summary>
            
            <param name="inputs">The input points.</param>
            <param name="outputs">The corresponding output labels.</param>
            
            <returns>The percentage error of the prediction.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning">
             <summary>
               ID3 (Iterative Dichotomizer 3) learning algorithm
               for <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree">Decision Trees</see>.
             </summary>
             
             <remarks>
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   Quinlan, J. R 1986. Induction of Decision Trees.
                   Mach. Learn. 1, 1 (Mar. 1986), 81-106.</description></item>
                 <item><description>
                   Mitchell, T. M. Machine Learning. McGraw-Hill, 1997. pp. 55-58. </description></item>
                 <item><description><a href="http://en.wikipedia.org/wiki/ID3_algorithm">
                   Wikipedia, the free encyclopedia. ID3 algorithm. Available on 
                   http://en.wikipedia.org/wiki/ID3_algorithm </a></description></item>
               </list>
             </para>   
             </remarks>
             
             <example>
             <para>
               This example shows the simplest way to induce a decision tree with discrete variables.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\ID3LearningTest.cs" region="doc_learn_simplest" />
               
            <para>
               This example shows a common textbook example, and how to induce a decision tree using a 
               <see cref="T:Accord.Statistics.Filters.Codification">codebook</see> to convert string (text) variables into discrete symbols.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\ID3LearningTest.cs" region="doc_learn_mitchell" />
             </example>
            
             <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/> 
             <see cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning"/>
             <see cref="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning"/>
             
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.Rejection">
            <summary>
              Gets or sets whether all nodes are obligated to provide 
              a true decision value. If set to false, some leaf nodes
              may contain <c>null</c>. Default is false.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.#ctor">
            <summary>
              Creates a new ID3 learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionTree)">
            <summary>
              Creates a new ID3 learning algorithm.
            </summary>
            
            <param name="tree">The decision tree to be generated.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionVariable[])">
            <summary>
              Creates a new ID3 learning algorithm.
            </summary>
            
            <param name="attributes">The attributes to be processed by the induced tree.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.Learn(System.Int32[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.Run(System.Int32[][],System.Int32[])">
            <summary>
              Runs the learning algorithm, creating a decision
              tree modeling the given inputs and outputs.
            </summary>
            
            <param name="inputs">The inputs.</param>
            <param name="outputs">The corresponding outputs.</param>
            
            <returns>The error of the generated tree.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning.ComputeError(System.Int32[][],System.Int32[])">
            <summary>
              Computes the prediction error for the tree
              over a given set of input and outputs.
            </summary>
            
            <param name="inputs">The input points.</param>
            <param name="outputs">The corresponding output labels.</param>
            
            <returns>The percentage error of the prediction.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.NamespaceDoc">
            <summary>
             Contains discrete and continuous Decision Trees, with 
             support for automatic code generation, tree pruning and
             the creation of <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet">decision rule sets</see>.
            </summary>
            
            <seealso cref="N:Accord.MachineLearning.DecisionTrees"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Pruning"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Rules"/>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.ComparisonKind">
            <summary>
              Numeric comparison category.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.None">
            <summary>
              The node does no comparison.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.Equal">
            <summary>
              The node compares for equality.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.NotEqual">
            <summary>
              The node compares for non-equality.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.GreaterThanOrEqual">
            <summary>
              The node compares for greater-than or equality.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.GreaterThan">
            <summary>
              The node compares for greater-than.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.LessThan">
            <summary>
              The node compares for less-than.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.ComparisonKind.LessThanOrEqual">
            <summary>
              The node compares for less-than or equality.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.ComparisonExtensions">
            <summary>
              Extension methods for <see cref="T:Accord.MachineLearning.DecisionTrees.ComparisonKind"/> enumeration values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.ComparisonExtensions.ToString(Accord.MachineLearning.DecisionTrees.ComparisonKind)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <param name="comparison">The comparison type.</param>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection">
            <summary>
              Collection of decision nodes. A decision branch specifies the index of
              an attribute whose current value should be compared against its children
              nodes. The type of the comparison is specified in each child node.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.AttributeIndex">
            <summary>
              Gets or sets the index of the attribute to be
              used in this stage of the decision process.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.Attribute">
            <summary>
              Gets the attribute that is being used in
              this stage of the decision process, given
              by the current <see cref="P:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.AttributeIndex"/>
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.Owner">
            <summary>
              Gets or sets the decision node that contains this collection.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.#ctor(Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection"/> class.
            </summary>
            
            <param name="owner">The <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionNode"/> to whom
              this <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection"/> belongs.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.#ctor(System.Int32,Accord.MachineLearning.DecisionTrees.DecisionNode[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection"/> class.
            </summary>
            
            <param name="attributeIndex">Index of the attribute to be processed.</param>
            
            <param name="nodes">The children nodes. Each child node should be
            responsible for a possible value of a discrete attribute, or for
            a region of a continuous-valued attribute.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.AddRange(System.Collections.Generic.IEnumerable{Accord.MachineLearning.DecisionTrees.DecisionNode})">
            <summary>
              Adds the elements of the specified collection to the end of the collection.
            </summary>
            
            <param name="children">The child nodes to be added.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            
            <returns>A <see cref="T:System.String" /> that represents this instance.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Pruning.NamespaceDoc">
            <summary>
             Contains classes to prune decision trees, removing 
             unneeded nodes in an attempt to improve generalization.
            </summary>
            
            <seealso cref="N:Accord.MachineLearning.DecisionTrees"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Rules"/>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Pruning.ReducedErrorPruning">
            <summary>
              Reduced error pruning.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Pruning.ReducedErrorPruning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionTree,System.Double[][],System.Int32[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Pruning.ReducedErrorPruning"/> class.
            </summary>
            
            <param name="tree">The tree to be pruned.</param>
            <param name="inputs">The pruning set inputs.</param>
            <param name="outputs">The pruning set outputs.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Pruning.ReducedErrorPruning.Run">
            <summary>
              Computes one pass of the pruning algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Pruning.ErrorBasedPruning">
            <summary>
              Error-based pruning.
            </summary>
            
            <remarks>
            <para>
              References:
              <list type="bullet">
                <item><description>
                  Lior Rokach, Oded Maimon. The Data Mining and Knowledge Discovery Handbook,
                  Chapter 9, Decision Trees. Springer, 2nd ed. 2010, XX, 1285 p. 40 illus. 
                  Available at: http://www.ise.bgu.ac.il/faculty/liorr/hbchap9.pdf .</description></item>
              </list>
            </para>  
            </remarks>
            
            <example>
            <code>
            // Suppose you have the following input and output data
            // and would like to learn the relationship between the
            // inputs and outputs by using a Decision Tree:
            
            double[][] inputs = ...
            int[] output = ...
            
            // To prune a decision tree, we need to split your data into
            // training and pruning groups. Let's say we have 100 samples,
            // and would like to reserve 50 samples for training, and 50
            // for pruning:
            
            // Gather the first half for the training set
            var trainingInputs = inputs.Submatrix(0, 49);
            var trainingOutput = output.Submatrix(0, 49);
            
            // Gather the second hand data for pruning
            var pruningInputs = inputs.Submatrix(50, 99);
            var pruningOutput = output.Submatrix(50, 99);
            
            
            // Create the decision tree
            DecisionTree tree = new DecisionTree( ... );
            
            // Learn our tree using the training data
            C45Learning c45 = new C45Learning(tree);
            double error = c45.Run(trainingInputs, trainingOutput);
            
                        
            // Now we can attempt to prune the tree using the pruning groups
            ErrorBasedPruning prune = new ErrorBasedPruning(tree, pruningInputs, pruningOutput);
            
            // Gain threshold
            prune.Threshold = 0.1;
            
            double lastError;
            double error = Double.PositiveInfinity;
            
            do
            {
                // Now we can start pruning the tree as 
                // long as the error doesn't increase
            
                lastError = error;
                error = prune.Run();
            
            } while (error &lt; lastError);
            </code>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Pruning.ErrorBasedPruning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionTree,System.Double[][],System.Int32[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Pruning.ErrorBasedPruning"/> class.
            </summary>
            
            <param name="tree">The tree to be pruned.</param>
            <param name="inputs">The pruning set inputs.</param>
            <param name="outputs">The pruning set outputs.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Pruning.ErrorBasedPruning.Threshold">
            <summary>
              Gets or sets the minimum allowed gain threshold
              to prune the tree. Default is 0.01.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Pruning.ErrorBasedPruning.Run">
            <summary>
              Computes one pass of the pruning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Pruning.ErrorBasedPruning.compute(Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Attempts to prune a node's subtrees.
            </summary>
            
            <returns>Whether the current node was changed or not.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning">
            <summary>
              Random Forest learning algorithm.
            </summary>
            
            <example>
            <para>
              This example shows the simplest way to induce a decision tree with continuous variables.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\RandomForestTest.cs" region="doc_iris" />
            <para>
              The next example shows how to induce a decision tree with continuous variables using a 
              <see cref="T:Accord.Statistics.Filters.Codification">codebook</see> to manage how input 
              variables should be encoded.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\RandomForestTest.cs" region="doc_nursery" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.RandomForest"/>
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning"/>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForestLearning.Trees">
            <summary>
              Gets or sets the number of trees in the random forest.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForestLearning.NumberOfTrees">
            <summary>
              Gets or sets the number of trees in the random forest.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForestLearning.Join">
            <summary>
              Gets or sets how many times the same variable can 
              enter a tree's decision path. Default is 100.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForestLearning.Attributes">
            <summary>
              Gets or sets the collection of attributes to 
              be processed by the induced decision tree.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForestLearning.SampleRatio">
            <summary>
              Gets the proportion of samples used to train each
              of the trees in the decision forest. Default is 0.632.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForestLearning.CoverageRatio">
            <summary>
              Gets or sets the proportion of variables that
              can be used at maximum by each tree in the decision
              forest. Default is 1 (always use all variables).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.#ctor">
            <summary>
              Creates a new decision forest learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.#ctor(Accord.MachineLearning.DecisionTrees.RandomForest)">
            <summary>
              Creates a new decision forest learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.#ctor(Accord.Collections.OrderedDictionary{System.String,System.String[]})">
             <summary>
               Creates a new decision forest learning algorithm.
             </summary>
             
             <param name="attributes">The attributes to be processed by the induced tree.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.#ctor(Accord.MachineLearning.DecisionTrees.DecisionVariable[])">
             <summary>
               Creates a new decision forest learning algorithm.
             </summary>
             
             <param name="attributes">The attributes to be processed by the induced tree.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.Learn(System.Int32[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForestLearning.Run(System.Double[][],System.Int32[])">
            <summary>
              Runs the learning algorithm with the given data.
            </summary>
            
            <param name="inputs">The input points.</param>
            <param name="output">The class label for each point.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.RandomForest">
            <summary>
              Random Forest.
            </summary>
            
            <remarks>
            <para>
              Represents a random forest of <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>s. For 
              sample usage and example of learning, please see the documentation
              page for <see cref="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning"/>.</para>
            </remarks>
            
            <example>
            <para>
              This example shows the simplest way to induce a decision tree with continuous variables.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\RandomForestTest.cs" region="doc_iris" />
            <para>
              The next example shows how to induce a decision tree with continuous variables using a 
              <see cref="T:Accord.Statistics.Filters.Codification">codebook</see> to manage how input 
              variables should be encoded.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\RandomForestTest.cs" region="doc_nursery" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning"/>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForest.Trees">
            <summary>
              Gets the trees in the random forest.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForest.Classes">
            <summary>
              Gets the number of classes that can be recognized
              by this random forest.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForest.ParallelOptions">
            <summary>
              Gets or sets the parallelization options for this algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.RandomForest.Token">
            <summary>
            Gets or sets a cancellation token that can be used
            to cancel the algorithm while it is running.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForest.#ctor(Accord.MachineLearning.DecisionTrees.DecisionTree[])">
            <summary>
              Creates a new random forest.
            </summary>
            
            <param name="trees">The trees to be added to the forest.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForest.#ctor(System.Int32,System.Collections.Generic.IList{Accord.MachineLearning.DecisionTrees.DecisionVariable},System.Int32)">
            <summary>
              Creates a new random forest.
            </summary>
            
            <param name="trees">The number of trees to be added to the forest.</param>
            <param name="inputs">An array specifying the attributes to be processed by the trees.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForest.#ctor(System.Int32,System.Int32)">
            <summary>
              Creates a new random forest.
            </summary>
            
            <param name="trees">The number of trees in the forest.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForest.Compute(System.Double[])">
            <summary>
              Computes the decision output for a given input vector.
            </summary>
            
            <param name="data">The input vector.</param>
            
            <returns>The forest decision for the given vector.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForest.Decide(System.Double[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.RandomForest.OnDeserializingMethod(System.Runtime.Serialization.StreamingContext)">
            <summary>
              Called when the object is being deserialized.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Prunning.NamespaceDoc">
            <summary>
             Contains sets of decision rules that can be created from
             <see cref="N:Accord.MachineLearning.DecisionTrees">Decision
             Trees</see>.
            </summary>
            
            <seealso cref="N:Accord.MachineLearning.DecisionTrees"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Prunning"/>
            <seealso cref="N:Accord.MachineLearning.DecisionTrees.Learning"/>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent">
            <summary>
              Antecedent expression for <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/>s.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Index">
            <summary>
              Gets the index of the variable used as the
              left hand side term of this expression.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Comparison">
            <summary>
              Gets the comparison being made between the variable
              value at <see cref="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Index"/> and <see cref="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Value"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Value">
            <summary>
              Gets the right hand side of this expression.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.#ctor(System.Int32,Accord.MachineLearning.DecisionTrees.ComparisonKind,System.Double)">
            <summary>
              Creates a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent"/> class.
            </summary>
            
            <param name="index">The variable index.</param>
            <param name="comparison">The comparison to be made using the value at 
              <paramref name="index"/> and <paramref name="value"/>.</param>
            <param name="value">The value to be compared against.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Match(System.Double[])">
            <summary>
              Checks if this antecedent applies to a given input.
            </summary>
            
            <param name="input">An input vector.</param>
            
            <returns>True if the input element at position <see cref="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Index"/>
               compares to <see cref="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Value"/> using <see cref="P:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Comparison"/>; false
               otherwise.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Equals(Accord.MachineLearning.DecisionTrees.Rules.Antecedent)">
            <summary>
              Determines whether the specified <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent"/>
              is equal to this instance.
            </summary>
            
            <param name="other">The <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent"/> to compare with this instance.</param>
            
            <returns>
              <c>true</c> if the specified <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent"/>
              is equal to this instance; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.Equals(System.Object)">
            <summary>
              Determines whether the specified <see cref="T:System.Object"/>
              is equal to this instance.
            </summary>
            
            <param name="obj">The <see cref="T:System.Object"/> to compare with this instance.</param>
            
            <returns>
              <c>true</c> if the specified <see cref="T:System.Object"/>
              is equal to this instance; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.GetHashCode">
            <summary>
               Returns a hash code for this instance.
            </summary>
            
            <returns>
               A hash code for this instance, suitable for use in
               hashing algorithms and data structures like a hash table. 
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.ToString">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.op_Equality(Accord.MachineLearning.DecisionTrees.Rules.Antecedent,Accord.MachineLearning.DecisionTrees.Rules.Antecedent)">
            <summary>
              Implements the operator ==.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Antecedent.op_Inequality(Accord.MachineLearning.DecisionTrees.Rules.Antecedent,Accord.MachineLearning.DecisionTrees.Rules.Antecedent)">
            <summary>
              Implements the operator !=.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet">
            <summary>
              Decision rule set.
            </summary>
            
            <remarks>
            <para>
              Decision rule sets can be created from <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>s using their
              <see cref="M:Accord.MachineLearning.DecisionTrees.DecisionTree.ToRules"/> method. An example is shown below.</para>
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_iris" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_missing" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning"/>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.OutputClasses">
            <summary>
              Obsolete. Please use <see cref="P:Accord.MachineLearning.ClassifierBase`2.NumberOfClasses"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.#ctor(System.Collections.Generic.IEnumerable{Accord.MachineLearning.DecisionTrees.Rules.DecisionRule})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet"/> class.
            </summary>
            
            <param name="rules">A set of decision rules.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.FromDecisionTree(Accord.MachineLearning.DecisionTrees.DecisionTree)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet"/> from a <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>.
            </summary>
            
            <param name="tree">A <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>.</param>
            
            <returns>A <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet"/> that is completely 
            equivalent to the given <paramref name="tree"/></returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.Compute(System.Double[])">
            <summary>
              Computes the decision output for a given input.
            </summary>
            
            <param name="input">An input vector.</param>
            
            <returns>The decision output for the given 
              <paramref name="input"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.Add(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Adds a new <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> to the set.
            </summary>
            
            <param name="item">The <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> to be added.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.AddRange(System.Collections.Generic.IEnumerable{Accord.MachineLearning.DecisionTrees.Rules.DecisionRule})">
            <summary>
              Adds a collection of new <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/>s to the set.
            </summary>
            
            <param name="items">The collection of <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/>s to be added.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.Clear">
            <summary>
              Removes all rules from this set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.Count">
            <summary>
              Gets the number of rules in this set.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.Remove(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Removes a given rule from the set.
            </summary>
            
            <param name="item">The <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> to be removed.</param>
            
            <returns>True if the rule was removed; false otherwise.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.ToString">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.ToString(Accord.Statistics.Filters.Codification{System.String},System.Globalization.CultureInfo)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.ToString(Accord.Statistics.Filters.Codification{System.String})">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.ToString(Accord.Statistics.Filters.Codification{System.String},System.String,System.Globalization.CultureInfo)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.GetEnumerator">
            <summary>
               Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>
               An <see cref="T:System.Collections.IEnumerator"/> object 
               that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.System#Collections#IEnumerable#GetEnumerator">
            <summary>
               Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>
               An <see cref="T:System.Collections.IEnumerator"/> object 
               that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet.Decide(System.Double[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule">
            <summary>
              Decision Rule.
            </summary>
            
            <example>
            <para>
              The simplest way to create a set of decision rules is by extracting them from an existing <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>.
              The example below shows how to create a simple decision tree and convert it to a <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet">set of rules</see>
              using its <see cref="M:Accord.MachineLearning.DecisionTrees.DecisionTree.ToRules"/> method.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_simplest" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet"/>
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning"/>
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning"/>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Variables">
            <summary>
              Gets the decision variables handled by this rule.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Antecedents">
            <summary>
              Gets the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent"/> expressions that
              must be fulfilled in order for this rule to be applicable.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Output">
            <summary>
              Gets or sets the output of this decision rule, given 
              when all <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Antecedent"/> conditions are met.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.#ctor(System.Collections.Generic.IList{Accord.MachineLearning.DecisionTrees.DecisionVariable},System.Double,Accord.MachineLearning.DecisionTrees.Rules.Antecedent[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> class.
            </summary>
            
            <param name="variables">The decision variables handled by this decision rule.</param>
            <param name="output">The output value, given after all antecedents are met.</param>
            <param name="antecedents">The antecedent conditions that lead to the <paramref name="output"/>.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.#ctor(System.Collections.Generic.IList{Accord.MachineLearning.DecisionTrees.DecisionVariable},System.Double,System.Collections.Generic.IEnumerable{Accord.MachineLearning.DecisionTrees.Rules.Antecedent})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> class.
            </summary>
            
            <param name="variables">The decision variables handled by this decision rule.</param>
            <param name="output">The output value, given after all antecedents are met.</param>
            <param name="antecedents">The antecedent conditions that lead to the <paramref name="output"/>.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.#ctor(System.Double,Accord.MachineLearning.DecisionTrees.Rules.Antecedent[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> class.
            </summary>
            
            <param name="output">The output value, given after all antecedents are met.</param>
            <param name="antecedents">The antecedent conditions that lead to the <paramref name="output"/>.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Count">
            <summary>
              Gets the number of antecedents contained 
              in this <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Match(System.Double[])">
            <summary>
              Checks whether a the rule applies to a given input vector.
            </summary>
            
            <param name="input">An input vector.</param>
            
            <returns>True, if the input matches the rule 
              <see cref="P:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Antecedents"/>; otherwise, false.
            </returns>
              
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.FromNode(Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> from a <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>'s
              <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionNode"/>. This node must be a leaf, cannot be the root, and
              should have one output value.
            </summary>
            
            <param name="node">A <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionNode"/> from a <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>.</param>
            
            <returns>A <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> representing the given <paramref name="node"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.IsInconsistentWith(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Gets whether this rule and another rule have
              the same antecedents but different outputs.
            </summary>
            
            <param name="rule"></param>
            
            <returns>True if the two rules are contradictory; 
              false otherwise.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.ToString">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.ToString(Accord.Statistics.Filters.Codification{System.String})">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.ToString(System.Globalization.CultureInfo)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.ToString(Accord.Statistics.Filters.Codification{System.String},System.Globalization.CultureInfo)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.ToString(Accord.Statistics.Filters.Codification{System.String},System.String,System.Globalization.CultureInfo)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Clone">
            <summary>
              Creates a new object that is a copy of the current instance.
            </summary>
            
            <returns>
              A new object that is a copy of this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that 
              can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.System#Collections#IEnumerable#GetEnumerator">
            <summary>
              Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that 
              can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.GetHashCode">
            <summary>
              Returns a hash code for this instance.
            </summary>
            
            <returns>
              A hash code for this instance, suitable for use in hashing
              algorithms and data structures like a hash table. 
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Equals(System.Object)">
            <summary>
              Determines whether the specified <see cref="T:System.Object"/> is equal to this instance.
            </summary>
            
            <param name="obj">The <see cref="T:System.Object"/> to compare with this instance.</param>
            
            <returns>
              <c>true</c> if the specified <see cref="T:System.Object"/>
              is equal to this instance; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.Equals(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Determines whether the specified <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> is equal to this instance.
            </summary>
            
            <param name="other">The <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/> to compare with this instance.</param>
            
            <returns>
              <c>true</c> if the specified <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/>
              is equal to this instance; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.CompareTo(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Compares this instance to another <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.op_LessThan(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule,Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Implements the operator &lt;.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.op_GreaterThan(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule,Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Implements the operator &gt;.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.op_Equality(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule,Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Implements the operator ==.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.DecisionRule.op_Inequality(Accord.MachineLearning.DecisionTrees.Rules.DecisionRule,Accord.MachineLearning.DecisionTrees.Rules.DecisionRule)">
            <summary>
              Implements the operator !=.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.Rules.Simplification">
            <summary>
              Decision rule simplification algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.Rules.Simplification.Alpha">
            <summary>
              Gets or sets the underlying hypothesis test
              size parameter used to reject hypothesis.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Simplification.#ctor(Accord.MachineLearning.DecisionTrees.Rules.DecisionSet)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.Simplification"/> class.
            </summary>
            
            <param name="list">The decision set to be simplified.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Simplification.Compute(System.Double[][],System.Int32[])">
            <summary>
              Computes the reduction algorithm.
            </summary>
            
            <param name="inputs">A set of training inputs.</param>
            <param name="outputs">The outputs corresponding to each of the inputs.</param>
            
            <returns>The average error after the reduction.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Simplification.ComputeError(System.Double[][],System.Int32[])">
            <summary>
              Computes the average decision error.
            </summary>
            
            <param name="inputs">A set of input vectors.</param>
            <param name="outputs">A set of corresponding output vectors.</param>
            
            <returns>The average misclassification rate.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Simplification.CanEliminate(System.Boolean[],System.Boolean[])">
            <summary>
              Checks if two variables can be eliminated.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.Rules.Simplification.CanEliminate(System.Boolean[],System.Boolean[],System.Double)">
            <summary>
              Checks if two variables can be eliminated.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionTreeWriter">
            <summary>
              Decision Tree C# Writer.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTreeWriter.#ctor(System.IO.TextWriter)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTreeWriter"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTreeWriter.Write(Accord.MachineLearning.DecisionTrees.DecisionTree,System.String)">
            <summary>
              Creates a C# code for the tree.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionVariableKind">
            <summary>
              Attribute category.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.DecisionVariableKind.Discrete">
            <summary>
              Attribute is discrete-valued.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.DecisionTrees.DecisionVariableKind.Continuous">
            <summary>
              Attribute is continuous-valued.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionVariable">
            <summary>
              Decision attribute.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionVariable.Name">
            <summary>
              Gets the name of the attribute.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionVariable.Nature">
            <summary>
              Gets the nature of the attribute (i.e. real-valued or discrete-valued).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionVariable.Range">
            <summary>
              Gets the valid range of the attribute.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.#ctor(System.String,Accord.DoubleRange)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="range">The range of valid values for this attribute. Default is [0;1].</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.#ctor(System.String,Accord.MachineLearning.DecisionTrees.DecisionVariableKind)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="nature">The attribute's nature (i.e. real-valued or discrete-valued).</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.#ctor(System.String,Accord.IntRange)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="range">The range of valid values for this attribute.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.#ctor(System.String,System.Int32)">
            <summary>
              Creates a new discrete-valued <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="symbols">The number of possible values for this attribute.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.Continuous(System.String)">
            <summary>
              Creates a new continuous <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.Continuous(System.String,Accord.DoubleRange)">
            <summary>
              Creates a new continuous <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="range">The range of valid values for this attribute. Default is [0;1].</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.Discrete(System.String,Accord.IntRange)">
            <summary>
              Creates a new discrete <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="range">The range of valid values for this attribute.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.Discrete(System.String,System.Int32)">
            <summary>
              Creates a new discrete-valued <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/>.
            </summary>
            
            <param name="name">The name of the attribute.</param>
            <param name="symbols">The number of possible values for this attribute.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>A <see cref="T:System.String" /> that represents this instance.</returns>
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.FromDictionary(Accord.Collections.OrderedDictionary{System.String,System.String[]})">
            <summary>
              Creates a set of decision variables from a <see cref="T:Accord.Collections.OrderedDictionary`2"/> codebook.
            </summary>
            
            <param name="columns">The ordered dictionary containing information about the variables.</param>
            
            <returns>An array of <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/> objects 
              initialized with the values from the codebook.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.FromCodebook(Accord.Statistics.Filters.Codification{System.String},System.String[])">
            <summary>
              Creates a set of decision variables from a <see cref="T:Accord.Statistics.Filters.Codification"/> codebook.
            </summary>
            
            <param name="codebook">The codebook containing information about the variables.</param>
            <param name="columns">The columns to consider as decision variables.</param>
            
            <returns>An array of <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/> objects 
            initialized with the values from the codebook.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.FromData(System.Double[][])">
            <summary>
              Creates a set of decision variables from input data.
            </summary>
            
            <param name="inputs">The input data.</param>
            
            <returns>An array of <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/> objects 
            initialized with the values from the codebook.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.FromData(System.Int32[][])">
            <summary>
              Creates a set of decision variables from input data.
            </summary>
            
            <param name="inputs">The input data.</param>
            
            <returns>An array of <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/> objects 
            initialized with the values from the codebook.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariable.FromData(System.Nullable{System.Int32}[][])">
            <summary>
              Creates a set of decision variables from input data.
            </summary>
            
            <param name="inputs">The input data.</param>
            
            <returns>An array of <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariable"/> objects 
            initialized with the values from the codebook.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionVariableCollection">
            <summary>
              Collection of decision attributes.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionVariableCollection.#ctor(System.Collections.Generic.IList{Accord.MachineLearning.DecisionTrees.DecisionVariable})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionVariableCollection"/> class.
            </summary>
            
            <param name="list">The list to initialize the collection.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionTree">
             <summary>
               Decision tree (for both discrete and continuous classification problems).
             </summary>
             
             <remarks>
             <para>
               Represents a decision tree which can be compiled to code at run-time. For sample usage 
               and example of learning, please see the documentation pages for the <see cref="T:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning">
               ID3</see> and <see cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning">C4.5 learning algorithms</see>.</para>
               
             <para>
               It is also possible to create <see cref="T:Accord.MachineLearning.DecisionTrees.RandomForest">random forests</see> using
               the <see cref="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning">random forest learning algorithm</see>.</para>
             </remarks>
            
             <example>
             <para>
               This example shows the simplest way to induce a decision tree with discrete variables.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\ID3LearningTest.cs" region="doc_learn_simplest" />
               
            <para>
               This example shows a common textbook example, and how to induce a decision tree using a 
               <see cref="T:Accord.Statistics.Filters.Codification">codebook</see> to convert string (text) variables into discrete symbols.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\ID3LearningTest.cs" region="doc_learn_mitchell" />
               <para>For more examples with discrete variables, please see <see cref="T:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning"/></para>
             
             <para>
               This example shows the simplest way to induce a decision tree with continuous variables.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\C45LearningTest.cs" region="doc_simplest" />
               <para>For more examples with continuous variables, please see <see cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning"/></para>
               
             <para>
               The next example shows how to estimate the true performance of a decision tree model using cross-validation:</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.ID3Learning"/>
             <seealso cref="T:Accord.MachineLearning.DecisionTrees.Learning.C45Learning"/>
             <seealso cref="T:Accord.MachineLearning.DecisionTrees.RandomForestLearning"/>
             
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionTree.Root">
            <summary>
              Gets or sets the root node for this tree.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionTree.Attributes">
            <summary>
              Gets the collection of attributes processed by this tree.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.#ctor(System.Collections.Generic.IList{Accord.MachineLearning.DecisionTrees.DecisionVariable},System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/> to process
              the given <paramref name="inputs"/> and the given
              number of possible <paramref name="classes"/>.
            </summary>
            
            <param name="inputs">An array specifying the attributes to be processed by this tree.</param>
            <param name="classes">The number of possible output classes for the given attributes.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Double[])">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Int32[])">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Nullable{System.Int32}[])">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Nullable{System.Int32}[][])">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Nullable{System.Int32}[][],System.Int32[])">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            <param name="result">The location to where to store the class labels.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Double[],Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            <param name="subtree">The node where the decision starts.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Decide(System.Nullable{System.Int32}[],Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Computes the tree decision for a given input.
            </summary>
            
            <param name="input">The input data.</param>
            <param name="subtree">The node where the decision starts.</param>
            
            <returns>A predicted class for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through the tree.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that can be 
              used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Traverse(Accord.MachineLearning.DecisionTrees.DecisionTreeTraversalMethod)">
            <summary>
              Traverse the tree using a <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversal">tree 
              traversal method</see>. Can be iterated with a foreach loop.
            </summary>
            
            <param name="method">The tree traversal method. Common methods are
            available in the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree.TreeTraversal"/>static class.</param>
            
            <returns>An <see cref="T:System.Collections.Generic.IEnumerable`1"/> object which can be used to
            traverse the tree using the chosen traversal method.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Traverse(Accord.MachineLearning.DecisionTrees.DecisionTreeTraversalMethod,Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Traverse a subtree using a <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversal">tree 
              traversal method</see>. Can be iterated with a foreach loop.
            </summary>
            
            <param name="method">The tree traversal method. Common methods are
            available in the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree.TreeTraversal"/>static class.</param>
            <param name="subtree">The root of the subtree to be traversed.</param>
            
            <returns>An <see cref="T:System.Collections.Generic.IEnumerable`1"/> object which can be used to
            traverse the tree using the chosen traversal method.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.ToRules">
            <summary>
              Transforms the tree into a set of <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet">decision rules</see>.
            </summary>
            
            <returns>A <see cref="T:Accord.MachineLearning.DecisionTrees.Rules.DecisionSet"/> created from this tree.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.ToCode(System.String)">
            <summary>
              Generates a C# class implementing the decision tree.
            </summary>
            
            <param name="className">The name for the generated class.</param>
            
            <returns>A string containing the generated class.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.ToCode(System.IO.TextWriter,System.String)">
            <summary>
              Generates a C# class implementing the decision tree.
            </summary>
            
            <param name="className">The name for the generated class.</param>
            <param name="writer">The <see cref="T:System.IO.TextWriter"/> where the class should be written.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.GetHeight">
            <summary>
              Computes the height of the tree, defined as the
              greatest distance (in links) between the tree's
              root node and its leaves.
            </summary>
            
            <returns>The tree's height.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Save(System.String)">
            <summary>
              Obsolete. Please use <see cref="M:Accord.IO.Serializer.Save``1(``0,System.String)"/> (or use it as an extension method).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Save(System.IO.Stream)">
            <summary>
              Obsolete. Please use <see cref="M:Accord.IO.Serializer.Save``1(``0,System.IO.Stream,Accord.IO.SerializerCompression)"/> (or use it as an extension method).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Load(System.IO.Stream)">
            <summary>
              Obsolete. Please use <see cref="M:Accord.IO.Serializer.Load``1(System.IO.Stream,Accord.IO.SerializerCompression)"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Load(System.String)">
            <summary>
              Obsolete. Please use <see cref="M:Accord.IO.Serializer.Load``1(System.String)"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionTree.OutputClasses">
            <summary>
              Deprecated. Please use the NumberOfOutputs property instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionTree.InputCount">
            <summary>
              Deprecated. Please use the NumberOfInputs property.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Compute(System.Int32[])">
            <summary>
              Deprecated. Please use the Decide() method instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Compute(System.Double[])">
            <summary>
              Deprecated. Please use the Decide() method instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Compute(System.Int32[][])">
            <summary>
              Deprecated. Please use the Decide() method instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTree.Compute(System.Double[],Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Deprecated. Please use the Decide() method instead.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionNode">
            <summary>
              Decision Tree (DT) Node.
            </summary>
            
            <remarks>
              Each node of a decision tree can play two roles. When a node is not a leaf, it
              contains a <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionBranchNodeCollection"/> with a collection of child nodes. The
              branch specifies an attribute index, indicating which column from the data set
              (the attribute) should be compared against its children values. The type of the
              comparison is specified by each of the children. When a node is a leaf, it will
              contain the output value which should be decided for when the node is reached.
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Value">
            <summary>
              Gets or sets the value this node responds to
              whenever this node acts as a child node. This
              value is set only when the node has a parent.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Comparison">
            <summary>
              Gets or sets the type of the comparison which
              should be done against <see cref="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Value"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Output">
            <summary>
              If this is a leaf node, gets or sets the output
              value to be decided when this node is reached.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Branches">
            <summary>
              If this is not a leaf node, gets or sets the collection
              of child nodes for this node, together with the attribute
              determining the reasoning process for those children.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Parent">
            <summary>
              Gets or sets the parent of this node. If this is a root
              node, the parent is <c>null</c>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.Owner">
            <summary>
              Gets the <see cref="T:Accord.MachineLearning.DecisionTrees.DecisionTree"/> containing this node.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.#ctor(Accord.MachineLearning.DecisionTrees.DecisionTree)">
            <summary>
              Creates a new decision node.
            </summary>
            
            <param name="owner">The owner tree for this node.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.IsRoot">
            <summary>
              Gets a value indicating whether this instance is a root node (has no parent).
            </summary>
            
            <value><c>true</c> if this instance is a root; otherwise, <c>false</c>.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.DecisionTrees.DecisionNode.IsLeaf">
            <summary>
              Gets a value indicating whether this instance is a leaf (has no children).
            </summary>
            
            <value><c>true</c> if this instance is a leaf; otherwise, <c>false</c>.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.Compute(System.Double)">
            <summary>
              Computes whether a value satisfies
              the condition imposed by this node.
            </summary>
            
            <param name="x">The value x.</param>
            
            <returns><c>true</c> if the value satisfies this node's
            condition; otherwise, <c>false</c>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.Compute(System.Int32)">
            <summary>
              Computes whether a value satisfies
              the condition imposed by this node.
            </summary>
            
            <param name="x">The value x.</param>
            
            <returns><c>true</c> if the value satisfies this node's
            condition; otherwise, <c>false</c>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.ToString">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.ToString(Accord.Statistics.Filters.Codification)">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.GetHeight">
            <summary>
              Computes the height of the node, defined as the
              distance (in number of links) between the tree's
              root node and this node.
            </summary>
            
            <returns>The node's height.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through the node's subtree.
            </summary>
            
            <returns>
              A <see cref="T:System.Collections.Generic.IEnumerator`1" /> that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionNode.System#Collections#IEnumerable#GetEnumerator">
            <summary>
              Returns an enumerator that iterates through the node's subtree.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversalMethod">
            <summary>
              Tree enumeration method delegate.
            </summary>
            
            <returns>An enumerator traversing the tree.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversal">
            <summary>
              Common traversal methods for n-ary trees.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversal.BreadthFirst(Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Breadth-first traversal method.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversal.DepthFirst(Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Depth-first traversal method.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.DecisionTrees.DecisionTreeTraversal.PostOrder(Accord.MachineLearning.DecisionTrees.DecisionNode)">
            <summary>
              Post-order tree traversal method.
            </summary>
            
            <remarks>
              Adapted from John Cowan (1998) recommendation.
            </remarks>
            
        </member>
        <member name="T:Accord.MachineLearning.BaseKNearestNeighbors`3">
            <summary>
              Base class for <see cref="T:Accord.MachineLearning.KNearestNeighbors`1">K-Nearest Neighbor (k-NN) algorithms</see>.
            </summary>
            
            <typeparam name="TModel">The type of the model being learned.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TDistance">The type for distance functions that can be used with this algorithm.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.KNearestNeighbors"/>
            <seealso cref="T:Accord.MachineLearning.KNearestNeighbors`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseKNearestNeighbors`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.BaseKNearestNeighbors`3"/> class.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseKNearestNeighbors`3.Distance">
            <summary>
              Gets or sets the distance function used
              as a distance metric between data points.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K">
            <summary>
              Gets or sets the number of nearest neighbors to be used 
              in the decision. Default is 5.
            </summary>
            
            <value>The number of neighbors.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseKNearestNeighbors`3.Token">
            <summary>
              Gets or sets a cancellation token that can be used to 
              stop the learning algorithm while it is running.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseKNearestNeighbors`3.Inputs">
            <summary>
              Gets the set of points given
              as input of the algorithm.
            </summary>
            
            <value>The input points.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseKNearestNeighbors`3.Outputs">
            <summary>
              Gets the set of labels associated
              with each <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.Inputs"/> point.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseKNearestNeighbors`3.Score(`1,System.Int32)">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <returns>System.Double.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseKNearestNeighbors`3.GetNearestNeighbors(`1,System.Int32[]@)">
            <summary>
              Gets the top <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K"/> points that are the closest
              to a given <paramref name="input"> reference point</paramref>.
            </summary>
            
            <param name="input">The query point whose neighbors will be found.</param>
            <param name="labels">The label for each neighboring point.</param>
            
            <returns>
              An array containing the top <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K"/> points that are 
              at the closest possible distance to <paramref name="input"/>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseKNearestNeighbors`3.Learn(`1[],System.Int32[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseKNearestNeighbors`3.Learn(`1[],System.Boolean[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseKNearestNeighbors`3.Learn(`1[],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.ShuffleMethod">
            <summary>
              Mini-batch data shuffling options.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.ShuffleMethod.None">
            <summary>
              Do not perform any shuffling.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.ShuffleMethod.OnlyOnce">
            <summary>
              Shuffle the data only once, before any batches are created.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.ShuffleMethod.EveryEpoch">
            <summary>
              Re-shuffles the data after every epoch.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.MiniBatches">
            <summary>
              Utility class for preparing mini-batches of data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MiniBatches.Create``2(``0[],``1[],System.Double[],System.Int32,System.Int32,System.Int32,Accord.MachineLearning.ShuffleMethod)">
            <summary>
              Creates a method to partition a given dataset into mini-batches of equal size.
            </summary>
            
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output output.</typeparam>
            
            <param name="input">The input data to be partitioned into mini-batches.</param>
            <param name="output">The output data to be partitioned into mini-batches.</param>
            <param name="weights">The weights for the data to be partitioned into mini-batches.</param>
            <param name="batchSize">The size of the batch.</param>
            <param name="maxIterations">The maximum number of mini-batches that should be created until the method stops.</param>
            <param name="maxEpochs">The maximum number of epochs that should be run until the method stops.</param>
            <param name="shuffle">The data shuffling options.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.MiniBatches`1">
            <summary>
              Utility class for preparing mini-batches of data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MiniBatches`1.#ctor(`0[],System.Double[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.MiniBatches`1"/> class.
            </summary>
            
            <param name="inputs">The input data that should be divided into batches.</param>
            <param name="weights">The weight for the data that should be divided into batches.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.MiniBatches`1.Init">
            <summary>
            Inheritors should use this method to create a new instance of a mini-batch object.
            You can use this method to create mini-batches containing different objects related
            to the mini-batch, such as auxiliary data, privileged information, etc).
            </summary>
            <returns>DataSubset&lt;TInput&gt;.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Batches`2">
            <summary>
              Utility class for preparing mini-batches of data.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Batches`2.Outputs">
            <summary>
              Gets or sets the output associated with each input instances 
              that should be divided among the mini-batches at every epoch.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Batches`2.#ctor(`0[],`1[],System.Double[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Batches`2"/> class.
            </summary>
            
            <param name="inputs">The input data that should be divided into batches.</param>
            <param name="outputs">The output for the data that should be divided into batches.</param>
            <param name="weights">The weight for the data that should be divided into batches.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Batches`2.Init">
            <summary>
            Inheritors should use this method to create a new instance of a mini-batch object.
            You can use this method to create mini-batches containing different objects related
            to the mini-batch, such as auxiliary data, privileged information, etc).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Batches`2.PutCurrentSampleInMiniBatch(Accord.MachineLearning.Performance.DataSubset{`0,`1},System.Int32)">
            <summary>
            Inheritors should use this method to put the current sample in the
            given mini-batch at the given position.
            </summary>
            <param name="batch">The mini-batch being constructed.</param>
            <param name="positionInMiniBatch">The position in mini-batch where the current sample must be put.</param>
        </member>
        <member name="M:Accord.MachineLearning.Batches`2.PrepareBatch(System.Int32[])">
            <summary>
            Inheritors should use this method to prepare the data for the next batches,
            for example by reshuffling according to the ordering passed as argument.
            </summary>
            <param name="idx">The ordering for the samples in the new batches.</param>
        </member>
        <member name="T:Accord.MachineLearning.BaseBatches`2">
            <summary>
              Utility class for preparing mini-batches of data.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.Inputs">
            <summary>
              Gets or sets the input instances that should be divided among the mini-batches at every epoch.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.Weights">
            <summary>
              Gets or sets the weights associated with each data instance
              that should be divided among the mini-batches at every epoch.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.MiniBatchSize">
            <summary>
              Gets or sets the size of the mini-batch that will be generated.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.Shuffle">
            <summary>
              Gets or sets options about how and when data should be shuffled.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.NumberOfSamples">
            <summary>
              Gets the number of samples in each epoch.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.NumberOfMiniBatches">
            <summary>
              Gets or sets the number of mini-batches that are going to be generated for each epoch.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations for which mini-batches should be generated.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.MaxEpochs">
            <summary>
              Gets or sets the maximum number of epochs for which mini-batches should be generated.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.CurrentIteration">
            <summary>
            Gets or sets the current iteration counter.
            </summary>
            
            <value>The index of the current iteration.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.CurrentEpoch">
            <summary>
            Gets or sets the current epoch counter.
            </summary>
            
            <value>The index of the current epoch.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.CurrentSample">
            <summary>
            Gets or sets the current sample counter.
            </summary>
            
            <value>The index of the current sample.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBatches`2.CurrentMiniBatch">
            <summary>
              Gets or sets the current mini-batch counter.
            </summary>
            
            <value>The index of the current mini-batch.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBatches`2.#ctor(`1[],System.Double[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.BaseBatches`2"/> class.
            </summary>
            
            <param name="inputs">The input data that should be divided into batches.</param>
            <param name="weights">The weight for the data that should be divided into batches.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBatches`2.Init">
            <summary>
              Inheritors should use this method to create a new instance of a mini-batch object. 
              You can use this method to create mini-batches containing different objects related 
              to the mini-batch, such as auxiliary data, privileged information, etc).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBatches`2.PutCurrentSampleInMiniBatch(`0,System.Int32)">
            <summary>
              Inheritors should use this method to put the current sample in the
              given mini-batch at the given position.
            </summary>
            
            <param name="batch">The mini-batch being constructed.</param>
            <param name="positionInMiniBatch">The position in mini-batch where the current sample must be put.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBatches`2.PrepareBatch(System.Int32[])">
            <summary>
              Inheritors should use this method to prepare the data for the next batches, 
              for example by reshuffling according to the ordering passed as argument.
            </summary>
            
            <param name="idx">The ordering for the samples in the new batches.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBatches`2.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBatches`2.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.CrossValidation`4">
            <summary>
              k-Fold cross-validation.
            </summary>
            
            <remarks>
            <para>
              Cross-validation is a technique for estimating the performance of a predictive
              model. It can be used to measure how the results of a statistical analysis will
              generalize to an independent data set. It is mainly used in settings where the
              goal is prediction, and one wants to estimate how accurately a predictive model
              will perform in practice.</para>
            <para>
              One round of cross-validation involves partitioning a sample of data into
              complementary subsets, performing the analysis on one subset (called the
              training set), and validating the analysis on the other subset (called the
              validation set or testing set). To reduce variability, multiple rounds of 
              cross-validation are performed using different partitions, and the validation 
              results are averaged over the rounds.</para> 
              
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">
                  Wikipedia, The Free Encyclopedia. Cross-validation (statistics). Available on:
                  http://en.wikipedia.org/wiki/Cross-validation_(statistics) </a></description></item>
              </list></para> 
            </remarks>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidation`4.Folds">
            <summary>
              Gets the array of data set indexes contained in each fold.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidation`4.Indices">
            <summary>
             Gets the array of fold indices for each point in the data set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidation`4.K">
            <summary>
              Gets the number of folds in the k-fold cross validation.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`4.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.CrossValidation" /> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`4.Learn(`2[],`3[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.</returns>
            <exception cref="T:System.InvalidOperationException">
            Please set the Learner property before calling the Learn(x, y) method.
            or
            Please set the Learner property before calling the Learn(x, y) method.
            or
            The number of folds can not exceed the total number of samples in the data set.
            </exception>
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`4.CreateValidationSplits(`2[],`3[],System.Int32)">
            <summary>
              Creates a list of the sample indices that should serve as the validation set.
            </summary>
            
            <param name="x">The input data from where subsamples should be drawn.</param>
            <param name="y">The output data from where subsamples should be drawn.</param>
            <param name="numberOfFolds">The number of folds to be created.</param>
            
            <returns>The indices of the samples in the original set that should compose the validation set.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`4.GetFold(System.Int32,`2[],`3[],System.Double[])">
            <summary>
              Gets a subset of the training and testing sets.
            </summary>
            
            <param name="validationFoldIndex">Index of the subsample.</param>
            <param name="x">The input data x.</param>
            <param name="y">The output data y.</param>
            <param name="weights">The weights of each sample.</param>
            
            <returns>A <see cref="T:Accord.MachineLearning.Performance.TrainValDataSplit`2"/> that defines a 
              data split of a subsample of the dataset.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.DataSubset`1">
            <summary>
              Subset of a larger dataset.
            </summary>
            
            <typeparam name="TInput">The type of the input data in this dataset.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`1.Inputs">
            <summary>
              Gets or sets the input data in the dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`1.Weights">
            <summary>
              Gets or sets the weights associated with each input sample in the dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`1.Indices">
            <summary>
              Gets or sets the indices of the samples of this subset 
              in relation to the original dataset they belong to.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`1.Tag">
            <summary>
              Gets or sets a user-defined tag that can be associated with this instance.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`1.Proportion">
            <summary>
              Gets or sets the size of this subset as a proportion in 
              relation to the original dataset this subset comes from.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`1.Index">
            <summary>
              Gets or sets an index associated with this subset, if applicable.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.DataSubset`1.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.DataSubset`1"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.DataSubset`1.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.DataSubset`1"/> class.
            </summary>
            
            <param name="subsetSize">The size of the data subset.</param>
            <param name="totalSize">The total size of the dataset that contains this subset.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.DataSubset`1.#ctor(System.Int32,`0[],System.Double[],System.Int32[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.DataSubset`1"/> class.
            </summary>
            
            <param name="index">The index associated with this subset, if any.</param>
            <param name="inputs">The input instances in this subset.</param>
            <param name="weights">The weights associated with the input instances.</param>
            <param name="indices">The indices of the input instances in relation to the original dataset.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.DataSubset`2">
            <summary>
              Subset of a larger dataset.
            </summary>
            
            <typeparam name="TInput">The type of the input data in this dataset.</typeparam>
            <typeparam name="TOutput"> The type of the output data in this dataset.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.DataSubset`2.Outputs">
            <summary>
              Gets or sets the input data in the dataset.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.DataSubset`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.DataSubset`2"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.DataSubset`2.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.DataSubset`2"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.DataSubset`2.#ctor(System.Int32,`0[],`1[],System.Double[],System.Int32[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.DataSubset`2"/> class.
            </summary>
            
            <param name="index">The index associated with this subset, if any.</param>
            <param name="inputs">The input instances in this subset.</param>
            <param name="outputs">The output instances in this subset.</param>
            <param name="weights">The weights associated with the input instances.</param>
            <param name="indices">The indices of the input instances in relation to the original dataset.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearchRange`1">
            <summary>
              Range of parameters to be tested in a grid search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchRange`1.Values">
            <summary>
              Gets or sets the range of values that should be tested for this parameter.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchRange`1.Index">
            <summary>
              Gets or sets the index of the current value in the search,
              whose value will be shown in the <see cref="P:Accord.MachineLearning.Performance.GridSearchRange`1.Value"/> property.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchRange`1.Value">
            <summary>
              Gets the current value being considered during the grid-search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchRange`1.Length">
            <summary>
              Gets the number of values that this parameter can assume (the length of the parameter range).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearchRange`1.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            
            <returns>A new object that is a copy of this instance.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearchRange`1.op_Implicit(Accord.MachineLearning.Performance.GridSearchRange{`0})~`0">
            <summary>
            Performs an implicit conversion from <see cref="T:Accord.MachineLearning.Performance.GridSearchRange`1"/> to <typeparam ref="T"/>.
            </summary>
            
            <param name="range">The range to be converted.</param>
            
            <returns>The value of the parameter's <see cref="P:Accord.MachineLearning.Performance.GridSearchRange`1.Value"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearch`2">
            <summary>
              Grid search procedure for automatic parameter tuning.
            </summary>
            
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <remarks>
              Grid Search tries to find the best combination of parameters across a range of possible values that produces the best fit model. If there
              are two parameters, each with 10 possible values, Grid Search will try an exhaustive evaluation of the model using every combination of points,
              resulting in 100 model fits.
            </remarks>
            
            <example>
              <para>
                The framework offers different ways to use grid search: one version is strongly-typed using generics
                and the other might need some manual casting. The exapmle below shows how to perform grid-search in
                a non-stringly typed way:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn" />
              
              <para>
                The main disadvantages of the method above is the need to keep string identifiers for each of the parameters
                being searched. Furthermore, it is also necessary to keep track of their types in order to cast them accordingly
                when using them in the specification of the <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Learner"/>
                property. </para>
                
              <para>    
                The next example shows how to perform grid-search in a strongly typed way:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
              
              <para>
                The code above uses anonymous types and generics to create a specialized <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/>
                class that keeps the anonymous type given as <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.ParameterRanges"/>.
                Its main disadvantage is the (high) increase in type complexity, making the use of the <c>var</c> keyword almost
                mandatory.</para>
                
              <para>
                It is also possible to create grid-search objects using convenience methods from the static <see cref="T:Accord.MachineLearning.Performance.GridSearch"/> class:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
              
              <para>
                Finally, it is also possible to combine grid-search with <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>, 
                as shown in the examples below: </para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_cv" />
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_tree_cv" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`2.Create``2(Accord.MachineLearning.GridSearchRange[],Accord.MachineLearning.Performance.CreateLearnerFromParameter{``1,Accord.MachineLearning.GridSearchParameterCollection},Accord.MachineLearning.Performance.ComputeLoss{`1,``0},Accord.MachineLearning.Performance.LearnNewModel{``1,`0,`1,``0})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> algorithm.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`2.Create``3(``0,Accord.MachineLearning.Performance.CreateLearnerFromParameter{``2,``0},Accord.MachineLearning.Performance.ComputeLoss{`1,``1},Accord.MachineLearning.Performance.LearnNewModel{``2,`0,`1,``1})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> algorithm.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TRange">The type that specifies how ranges of the parameter values are represented.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`2.CrossValidate``3(``0,System.Func{``0,Accord.MachineLearning.Performance.DataSubset{`0,`1},``2},Accord.MachineLearning.Performance.ComputeLoss{`1,``1},Accord.MachineLearning.Performance.LearnNewModel{``2,`0,`1,``1},System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> combined with 
              <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> algorithms.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TRange">The type that specifies how ranges of the parameter values are represented.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="folds">The number of folds in the k-fold cross-validation. Default is 10.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`2.CrossValidate``2(Accord.MachineLearning.GridSearchRange[],System.Func{Accord.MachineLearning.GridSearchParameterCollection,Accord.MachineLearning.Performance.DataSubset{`0,`1},``1},Accord.MachineLearning.Performance.ComputeLoss{`1,``0},Accord.MachineLearning.Performance.LearnNewModel{``1,`0,`1,``0},System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> combined with 
              <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> algorithms.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="folds">The number of folds in the k-fold cross-validation. Default is 10.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearch`3">
            <summary>
              Grid search procedure for automatic parameter tuning.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <remarks>
              Grid Search tries to find the best combination of parameters across a range of possible values that produces the best fit model. If there
              are two parameters, each with 10 possible values, Grid Search will try an exhaustive evaluation of the model using every combination of points,
              resulting in 100 model fits.
            </remarks>
            
            <example>
              <para>
                The framework offers different ways to use grid search: one version is strongly-typed using generics
                and the other might need some manual casting. The exapmle below shows how to perform grid-search in
                a non-stringly typed way:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn" />
              
              <para>
                The main disadvantages of the method above is the need to keep string identifiers for each of the parameters
                being searched. Furthermore, it is also necessary to keep track of their types in order to cast them accordingly
                when using them in the specification of the <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Learner"/>
                property. </para>
                
              <para>    
                The next example shows how to perform grid-search in a strongly typed way:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
              
              <para>
                The code above uses anonymous types and generics to create a specialized <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/>
                class that keeps the anonymous type given as <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.ParameterRanges"/>.
                Its main disadvantage is the (high) increase in type complexity, making the use of the <c>var</c> keyword almost
                mandatory.</para>
                
              <para>
                It is also possible to create grid-search objects using convenience methods from the static <see cref="T:Accord.MachineLearning.Performance.GridSearch"/> class:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
              
              <para>
                Finally, it is also possible to combine grid-search with <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>, 
                as shown in the examples below: </para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_cv" />
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_tree_cv" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/> class.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearch`5">
            <summary>
              Grid search procedure for automatic parameter tuning.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TRange">The type that specifies how ranges of the parameter values are represented.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <remarks>
              Grid Search tries to find the best combination of parameters across a range of possible values that produces the best fit model. If there
              are two parameters, each with 10 possible values, Grid Search will try an exhaustive evaluation of the model using every combination of points,
              resulting in 100 model fits.
            </remarks>
            
            <example>
              <para>
                The framework offers different ways to use grid search: one version is strongly-typed using generics
                and the other might need some manual casting. The exapmle below shows how to perform grid-search in
                a non-stringly typed way:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn" />
              
              <para>
                The main disadvantages of the method above is the need to keep string identifiers for each of the parameters
                being searched. Furthermore, it is also necessary to keep track of their types in order to cast them accordingly
                when using them in the specification of the <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Learner"/>
                property. </para>
                
              <para>    
                The next example shows how to perform grid-search in a strongly typed way:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
              
              <para>
                The code above uses anonymous types and generics to create a specialized <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/>
                class that keeps the anonymous type given as <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.ParameterRanges"/>.
                Its main disadvantage is the (high) increase in type complexity, making the use of the <c>var</c> keyword almost
                mandatory.</para>
                
              <para>
                It is also possible to create grid-search objects using convenience methods from the static <see cref="T:Accord.MachineLearning.Performance.GridSearch"/> class:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
              
              <para>
                Finally, it is also possible to combine grid-search with <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>, 
                as shown in the examples below: </para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_cv" />
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_tree_cv" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`5.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`5.GetLengths">
            <summary>
              Inheritors of this class should return the number of possible parameter values for
              each parameter in the grid-search range. For example, if a problem should search
              parameters in the range {0, 1, ... 9} (10 values) and {-1, -2, -3 } (3 values), this 
              method should return { 10, 3 }.
            </summary>
            
            <returns>The number of possibilities for each parameter.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`5.GetParameters(System.Int32[])">
            <summary>
              Inheritors of this class should specify how to get actual values for the parameters
              given a index vector in the grid-search space. Those indices indicate which values
              should be given, e.g. if there are two parameters in the problem, the ranges of the
              first parameter are {10, 20, 30}, and the ranges of the second parameter are {0.1, 0.01, 0.001 },
              if the index vector is { 1, 2 } this method should return { 20, 0.001 }.
            </summary>
            
            <param name="indices">The indices in grid-search space.</param>
            
            <returns>The parameters at the location indicated by <paramref name="indices"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearch">
            <summary>
              Grid search procedure for automatic parameter tuning.
            </summary>
            
            <remarks>
              Grid Search tries to find the best combination of parameters across a range of possible values that produces the best fit model. If there
              are two parameters, each with 10 possible values, Grid Search will try an exhaustive evaluation of the model using every combination of points,
              resulting in 100 model fits.
            </remarks>
            
            <example>
              <para>
                The framework offers different ways to use grid search: one version is strongly-typed using generics
                and the other might need some manual casting. The exapmle below shows how to perform grid-search in
                a non-stringly typed way:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn" />
              
              <para>
                The main disadvantages of the method above is the need to keep string identifiers for each of the parameters
                being searched. Furthermore, it is also necessary to keep track of their types in order to cast them accordingly
                when using them in the specification of the <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Learner"/>
                property. </para>
                
              <para>    
                The next example shows how to perform grid-search in a strongly typed way:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
              
              <para>
                The code above uses anonymous types and generics to create a specialized <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/>
                class that keeps the anonymous type given as <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.ParameterRanges"/>.
                Its main disadvantage is the (high) increase in type complexity, making the use of the <c>var</c> keyword almost
                mandatory.</para>
                
              <para>
                It is also possible to create grid-search objects using convenience methods from the static <see cref="T:Accord.MachineLearning.Performance.GridSearch"/> class:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
              
              <para>
                Finally, it is also possible to combine grid-search with <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>, 
                as shown in the examples below: </para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_cv" />
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_tree_cv" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch.Values``1(``0[])">
            <summary>
              Creates a range of parameter values that should be searched during <see cref="T:Accord.MachineLearning.Performance.GridSearch"/>.
            </summary>
            
            <typeparam name="T">The type of the parameter values.</typeparam>
            
            <param name="values">The values to be included in <see cref="T:Accord.MachineLearning.Performance.GridSearch"/>.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch.Create``4(Accord.MachineLearning.GridSearchRange[],Accord.MachineLearning.Performance.CreateLearnerFromParameter{``3,Accord.MachineLearning.GridSearchParameterCollection},Accord.MachineLearning.Performance.ComputeLoss{``1,``2},Accord.MachineLearning.Performance.LearnNewModel{``3,``0,``1,``2},``0[],``1[])">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> algorithm.
            </summary>
            
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="x">The input data to be used during training.</param>
            <param name="y">The output data to be used during training.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch.Create``5(``2,Accord.MachineLearning.Performance.CreateLearnerFromParameter{``4,``2},Accord.MachineLearning.Performance.ComputeLoss{``1,``3},Accord.MachineLearning.Performance.LearnNewModel{``4,``0,``1,``3},``0[],``1[])">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> algorithm.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TRange">The type that specifies how ranges of the parameter values are represented.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="x">The input data to be used during training.</param>
            <param name="y">The output data to be used during training.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch.CrossValidate``5(``2,System.Func{``2,Accord.MachineLearning.Performance.DataSubset{``0,``1},``4},Accord.MachineLearning.Performance.ComputeLoss{``1,``3},Accord.MachineLearning.Performance.LearnNewModel{``4,``0,``1,``3},``0[],``1[],System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> combined with 
              <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> algorithms.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TRange">The type that specifies how ranges of the parameter values are represented.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="folds">The number of folds in the k-fold cross-validation. Default is 10.</param>
            <param name="x">The input data to be used during training.</param>
            <param name="y">The output data to be used during training.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch.CrossValidate``4(Accord.MachineLearning.GridSearchRange[],System.Func{Accord.MachineLearning.GridSearchParameterCollection,Accord.MachineLearning.Performance.DataSubset{``0,``1},``3},Accord.MachineLearning.Performance.ComputeLoss{``1,``2},Accord.MachineLearning.Performance.LearnNewModel{``3,``0,``1,``2},``0[],``1[],System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.GridSearch`5"/> combined with 
              <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> algorithms.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <param name="ranges">The range of parameters to consider during search.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="folds">The number of folds in the k-fold cross-validation. Default is 10.</param>
            <param name="x">The input data to be used during training.</param>
            <param name="y">The output data to be used during training.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearch`4">
            <summary>
              Grid search procedure for automatic parameter tuning.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <remarks>
              Grid Search tries to find the best combination of parameters across a range of possible values that produces the best fit model. If there
              are two parameters, each with 10 possible values, Grid Search will try an exhaustive evaluation of the model using every combination of points,
              resulting in 100 model fits.
            </remarks>
            
            <example>
              <para>
                The framework offers different ways to use grid search: one version is strongly-typed using generics
                and the other might need some manual casting. The exapmle below shows how to perform grid-search in
                a non-stringly typed way:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn" />
              
              <para>
                The main disadvantages of the method above is the need to keep string identifiers for each of the parameters
                being searched. Furthermore, it is also necessary to keep track of their types in order to cast them accordingly
                when using them in the specification of the <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Learner"/>
                property. </para>
                
              <para>    
                The next example shows how to perform grid-search in a strongly typed way:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_strongly_typed" />
              
              <para>
                The code above uses anonymous types and generics to create a specialized <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/>
                class that keeps the anonymous type given as <see cref="P:Accord.MachineLearning.Performance.BaseGridSearch`7.ParameterRanges"/>.
                Its main disadvantage is the (high) increase in type complexity, making the use of the <c>var</c> keyword almost
                mandatory.</para>
                
              <para>
                It is also possible to create grid-search objects using convenience methods from the static <see cref="T:Accord.MachineLearning.Performance.GridSearch"/> class:</para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_create" />
              
              <para>
                Finally, it is also possible to combine grid-search with <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>, 
                as shown in the examples below: </para>
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_cv" />
                <code source="Unit Tests\Accord.Tests.MachineLearning\GridSearchTest.cs" region="doc_learn_tree_cv" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`4.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.GridSearch`4"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`4.GetLengths">
            <summary>
              Inheritors of this class should return the number of possible parameter values for
              each parameter in the grid-search range. For example, if a problem should search
              parameters in the range {0, 1, ... 9} (10 values) and {-1, -2, -3 } (3 values), this 
              method should return { 10, 3 }.
            </summary>
            
            <returns>The number of possibilities for each parameter.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearch`4.GetParameters(System.Int32[])">
            <summary>
              Inheritors of this class should specify how to get actual values for the parameters
              given a index vector in the grid-search space. Those indices indicate which values
              should be given, e.g. if there are two parameters in the problem, the ranges of the
              first parameter are {10, 20, 30}, and the ranges of the second parameter are {0.1, 0.01, 0.001 },
              if the index vector is { 1, 2 } this method should return { 20, 0.001 }.
            </summary>
            
            <param name="indices">The indices in grid-search space.</param>
            
            <returns>The parameters at the location indicated by <paramref name="indices"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.CreateLearnerFromParameter`2">
            <summary>
              Function signature for a function that creates a machine learning model 
              given a set of parameter values. This function should use the parameters to create and configure
              a <see cref="T:Accord.MachineLearning.ISupervisedLearning`3"/> learning algorithm that can in turn
              be used to create a new machine learning model with those parameters.
            </summary>
            
            <param name="parameters">The training parameters.</param>
            
            <returns>
              A <see cref="T:Accord.MachineLearning.ISupervisedLearning`3"/>learning algorithm that can be used
              to create and train machine learning models.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.BaseGridSearch`7">
            <summary>
              Base class for <see cref="T:Accord.MachineLearning.Performance.GridSearch`3"/> methods.
            </summary>
            
            <typeparam name="TResult">The type of the object that should hold the results of the grid serach (e.g. <see cref="T:Accord.MachineLearning.Performance.GridSearchResult`3"/>).</typeparam>
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TRange">The type that specifies how ranges of the parameter values are represented.</typeparam>
            <typeparam name="TParam">The type that specifies how the value for a single parameter is represented.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch`2"/>
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch`3"/>
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch`4"/>
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch`5"/>
            
            <seealso cref="T:Accord.MachineLearning.ParallelLearningBase" />
            <seealso cref="T:Accord.MachineLearning.ISupervisedLearning`3" />
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseGridSearch`7.ParameterRanges">
            <summary>
              The range of parameters to consider during search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Learner">
            <summary>
              Gets or sets a <see cref="T:Accord.MachineLearning.Performance.CreateLearnerFromParameter`2"/> function 
              that can be used to create a <typeparamref name="TModel"/> given training parameters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Fit">
            <summary>
              Gets or sets a <see cref="T:Accord.MachineLearning.Performance.LearnNewModel`4"/> function that can be used to create
              new <typeparam ref="TModel">machine learning models</typeparam> using the current
              <typeparam ref="TLearner">learning algorithm</typeparam>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseGridSearch`7.Loss">
            <summary>
              Gets or sets a <see cref="T:Accord.MachineLearning.Performance.ComputeLoss`2"/> function that can
              be used to measure how far the actual model predictions were from the expected ground-truth.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseGridSearch`7.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.BaseGridSearch`7" /> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseGridSearch`7.Learn(`5[],`6[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.</returns>
            <exception cref="T:System.InvalidOperationException">
            </exception>
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseGridSearch`7.GetParameters(System.Int32[])">
            <summary>
              Inheritors of this class should specify how to get actual values for the parameters
              given a index vector in the grid-search space. Those indices indicate which values
              should be given, e.g. if there are two parameters in the problem, the ranges of the
              first parameter are {10, 20, 30}, and the ranges of the second parameter are {0.1, 0.01, 0.001 },
              if the index vector is { 1, 2 } this method should return { 20, 0.001 }.
            </summary>
            
            <param name="indices">The indices in grid-search space.</param>
            
            <returns>The parameters at the location indicated by <paramref name="indices"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseGridSearch`7.GetLengths">
            <summary>
              Inheritors of this class should return the number of possible parameter values for
              each parameter in the grid-search range. For example, if a problem should search
              parameters in the range {0, 1, ... 9} (10 values) and {-1, -2, -3 } (3 values), this 
              method should return { 10, 3 }.
            </summary>
            
            <returns>The number of possibilities for each parameter.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.CreateLearnerFromSubset`3">
            <summary>
              Function signature for a function that creates a machine learning model
              from a <see cref="T:Accord.MachineLearning.Performance.DataSubset`2"/> subset of the training data. This function 
              should take a subset of the data as input, and create a <see cref="T:Accord.MachineLearning.ISupervisedLearning`3"/>
              algorithm that can create a model using this given subset.
            </summary>
            
            <param name="subset">The subset of the training data that the model should be trained on.</param>
            
            <returns>
              A <see cref="T:Accord.MachineLearning.ISupervisedLearning`3"/>learning algorithm that can be used
              to create and train machine learning models.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.LearnNewModel`4">
            <summary>
              Function signature for a function that specifies how a <paramref name="teacher">learning algorithm</paramref>
              should be used to create a new <typeparamref name="TModel">machine learning model</typeparamref>.
            </summary>
            
            <param name="teacher">The teacher learning algorithm.</param>
            <param name="inputs">The input data in the dataset.</param>
            <param name="outputs">The output data in the dataset.</param>
            <param name="weights">The weights for each instance in the dataset.</param>
            
            <returns>
              A <typeparamref name="TModel">machine learning</typeparamref> model that has been learnt from the
              <paramref name="inputs">input</paramref> and <paramref name="outputs">output</paramref> data using
              the given <paramref name="teacher">teaching algorithm</paramref>.
            </returns>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.ComputeLoss`2">
            <summary>
              Function signature for a function that can compute a performance metric (i.e. a <see cref="T:Accord.Math.Optimization.Losses.ILoss`1"/>) from
              a set of <paramref name="expected"/> (ground-truth) and <paramref name="actual"/> (model prediction) output
              values. Additional information about the metric (such as its variance) or the learning problem (such as the
              expected number of classes) can be set in the object passed as the <paramref name="info"/> parameter.
            </summary>
            
            <param name="expected">The ground-truth data that the model was supposed to predict.</param>
            <param name="actual">The data that the model has actually predicted.</param>
            <param name="info">A info object (e.g. <see cref="T:Accord.MachineLearning.Performance.SetResult`1"/>) that can be used to obtain more information
              about the data split being evaluated and store additional information about the computed metric.</param>
            
            <returns>A metric that measures how far the model predictions were from the expected ground-truth.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.BaseSplitSetValidation`5">
            <summary>
              Base class for performance measurement methods based on splitting the data into multiple sets,
              such as <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/>, <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>
              and <see cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/>.
            </summary>
            
            <typeparam name="TResult">The type of the result learned by the validation method (e.g. <see cref="T:Accord.MachineLearning.Performance.CrossValidationResult`3"/>).</typeparam>
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.DefaultValue">
            <summary>
              Gets or sets a value to be used as the <see cref="P:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.Loss"/> in case the model throws
              an exception during learning. Default is null (exceptions will not be ignored).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.Learner">
            <summary>
              Gets or sets a <see cref="T:Accord.MachineLearning.Performance.CreateLearnerFromSubset`3"/> function 
              that can be used to create a <typeparamref name="TModel"/> from a subset of the learning dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.Loss">
            <summary>
              Gets or sets a <see cref="T:Accord.MachineLearning.Performance.ComputeLoss`2"/> function that can
              be used to measure how far the actual model predictions were from the expected ground-truth.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.Fit">
            <summary>
              Gets or sets a <see cref="T:Accord.MachineLearning.Performance.LearnNewModel`4"/> function that can be used to create
              new <typeparam ref="TModel">machine learning models</typeparam> using the current
              <typeparam ref="TLearner">learning algorithm</typeparam>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.BaseSplitSetValidation`4"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.Learn(`3[],`4[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseSplitSetValidation`5.LearnSubset(Accord.MachineLearning.Performance.TrainValDataSplit{`3,`4},System.Int32)">
            <summary>
              Learns and evaluates a model in a single subset of the data.
            </summary>
            
            <param name="subset">The subset of the data containing the training and testing subsets where
              a model should be trained and evaluated, respectively.</param>
            <param name="index">The index of this subset, if applicable.</param>
            
            <returns>A <see cref="T:Accord.MachineLearning.Performance.SplitResult`3"/> object containing the created model
              and its performance on the training and validation sets.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.BootstrapResult`3">
            <summary>
              Bootstrap validation analysis results.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BootstrapResult`3.Estimate">
            <summary>
              Gets the 0.632 bootstrap estimate.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.BootstrapResult`3.NumberOfSubsamples">
            <summary>
              Gets the number of subsamples taken to compute the bootstrap estimate.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.BootstrapResult`3.#ctor(Accord.MachineLearning.Performance.SplitResult{`0,`1,`2}[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.BootstrapResult`3"/> class.
            </summary>
            <param name="models">The models created during the cross-validation runs.</param>
        </member>
        <member name="T:Accord.MachineLearning.Performance.Bootstrap`2">
            <summary>
              Bootstrap method for generalization performance measurements (with 
              support for stratification and default loss function for classification).
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\BootstrapTest.cs" region="doc_learn" />
            </example>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/>
            <seealso cref="T:Accord.MachineLearning.Performance.SplitSetValidation`2"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.Bootstrap`2.Stratify">
            <summary>
              Gets or sets a value indicating whether the prevalence of an output 
              label should be balanced between training and testing sets. Default is false.
            </summary>
            
            <value>
            	<c>true</c> if this instance is stratified; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.Bootstrap`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.Bootstrap`2"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.Performance.Bootstrap`2.CreateSubSampleIndices(`1[],System.Int32[],System.Int32,System.Int32)">
            <summary>
              Draws the bootstrap samples from the population.
            </summary>
            
            <param name="x">The input data from where subsamples should be drawn.</param>
            <param name="y">The output data from where subsamples should be drawn.</param>
            <param name="resamplings">The number of samples to drawn.</param>
            <param name="subsampleSize">The size of the samples to be drawn.</param>
            
            <returns>The indices of the samples in the original set.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.Bootstrap`3">
            <summary>
              Bootstrap method for generalization performance measurements.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\BootstrapTest.cs" region="doc_learn" />
            </example>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/>
            <seealso cref="T:Accord.MachineLearning.Performance.SplitSetValidation`2"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.Bootstrap`3.B">
            <summary>
              Gets or sets the number B of bootstrap samplings
              to be drawn from the population dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.Bootstrap`3.NumberOfSubsamples">
            <summary>
              Gets or sets the number of samples to be drawn in each subsample. If 
              set to zero, all samples in the entire dataset will be selected.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.Bootstrap`3.SubSampleIndices">
            <summary>
              Gets the bootstrap samples drawn from the population dataset as indices.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.Bootstrap`3.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Bootstrap" /> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.Bootstrap`3.Learn(`1[],`2[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.</returns>
            <exception cref="T:System.InvalidOperationException">
            Please set the Learner property before calling the Learn(x, y) method.
            or
            Please set the Learner property before calling the Learn(x, y) method.
            </exception>
        </member>
        <member name="M:Accord.MachineLearning.Performance.Bootstrap`3.CreateSubSampleIndices(`1[],`2[],System.Int32,System.Int32)">
            <summary>
              Draws the bootstrap samples from the population.
            </summary>
            
            <param name="x">The input data from where subsamples should be drawn.</param>
            <param name="y">The output data from where subsamples should be drawn.</param>
            <param name="resamplings">The number of samples to drawn.</param>
            <param name="subsampleSize">The size of the samples to be drawn.</param>
            
            <returns>The indices of the samples in the original set.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.Bootstrap`3.GetSubsample(System.Int32,`1[],`2[],System.Double[])">
            <summary>
              Gets a subset of the training and testing sets.
            </summary>
            
            <param name="subsampleIndex">Index of the subsample.</param>
            <param name="x">The input data x.</param>
            <param name="y">The output data y.</param>
            <param name="weights">The weights of each sample.</param>
            
            <returns>A <see cref="T:Accord.MachineLearning.Performance.TrainValDataSplit`2"/> that defines a 
              data split of a subsample of the dataset.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.CrossValidationResult`3">
            <summary>
              Class for representing results acquired through a 
              <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3">k-fold cross-validation analysis</see>.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.NumberOfSamples">
            <summary>
              Gets the total number of data samples in the entire data set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.AverageNumberOfSamples">
            <summary>
              Gets the average number of data samples in 
              each cross-validation fold of the data set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.Models">
            <summary>
              Gets the models created for each fold of the cross validation.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.NumberOfInputs">
            <summary>
            Gets the number of inputs accepted by the model.
            </summary>
            <value>The number of inputs.</value>
            <exception cref="T:System.ArgumentException">This property is read only.</exception>
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.NumberOfOutputs">
            <summary>
            Gets the number of outputs generated by the model.
            </summary>
            <value>The number of outputs.</value>
            <exception cref="T:System.ArgumentException">This property is read only.</exception>
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidationResult`3.#ctor(Accord.MachineLearning.Performance.SplitResult{`0,`1,`2}[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.CrossValidationResult`1"/> class.
            </summary>
            
            <param name="models">The models created during the cross-validation runs.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidationResult`3.Transform(`1)">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
            <exception cref="T:System.Exception">Please specify how the results of the different models should be combined by setting the CombineMethod property.</exception>
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidationResult`3.Transform(`1[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidationResult`3.Transform(`1[],`2[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            <exception cref="T:System.Exception">Please specify how the results of the different models should be combined by setting the CombineMethod property.</exception>
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidationResult`3.CombineMethod">
            <summary>
              Gets or sets the method used to combine the scores of different classifiers. 
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.BaseSplitSetValidation`4">
            <summary>
              Base class for performance measurement methods based on splitting the data into multiple sets,
              such as <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/>, <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>
              and <see cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/>.
            </summary>
            
            <typeparam name="TResult">The type of the result learned by the validation method (e.g. <see cref="T:Accord.MachineLearning.Performance.CrossValidationResult`3"/>).</typeparam>
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            <seealso cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/>
            <seealso cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>
            <seealso cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.BaseSplitSetValidation`4.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.BaseSplitSetValidation`4"/> class.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Performance.IDataSplit`2">
            <summary>
              Common interfae for data splits.
            </summary>
            
            <typeparam name="TInput">The type of the input being partitioned into splits.</typeparam>
            <typeparam name="TOutput">The type of the output being partitioned into splits.</typeparam>
            
            <seealso cref="T:System.Collections.Generic.IEnumerable`1" />
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.IDataSplit`2.SplitIndex">
            <summary>
              Gets or sets the index of the split in relation to the original dataset, if applicable.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.TrainValTestDataSplit`2">
            <summary>
              Training-Validation-Testing data split.
            </summary>
            
            <typeparam name="TInput">The type of the input being partitioned into splits.</typeparam>
            <typeparam name="TOutput">The type of the output being partitioned into splits.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValTestDataSplit`2.SplitIndex">
            <summary>
              Gets or sets the index of the split in relation to the original dataset, if applicable.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValTestDataSplit`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.TrainValTestDataSplit`2" /> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValTestDataSplit`2.#ctor(System.Int32,`0[],`1[],System.Double[],System.Int32[],System.Int32[],System.Int32[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.TrainValTestDataSplit`2"/> class.
            </summary>
            
            <param name="index">The index associated with this subset, if any.</param>
            <param name="inputs">The input instances in this subset.</param>
            <param name="outputs">The output instances in this subset.</param>
            <param name="weights">The weights associated with the input instances.</param>
            <param name="trainIndices">The indices of the training instances in relation to the original dataset.</param>
            <param name="validationIndices">The indices of the validation instances in relation to the original dataset.</param>
            <param name="testingIndices">The indices of the testing instances in relation to the original dataset.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.TrainTestDataSplit`2">
            <summary>
              Training-Validation-Testing data split.
            </summary>
            
            <typeparam name="TInput">The type of the input being partitioned into splits.</typeparam>
            <typeparam name="TOutput">The type of the output being partitioned into splits.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainTestDataSplit`2.SplitIndex">
            <summary>
              Gets or sets the index of the split in relation to the original dataset, if applicable.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainTestDataSplit`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.TrainTestDataSplit`2" /> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainTestDataSplit`2.#ctor(System.Int32,`0[],`1[],System.Double[],System.Int32[],System.Int32[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.TrainTestDataSplit`2"/> class.
            </summary>
            
            <param name="index">The index associated with this subset, if any.</param>
            <param name="inputs">The input instances in this subset.</param>
            <param name="outputs">The output instances in this subset.</param>
            <param name="weights">The weights associated with the input instances.</param>
            <param name="trainIndices">The indices of the training instances in relation to the original dataset.</param>
            <param name="testIndices">The indices of the validation instances in relation to the original dataset.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearchResult`3">
            <summary>
              Contains results from the grid-search procedure.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.GridSearchResult`4">
            <summary>
              Contains results from the grid-search procedure.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TParam">The type that specifies how the value for a single parameter is represented.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.Parameters">
            <summary>
              Gets all combination of parameters tried.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.Models">
            <summary>
              Gets all models created during the search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.Errors">
            <summary>
              Gets the error for each of the created models.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.Exceptions">
            <summary>
              Gets exceptions found during the learning of each of the created models, if any.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.BestModelIndex">
            <summary>
              Gets the index of the best found model
              in the <see cref="P:Accord.MachineLearning.Performance.GridSearchResult`4.Models"/> collection.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.BestModel">
            <summary>
              Gets the best model found.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.BestParameters">
            <summary>
              Gets the best parameter combination found.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.BestModelError">
            <summary>
              Gets the minimum validation error found. If this
              result has been retrieved through Grid-Search Cross-Validation,
              this will correspond to the minimum average validation error
              for the different data splits (validation folds).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.Count">
            <summary>
              Gets the size of the grid used in the grid-search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.NumberOfInputs">
            <summary>
            Gets the number of inputs accepted by the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.GridSearchResult`4.NumberOfOutputs">
            <summary>
            Gets the number of outputs generated by the model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearchResult`4.Transform(`2)">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearchResult`4.Transform(`2[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.GridSearchResult`4.Transform(`2[],`3[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Performance.IGridSearchRange">
            <summary>
              Non-generic interface for <see cref="T:Accord.MachineLearning.Performance.GridSearchRange`1"/>.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearchRange`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.IGridSearchRange.Index">
            <summary>
              Gets or sets the index of the current value in the search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.IGridSearchRange.Length">
            <summary>
              Gets the number of values that this parameter can assume (the length of the parameter range).
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.SetResult`1">
            <summary>
              Training and validation errors of a model. 
            </summary>
            
            <typeparam name="TModel">The type of the model.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Name">
            <summary>
              Gets or sets the set name (e.g. "Training" or "Testing").
            </summary>
            
            <value>The name of this set.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Model">
            <summary>
              Gets the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Indices">
            <summary>
              Gets the indices of the samples in this subset in the original complete dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.NumberOfSamples">
            <summary>
              Gets the number of samples in this subset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Proportion">
            <summary>
              Gets how much this subset represents, in proportion, of the original dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Value">
            <summary>
              Gets the metric value for the model in the current <see cref="P:Accord.MachineLearning.Performance.SetResult`1.Name">set</see>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Variance">
            <summary>
              Gets the variance of the validation value for the model, if available.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.StandardDeviation">
            <summary>
              Gets the standard deviation of the validation value for the model, if available.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SetResult`1.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.SetResult`1.#ctor(`0,System.Int32[],System.String,System.Double)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.SetResult`1"/> class.
            </summary>
            
            <param name="model">The model computed in this subset.</param>
            <param name="indices">The indices of the samples in this subset.</param>
            <param name="name">The name of this set.</param>
            <param name="proportion">The proportion of samples in this subset, compared to the full dataset.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.SplitResult`3">
            <summary>
              Information class to store the training and validation errors of a model. 
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.NumberOfSamples">
            <summary>
              Gets the total number of samples contained in the subset used to teach the <see cref="P:Accord.MachineLearning.Performance.SplitResult`3.Model"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.AverageNumberOfSamples">
            <summary>
              Gets the average number of samples between the <see cref="P:Accord.MachineLearning.Performance.TrainValSplit`1.Training"/>
              and <see cref="P:Accord.MachineLearning.Performance.TrainValSplit`1.Validation"/> sets.
            </summary>
            
            <value>The average number of samples.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.Model">
            <summary>
              Gets the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.Index">
            <summary>
              Gets or sets the index of this split.
            </summary>
            
            <value>The data set split index.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.Tag">
             <summary>
               Gets or sets a tag for user-defined information.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitResult`3.#ctor(`0,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.SplitResult`3"/> class.
            </summary>
            
            <param name="model">The model.</param>
            <param name="index">The index of this subset in relation to the entire set, if applicable.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.NumberOfInputs">
            <summary>
            Gets or sets the number of inputs accepted by the model.
            </summary>
            <value>The number of inputs.</value>
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitResult`3.NumberOfOutputs">
            <summary>
            Gets or sets the number of outputs generated by the model.
            </summary>
            <value>The number of outputs.</value>
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitResult`3.Transform(`1)">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitResult`3.Transform(`1[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitResult`3.Transform(`1[],`2[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Performance.CrossValidation`2">
            <summary>
              k-Fold cross-validation (with support for stratification and default loss function for classification).
            </summary>
            
            <remarks>
            <para>
              Cross-validation is a technique for estimating the performance of a predictive
              model. It can be used to measure how the results of a statistical analysis will
              generalize to an independent data set. It is mainly used in settings where the
              goal is prediction, and one wants to estimate how accurately a predictive model
              will perform in practice.</para>
            <para>
              One round of cross-validation involves partitioning a sample of data into
              complementary subsets, performing the analysis on one subset (called the
              training set), and validating the analysis on the other subset (called the
              validation set or testing set). To reduce variability, multiple rounds of 
              cross-validation are performed using different partitions, and the validation 
              results are averaged over the rounds.</para> 
              
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">
                  Wikipedia, The Free Encyclopedia. Cross-validation (statistics). Available on:
                  http://en.wikipedia.org/wiki/Cross-validation_(statistics) </a></description></item>
              </list></para> 
            </remarks>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/>
            <seealso cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.CrossValidation`2.Stratify">
            <summary>
              Gets or sets a value indicating whether the prevalence of an output 
              label should be balanced between training and testing sets. Default is false.
            </summary>
            
            <value>
            	<c>true</c> if this instance is stratified; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`2.CreateValidationSplits(`1[],System.Int32[],System.Int32)">
            <summary>
              Creates a list of the sample indices that should serve as the validation set.
            </summary>
            
            <param name="x">The input data from where subsamples should be drawn.</param>
            <param name="y">The output data from where subsamples should be drawn.</param>
            <param name="numberOfFolds">The number of folds to be created.</param>
            
            <returns>The indices of the samples in the original set that should compose the validation set.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.CrossValidation`3">
            <summary>
              k-Fold cross-validation.
            </summary>
            
            <remarks>
            <para>
              Cross-validation is a technique for estimating the performance of a predictive
              model. It can be used to measure how the results of a statistical analysis will
              generalize to an independent data set. It is mainly used in settings where the
              goal is prediction, and one wants to estimate how accurately a predictive model
              will perform in practice.</para>
            <para>
              One round of cross-validation involves partitioning a sample of data into
              complementary subsets, performing the analysis on one subset (called the
              training set), and validating the analysis on the other subset (called the
              validation set or testing set). To reduce variability, multiple rounds of 
              cross-validation are performed using different partitions, and the validation 
              results are averaged over the rounds.</para> 
              
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">
                  Wikipedia, The Free Encyclopedia. Cross-validation (statistics). Available on:
                  http://en.wikipedia.org/wiki/Cross-validation_(statistics) </a></description></item>
              </list></para> 
            </remarks>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.CrossValidation`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> class.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Performance.SplitSetValidation`2">
            <summary>
              Split-Set Validation (with support for stratification and default loss function for classification).
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\SplitSetTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/>
            <seealso cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/>
            <seealso cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitSetValidation`2.Stratify">
            <summary>
              Gets or sets a value indicating whether the prevalence of an output 
              label should be balanced between training and testing sets. Default is false.
            </summary>
            
            <value>
            	<c>true</c> if this instance is stratified; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitSetValidation`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`2"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitSetValidation`2.CreateValidationSplits(`1[],System.Int32[])">
            <summary>
              Creates a list of the sample indices that should serve as the validation set.
            </summary>
            
            <param name="x">The input data from where subsamples should be drawn.</param>
            <param name="y">The output data from where subsamples should be drawn.</param>
            
            <returns>The indices of the samples in the original set that should compose the validation set.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.SplitSetValidation`3">
            <summary>
              Split-Set Validation.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model.</typeparam>
            <typeparam name="TInput">The type of the input data.</typeparam>
            <typeparam name="TOutput">The type of the output data or labels.</typeparam>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\SplitSetTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/>
            <seealso cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitSetValidation`3.Indices">
            <summary>
              Gets the group labels assigned to each of the data samples.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitSetValidation`3.ValidationSetProportion">
            <summary>
              Gets or sets the proportion of samples that should be 
              reserved in the validation set. Default is 20%.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitSetValidation`3.TrainingSetProportion">
            <summary>
              Gets or sets the proportion of samples that should be 
              reserved in the training set. Default is 80%.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitSetValidation`3.IndicesValidationSet">
            <summary>
              Gets the indices of elements in the validation set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.SplitSetValidation`3.IndicesTrainingSet">
            <summary>
              Gets the indices of elements in the training set.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitSetValidation`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitSetValidation`3.CreateValidationSplits(`1[],`2[])">
            <summary>
              Creates a list of the sample indices that should serve as the validation set.
            </summary>
            
            <param name="x">The input data from where subsamples should be drawn.</param>
            <param name="y">The output data from where subsamples should be drawn.</param>
            
            <returns>The indices of the samples in the original set that should compose the validation set.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.SplitSetValidation`3.Learn(`1[],`2[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.</returns>
            <exception cref="T:System.InvalidOperationException">
            Please set the Learner property before calling the Learn(x, y) method.
            or
            Please set the Learner property before calling the Learn(x, y) method.
            </exception>
        </member>
        <member name="T:Accord.MachineLearning.Performance.TrainValDataSplit`2">
            <summary>
              Training-Validation-Testing data split.
            </summary>
            
            <typeparam name="TInput">The type of the input being partitioned into splits.</typeparam>
            <typeparam name="TOutput">The type of the output being partitioned into splits.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValDataSplit`2.SplitIndex">
            <summary>
              Gets or sets the index of the split in relation to the original dataset, if applicable.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValDataSplit`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.TrainValDataSplit`2" /> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValDataSplit`2.#ctor(System.Int32,`0[],`1[],System.Double[],System.Int32[],System.Int32[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Performance.TrainValDataSplit`2"/> class.
            </summary>
            
            <param name="index">The index associated with this subset, if any.</param>
            <param name="inputs">The input instances in this subset.</param>
            <param name="outputs">The output instances in this subset.</param>
            <param name="weights">The weights associated with the input instances.</param>
            <param name="trainIndices">The indices of the training instances in relation to the original dataset.</param>
            <param name="validationIndices">The indices of the validation instances in relation to the original dataset.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Performance.TrainValSplit`1">
            <summary>
              Training-Validation split.
            </summary>
            
            <typeparam name="T">The type being separated in training and validation splits.</typeparam>
            
            <seealso cref="T:System.Collections.Generic.IEnumerable`1" />
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValSplit`1.Training">
            <summary>
              Gets or sets the training split.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValSplit`1.Validation">
            <summary>
              Gets or sets the validation split.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValSplit`1.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValSplit`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Performance.TrainValTestSplit`1">
            <summary>
              Training-Validation-Test split.
            </summary>
            
            <typeparam name="T">The type being separated in training, validation and test splits.</typeparam>
            
            <seealso cref="T:System.Collections.Generic.IEnumerable`1" />
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValTestSplit`1.Training">
            <summary>
              Gets or sets the training split.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValTestSplit`1.Validation">
            <summary>
              Gets or sets the validation split.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainValTestSplit`1.Testing">
            <summary>
              Gets or sets the testing split.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValTestSplit`1.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainValTestSplit`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Performance.TrainTestSplit`1">
            <summary>
              Training-Test split.
            </summary>
            
            <typeparam name="T">The type being separated in training and test splits.</typeparam>
            
            <seealso cref="T:System.Collections.Generic.IEnumerable`1" />
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainTestSplit`1.Training">
            <summary>
              Gets or sets the training split.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Performance.TrainTestSplit`1.Testing">
            <summary>
              Gets or sets the testing split.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainTestSplit`1.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.Performance.TrainTestSplit`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="T:Accord.MachineLearning.BagOfWordsStatistics">
            <summary>
              Codebook learning statistics for <see cref="T:Accord.MachineLearning.BagOfWords"/> models.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.TotalNumberOfInstances">
            <summary>
              Gets or sets the number of instances (i.e. images or audio signals) in the training set.
            </summary>
            
            <value>The number of instances (i.e. images or audio signals).</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.TotalNumberOfDescriptors">
            <summary>
              Gets or sets the total number of descriptors seen in the training set.
            </summary>
            
            <value>The total number of descriptors.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.TotalNumberOfDescriptorsPerInstance">
            <summary>
              Gets or sets the count distribution of the descriptors seen in the training set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.TotalNumberOfDescriptorsPerInstanceRange">
            <summary>
              Gets or sets the minimum and maximum number of descriptors per instance seen in the training set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.NumberOfInstancesTaken">
            <summary>
              Gets or sets the number of instances (i.e. images or audio signals)
              actually used in the learning of the <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
            <value>The number of instances.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.NumberOfDescriptorsTaken">
            <summary>
              Gets or sets the number of descriptors actually used 
              in the learning of the <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
            <value>The total number of descriptors.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.NumberOfDescriptorsTakenPerInstance">
            <summary>
              Gets or sets the count distribution of the descriptors actually
              used in the learning of the <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWordsStatistics.NumberOfDescriptorsTakenPerInstanceRange">
            <summary>
              Gets or sets the minimum and maximum number of descriptors per instance
              actually used in the learning of the <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.BagOfWords`1">
            <summary>
              Bag of words.
            </summary>
            
            <remarks>
              The bag-of-words (BoW) model can be used to extract finite
              length features from otherwise varying length representations.
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\BagOfWordsTest.cs" region="doc_learn"/>
              
            <para>
              The following example shows how to use Bag-of-Words to convert other kinds of sequences
              into fixed-length representations. In particular, we apply Bag-of-Words to convert data
              from the PENDIGITS handwritten digit recognition dataset and afterwards convert their
              representations using a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.</para>
              
              <code source="Unit Tests\Accord.Tests.MachineLearning\BagOfWordsTest.cs" region="doc_learn_pendigits"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords`1.#ctor">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.BagOfWords`2">
            <summary>
              Bag of words.
            </summary>
            
            <remarks>
              The bag-of-words (BoW) model can be used to extract finite
              length features from otherwise varying length representations.
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\BagOfWordsTest.cs" region="doc_learn"/>
              
            <para>
              The following example shows how to use Bag-of-Words to convert other kinds of sequences
              into fixed-length representations. In particular, we apply Bag-of-Words to convert data
              from the PENDIGITS handwritten digit recognition dataset and afterwards convert their
              representations using a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.</para>
              
              <code source="Unit Tests\Accord.Tests.MachineLearning\BagOfWordsTest.cs" region="doc_learn_pendigits"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords`2.#ctor">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.BaseBagOfWords`6">
            <summary>
              Base class for <see cref="T:Accord.MachineLearning.BagOfWords">Bag of Audiovisual Words</see> implementations.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.NumberOfWords">
            <summary>
              Gets the number of words in this codebook.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.NumberOfDescriptors">
            <summary>
              Gets or sets the maximum number of descriptors that should be used 
              to learn the codebook. Default is 0 (meaning to use all descriptors).
            </summary>
            
            <value>The maximum number of samples.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.MaxDescriptorsPerInstance">
            <summary>
              Gets or sets the maximum number of descriptors per image that should be 
              used to learn the codebook. Default is 0 (meaning to use all descriptors).
            </summary>
            
            <value>The maximum number of samples per image.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.Clustering">
            <summary>
              Gets the clustering algorithm used to create this model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.Detector">
            <summary>
              Gets the feature extractor used to identify features in the input data.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.NumberOfInputs">
            <summary>
            Gets the number of inputs accepted by the model.
            </summary>
            <value>The number of inputs.</value>
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.NumberOfOutputs">
            <summary>
            Gets the number of outputs generated by the model.
            </summary>
            <value>The number of outputs.</value>
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`6.Statistics">
            <summary>
            Gets statistics about the last codebook learned.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.#ctor">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BaseBagOfWords`6"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Init(`4,`3)">
            <summary>
              Initializes this instance.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(System.Collections.Generic.IEnumerable{`1},System.Int32[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(System.Collections.Generic.IEnumerable{`1},System.Double[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(`5,System.Double[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(`5,System.Int32[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(System.Collections.Generic.List{`1})">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(`5)">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(`5[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.For(System.Int32,System.Int32,System.Action{System.Int32,`4})">
            <summary>
              Executes a parallel for using the feature detector in a thread-safe way.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(`5[],System.Double[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Transform(`5[],System.Int32[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Learn(`2[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.Learn(`5[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`6.InnerLearn``1(``0[],System.Double[],System.Func{``0,`4,System.Collections.Generic.IEnumerable{`1}})">
            <summary>
              Generic learn method implementation that should work for any input type.
              This method is useful for re-using code between methods that accept Bitmap,
              BitmapData, UnmanagedImage, filenames as strings, etc.
            </summary>
            
            <typeparam name="T">The input type.</typeparam>
            
            <param name="x">The inputs.</param>
            <param name="weights">The weights.</param>
            <param name="extractor">A function that knows how to process the input 
              and extract features from them.</param>
            
            <returns>The trained model.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.BaseBagOfWords`3">
            <summary>
              Base class for Bag of Visual Words implementations.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`3.NumberOfWords">
            <summary>
              Gets the number of words in this codebook.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`3.Clustering">
            <summary>
              Gets the clustering algorithm used to create this model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`3.NumberOfInputs">
            <summary>
            Gets the number of inputs accepted by the model.
            </summary>
            <value>The number of inputs.</value>
        </member>
        <member name="P:Accord.MachineLearning.BaseBagOfWords`3.NumberOfOutputs">
            <summary>
            Gets the number of outputs generated by the model.
            </summary>
            <value>The number of outputs.</value>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.#ctor">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Init(`2)">
            <summary>
              Initializes this instance.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[],System.Int32[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[],System.Double[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Learn(`1[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="inputs">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="inputs" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[][],System.Double[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[][],System.Int32[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1)">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Accord#MachineLearning#ICovariantTransform{TInput,Accord#Math#Sparse{System#Double}}#Transform(`1[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BaseBagOfWords`3.Transform(`1[],Accord.Math.Sparse{System.Double}[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="T:Accord.MachineLearning.TermFrequency">
            <summary>
              Weighting schemes for term-frequency (TF).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.TermFrequency.Binary">
            <summary>
              Binary TF variant (0, 1).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.TermFrequency.Default">
            <summary>
              Raw frequency variant (f_{t,d}).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.TermFrequency.Log">
            <summary>
              Log normalization (1 + log(f_{t,d})).
            </summary>
        </member>
        <member name="F:Accord.MachineLearning.TermFrequency.DoubleNormalization">
            <summary>
              Double normalization (0.5 + 0.5 { f_{t,d} / max_t'{ f_{t',d} } }
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.InverseDocumentFrequency">
            <summary>
              Weighting schemes for Inverse Document Frequency (IDF).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.InverseDocumentFrequency.Unary">
            <summary>
              Unary (1).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.InverseDocumentFrequency.Default">
            <summary>
              Inverse document frequency, log(N / n_t).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.InverseDocumentFrequency.Smooth">
            <summary>
              Smooth inverse document frequency, log(N / (1 + n_t)).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.InverseDocumentFrequency.Max">
            <summary>
              Max inverse document frequency, log( max_t'{n_t} / n_t).
            </summary>
        </member>
        <member name="F:Accord.MachineLearning.InverseDocumentFrequency.Probabilistic">
            <summary>
              Probabilistic inverse document frequency, log((N -n_t) / n_t).
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.TFIDF">
            <summary>
              Term Frequency - Inverse Term Frequency.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.Counts">
            <summary>
              Gets the number of documents that contain each code word. Each element 
              is associated with a word, and the value of the element gives the number 
              of documents that contain this word.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.NumberOfDocuments">
            <summary>
              Gets the total number of documents considered by this TF-IDF.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.NumberOfWords">
            <summary>
              Gets the number of words in this codebook.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.NumberOfInputs">
            <summary>
            Gets the number of inputs accepted by the model.
            </summary>
            
            <value>The number of inputs.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.NumberOfOutputs">
            <summary>
            Gets the number of outputs generated by the model.
            </summary>
            
            <value>The number of outputs.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.Idf">
            <summary>
              Gets or sets the inverse document frequency (IDF) definition to be used.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.Tf">
            <summary>
              Gets or sets the term frequency (TF) definition to be used.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.UpdateDictionary">
            <summary>
            Gets or sets a value indicating whether new words should be added to the
            dictionary in the next call to <see cref="M:Accord.MachineLearning.TFIDF.Learn(System.String[][],System.Double[])"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.TFIDF.InverseDocumentFrequency">
            <summary>
              Gets the inverse document frequency vector used to scale term-frequency vectors.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.#ctor">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.TFIDF"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.#ctor(System.String[][])">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.TFIDF"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Learn(System.String[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[][],System.Double[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[][],Accord.Math.Sparse{System.Double}[]@)">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[][],Accord.Math.Sparse{System.Double}[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[],System.Double[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[],Accord.Math.Sparse{System.Double})">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.TFIDF.Transform(System.String[],Accord.Math.Sparse{System.Double}@)">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
            
            <example>
              <para>Examples are available in the main documentation page for 
              <see cref="T:Accord.MachineLearning.TFIDF"/>. One of those examples is reproduced below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\TFIDFTest.cs" region="doc_learn"/>
            </example>
            
        </member>
        <member name="T:Accord.MachineLearning.BagOfWords">
            <summary>
              Bag of words.
            </summary>
            
            <remarks>
              The bag-of-words (BoW) model can be used to extract finite
              length features from otherwise varying length representations.
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\BagOfWordsTest.cs" region="doc_learn"/>
              
            <para>
              The following example shows how to use Bag-of-Words to convert other kinds of sequences
              into fixed-length representations. In particular, we apply Bag-of-Words to convert data
              from the PENDIGITS handwritten digit recognition dataset and afterwards convert their
              representations using a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.</para>
              
              <code source="Unit Tests\Accord.Tests.MachineLearning\BagOfWordsTest.cs" region="doc_learn_pendigits"/>
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWords.NumberOfWords">
            <summary>
              Gets the number of words in this codebook.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWords.NumberOfOutputs">
            <summary>
            Gets the number of outputs generated by the model.
            </summary>
            <value>The number of outputs.</value>
        </member>
        <member name="P:Accord.MachineLearning.BagOfWords.NumberOfInputs">
            <summary>
            Gets the number of inputs accepted by the model.
            </summary>
            <value>The number of inputs.</value>
        </member>
        <member name="P:Accord.MachineLearning.BagOfWords.StringToCode">
            <summary>
              Gets the forward dictionary which translates
              string tokens to integer labels.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWords.CodeToString">
            <summary>
              Gets the reverse dictionary which translates
              integer labels into string tokens.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BagOfWords.MaximumOccurance">
            <summary>
              Gets or sets the maximum number of occurrences of a word which
              should be registered in the feature vector. Default is 1 (if a
              word occurs, corresponding feature is set to 1).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.#ctor(System.String[][])">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
            <param name="texts">The texts to build the bag of words model from.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.#ctor(System.String[])">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
            <param name="texts">The texts to build the bag of words model from.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.#ctor">
            <summary>
              Constructs a new <see cref="T:Accord.MachineLearning.BagOfWords"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Compute(System.String[][])">
            <summary>
              Computes the Bag of Words model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.GetFeatureVector(System.String[])">
            <summary>
              Gets the codeword representation of a given text.
            </summary>
            
            <param name="text">The text to be processed.</param>
            
            <returns>An integer vector with the same length as words
            in the code book.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[],System.Double[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[],System.Int32[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>The output generated by applying this transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[][],System.Int32[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[][],System.Double[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[][])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Learn(System.String[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Learn(System.String[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[],Accord.Math.Sparse{System.Double})">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.Transform(System.String[][],Accord.Math.Sparse{System.Double}[])">
            <summary>
            Applies the transformation to a set of input vectors,
            producing an associated set of output vectors.
            </summary>
            <param name="input">The input data to which
            the transformation should be applied.</param>
            <param name="result">The location to where to store the
            result of this transformation.</param>
            <returns>The output generated by applying this
            transformation to the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.BagOfWords.GetDefaultClusteringAlgorithm(System.Int32)">
            <summary>
              Creates the default clustering algorithm for Bag-of-Words models (<see cref="T:Accord.MachineLearning.KMeans"/>).
            </summary>
            
            <param name="numberOfWords">The number of clusters for k-means.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Rules.AssociationRule`1">
            <summary>
              Association rule.
            </summary>
            
            <typeparam name="T">The item type.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRule`1.X">
            <summary>
              Gets or sets the set of items that triggers the 
              activation of this association rule.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRule`1.Y">
            <summary>
              Gets or sets the set of items that are also likely to
              be included in the original list given that <see cref="P:Accord.MachineLearning.Rules.AssociationRule`1.X">
              the input items</see> are present.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRule`1.Support">
            <summary>
              Gets or sets the number of cases that support this rule
              (the number of times this association has been seen in the
              training set).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRule`1.Confidence">
            <summary>
              Gets or sets the confidence of this rule (as a percentage).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRule`1.Matches(Accord.Compat.SortedSet{`0})">
            <summary>
              Determines whether this rule can be applied to a given input.
            </summary>
            <param name="input">The set of elements (being bought, or processed).</param>
            
            <returns>True, if this rule can be applied to the given set of inputs; false othersie.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRule`1.Matches(`0[])">
            <summary>
              Determines whether this rule can be applied to a given input.
            </summary>
            <param name="input">The set of elements (being bought, or processed).</param>
            
            <returns>True, if this rule can be applied to the given set of inputs; false othersie.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRule`1.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.Rules.Apriori">
             <summary>
               A-priori algorithm for association rule mining.
             </summary>
             
             <remarks>
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   Anita Wasilewska, Lecture Notes. Available on 
                   http://www3.cs.stonybrook.edu/~cse634/lecture_notes/07apriori.pdf </description></item>
                </list>></para>
             </remarks>
             
             <example>
               <code source="Unit Tests\Accord.Tests.MachineLearning\AprioriTest.cs" region="doc_learn_1" lang="cs"/>
               <code source="Unit Tests\Accord.Tests.MachineLearning\AprioriTest.cs" region="doc_learn_2" lang="cs"/>
             </example>
             
             <seealso cref="T:Accord.MachineLearning.Rules.AssociationRule`1"/>
             <seealso cref="T:Accord.MachineLearning.Rules.AssociationRuleMatcher`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.Apriori.#ctor(System.Int32,System.Double)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Rules.Apriori"/> class.
            </summary>
            <param name="threshold">The minimum number of times a rule should be detected (also known as its support) 
              before it can be registered as a permanent in the learned classifier.</param>
            <param name="confidence">The minimum confidence in an association rule beore it is 
              registered.</param>
              
        </member>
        <member name="T:Accord.MachineLearning.Rules.Apriori`1">
             <summary>
               A-priori algorithm for association rule mining.
             </summary>
             
             <typeparam name="T">The dataset item type. Default is int.</typeparam>
             
             <remarks>
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   Anita Wasilewska, Lecture Notes. Available on 
                   http://www3.cs.stonybrook.edu/~cse634/lecture_notes/07apriori.pdf </description></item>
                </list>></para>
             </remarks>
             
             <example>
               <code source="Unit Tests\Accord.Tests.MachineLearning\AprioriTest.cs" region="doc_learn_1" lang="cs"/>
               <code source="Unit Tests\Accord.Tests.MachineLearning\AprioriTest.cs" region="doc_learn_2" lang="cs"/>
             </example>
             
             <seealso cref="T:Accord.MachineLearning.Rules.AssociationRule`1"/>
             <seealso cref="T:Accord.MachineLearning.Rules.AssociationRuleMatcher`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.Apriori`1.Frequent">
            <summary>
              Gets the set of most frequent items and the respective 
              number of times their appear in in the training dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.Apriori`1.Token">
            <summary>
            Gets or sets a cancellation token that can be used to
            stop the learning algorithm while it is running.
            </summary>
            <value>The token.</value>
        </member>
        <member name="M:Accord.MachineLearning.Rules.Apriori`1.#ctor(System.Int32,System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Rules.Apriori`1"/> class.
            </summary>
            
            <param name="threshold">The minimum number of times a rule should be detected (also known as its support) 
              before it can be registered as a permanent in the learned classifier.</param>
            <param name="confidence">The minimum confidence in an association rule beore it is 
              registered.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.Rules.Apriori`1.Learn(`0[][],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the desired outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            
            <returns>A model that has learned how to produce suitable outputs
              given the input data <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.Apriori`1.Learn(Accord.Compat.SortedSet{`0}[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the desired outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            
            <returns>A model that has learned how to produce suitable outputs
              given the input data <paramref name="x"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Rules.AssociationRuleMatcher`1">
            <summary>
              Association ruler matcher.
            </summary>
            
            <typeparam name="T">The item type.</typeparam>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.#ctor(System.Int32,Accord.MachineLearning.Rules.AssociationRule{`0}[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Rules.AssociationRuleMatcher`1"/> class.
            </summary>
            
            <param name="items">The number of distinct items in the dataset.</param>
            <param name="rules">The association rules between items of the dataset.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.NumberOfInputs">
            <summary>
              Gets the number of items seen by the model during training.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.NumberOfOutputs">
            <summary>
              Gets the number of association rules seen by the model.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.NumberOfClasses">
            <summary>
            Gets the number of classes expected and recognized by the classifier.
            </summary>
            <value>The number of classes.</value>
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Rules">
            <summary>
              Gets or sets the association rules in this model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Threshold">
            <summary>
              Gets or sets the minimum confidence threshold used to 
              determine whether a rule applies to an input or not.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(Accord.Compat.SortedSet{`0},Accord.Compat.SortedSet{`0}[]@)">
            <summary>
            Predicts a class label vector for the given input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(Accord.Compat.SortedSet{`0},Accord.Compat.SortedSet{`0}[]@,System.Double[])">
            <summary>
            Predicts a class label vector for the given input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Decide(Accord.Compat.SortedSet{`0})">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Decide(Accord.Compat.SortedSet{`0}[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Decide(Accord.Compat.SortedSet{`0}[],Accord.Compat.SortedSet{`0}[][])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(Accord.Compat.SortedSet{`0}[],Accord.Compat.SortedSet{`0}[][]@)">
            <summary>
            Predicts a class label vector for each input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(Accord.Compat.SortedSet{`0}[],Accord.Compat.SortedSet{`0}[][]@,System.Double[][])">
            <summary>
            Predicts a class label vector for each input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Transform(Accord.Compat.SortedSet{`0})">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>
            The output generated by applying this transformation to the given input.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Transform(Accord.Compat.SortedSet{`0}[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>
            The output generated by applying this transformation to the given input.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Transform(Accord.Compat.SortedSet{`0}[],Accord.Compat.SortedSet{`0}[][])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
            <returns>
            The output generated by applying this transformation to the given input.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(`0[],`0[][]@)">
            <summary>
            Predicts a class label vector for the given input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(`0[],`0[][]@,System.Double[])">
            <summary>
            Predicts a class label vector for the given input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(`0[][],`0[][][]@)">
            <summary>
            Predicts a class label vector for each input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Scores(`0[][],`0[][][]@,System.Double[][])">
            <summary>
            Predicts a class label vector for each input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Decide(`0[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Decide(`0[][])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Decide(`0[][],`0[][][])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="result">An array where the distances will be stored,
              avoiding unnecessary memory allocations.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Transform(`0[])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>
            The output generated by applying this transformation to the given input.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Transform(`0[][])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <returns>
            The output generated by applying this transformation to the given input.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.Rules.AssociationRuleMatcher`1.Transform(`0[][],`0[][][])">
            <summary>
            Applies the transformation to an input, producing an associated output.
            </summary>
            <param name="input">The input data to which the transformation should be applied.</param>
            <param name="result"></param>
            <returns>
            The output generated by applying this transformation to the given input.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4">
            <summary>
              Base class for Naive Bayes learning algorithms.
            </summary>
            
            <typeparam name="TModel">The type for the Naive Bayes model to be learned.</typeparam>
            <typeparam name="TDistribution">The univariate distribution to be used as components in the Naive Bayes distribution.</typeparam>
            <typeparam name="TInput">The type for the samples modeled by the distribution.</typeparam>
            <typeparam name="TOptions">The fitting options for the independent distribution.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.ParallelOptions">
            <summary>
            Gets or sets the parallelization options for this algorithm.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Model">
            <summary>
              Gets or sets the model being learned.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Token">
            <summary>
            Gets or sets a cancellation token that can be used to
            stop the learning algorithm while it is running.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Empirical">
            <summary>
            Gets or sets whether the class priors should be estimated
            from the data.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Options">
             <summary>
               Gets or sets the fitting options to use when
               estimating the class-specific distributions.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Distribution">
            <summary>
              Gets or sets the distribution creation function. This function can
              be used to specify how the initial distributions of the model should
              be created. By default, this function attempts to call the empty
              constructor of the distribution using <c>Activator.CreateInstance()</c>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.#ctor">
             <summary>
               Constructs a new Naïve Bayes learning algorithm.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Create(`2[][],System.Int32)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Learn(`2[][],System.Int32[],System.Double[])">
             <summary>
             Learns a model that can map the given inputs to the given outputs.
             </summary>
            
             <param name="x">The model inputs.</param>
             <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
             <param name="weight">The weight of importance for each input-output pair.</param>
            
             <returns>
               A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
             </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Learn(`2[][],System.Int32[][],System.Double[])">
             <summary>
             Learns a model that can map the given inputs to the given outputs.
             </summary>
            
             <param name="x">The model inputs.</param>
             <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
             <param name="weight">The weight of importance for each input-output pair.</param>
             
             <returns>
               A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
             </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Learn(`2[][],System.Double[][],System.Double[])">
             <summary>
             Learns a model that can map the given inputs to the given outputs.
             </summary>
            
             <param name="x">The model inputs.</param>
             <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
             <param name="weight">The weight of importance for each input-output pair.</param>
             
             <returns>
               A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
             </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`4.Fit(System.Int32,`2[][],System.Double[],System.Boolean)">
            <summary>
               Fits one of the distributions in the naive bayes model.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`5">
            <summary>
              Base class for Naive Bayes learning algorithms.
            </summary>
            
            <typeparam name="TModel">The type for the Naive Bayes model to be learned.</typeparam>
            <typeparam name="TDistribution">The univariate distribution to be used as components in the Naive Bayes distribution.</typeparam>
            <typeparam name="TInput">The type for the samples modeled by the distribution.</typeparam>
            <typeparam name="TOptions">The fitting options for the independent distribution.</typeparam>
            <typeparam name="TInnerOptions">The individual fitting options for the component distributions.</typeparam>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearningBase`5.Fit(System.Int32,`2[][],System.Double[],System.Boolean)">
            <summary>
            Fits one of the distributions in the naive bayes model.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayesLearning`1">
             <summary>
               Naïve Bayes learning algorithm.
             </summary>
             
             <example>
             <para>
               For basic examples on how to learn a Naive Bayes algorithm, please see
               <see cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/> page. The following examples show how to set
               more specialized learning settings for Normal (Gaussian) models.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_learn" />
             </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearning`1.Create(System.Double[][],System.Int32)">
            <summary>
            Creates an instance of the model to be learned.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayesLearning`2">
             <summary>
               Naïve Bayes learning algorithm.
             </summary>
            
             <example>
             <para>
               For basic examples on how to learn a Naive Bayes algorithm, please see
               <see cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/> page. The following examples show how to set
               more specialized learning settings for Normal (Gaussian) models.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_learn_options" />
             </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearning`2.Create(System.Double[][],System.Int32)">
            <summary>
            Creates an instance of the model to be learned.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayesLearning`3">
             <summary>
               Naïve Bayes learning algorithm.
             </summary>
            
             <example>
             <para>
               For basic examples on how to learn a Naive Bayes algorithm, please see
               <see cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/> page. The following examples show how to set
               more specialized learning settings for Normal (Gaussian) models.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_learn_options" />
             </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearning`3.Create(`2[][],System.Int32)">
            <summary>
            Creates an instance of the model to be learned.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayesLearning">
            <summary>
              Naïve Bayes learning algorithm for discrete distribution models.
            </summary>
            
            <example>
            <para>
              For basic examples on how to learn a Naive Bayes algorithm, please see
              <see cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/> page. The following examples show how to set
              more specialized learning settings for discrete models.</para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_laplace" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayesLearning.Create(System.Int32[][],System.Int32)">
            <summary>
            Creates an instance of the model to be learned.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.Bayes`2">
             <summary>
               Bayes decision algorithm (not naive).
             </summary>
             
             <typeparam name="TDistribution">The type for the distributions used to model each class.</typeparam>
             <typeparam name="TInput">The type for the samples modeled by the distributions.</typeparam>
            
             <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/>
             <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes`1"/>
             <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes`2"/>
             
        </member>
        <member name="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions">
            <summary>
              Gets the probability distributions for each class and input.
            </summary>
            
            <value>A TDistribution[,] array in with each row corresponds to a 
            class, each column corresponds to an input variable. Each element
            of this double[,] array is a probability distribution modeling
            the occurrence of the input variable in the corresponding class.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.Bayes`2.Priors">
            <summary>
              Gets the prior beliefs for each class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.Bayes`2.#ctor(System.Int32,System.Int32,System.Func{`0})">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initializer">
              An initialization function used to create the distribution functions for
              each class. Those will be available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.Bayes`2.#ctor(System.Int32,System.Int32,System.Func{System.Int32,`0})">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initializer">
              An initialization function used to create the distribution functions for
              each class. Those will be available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.Bayes`2.LogLikelihood(`1,System.Int32)">
            <summary>
            Computes the log-likelihood that the given input vector
            belongs to the specified <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayes`2">
            <summary>
              Naïve Bayes Classifier for arbitrary distributions of arbitrary elements.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/>
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes`1"/>
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayesLearning`2"/>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`2.#ctor(System.Int32,System.Int32,System.Func{System.Int32,`0})">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initializer">
              An initialization function used to create the distribution functions for
              each class. Those will be available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`2.#ctor(System.Int32,System.Int32,System.Func{System.Int32,System.Int32,`0})">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initialization function used to create the distribution functions for
              each class. Those will be available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`2.#ctor(System.Int32,System.Int32,`0)">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`2.#ctor(System.Int32,System.Int32,`0[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`2.#ctor(System.Int32,System.Int32,`0[][])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.Bayes`2.Distributions"/> property.
            </param>
            
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayes`1">
             <summary>
               Naïve Bayes Classifier for arbitrary distributions.
             </summary>
             
             <remarks>
             <para>
               A naive Bayes classifier is a simple probabilistic classifier based on applying Bayes' theorem
               with strong (naive) independence assumptions. A more descriptive term for the underlying probability
               model would be "independent feature model".</para>
             <para>
               In simple terms, a naive Bayes classifier assumes that the presence (or absence) of a particular
               feature of a class is unrelated to the presence (or absence) of any other feature, given the class
               variable. In spite of their naive design and apparently over-simplified assumptions, naive Bayes 
               classifiers have worked quite well in many complex real-world situations.</para>
               
             <para>
               This class implements an arbitrary-distribution (real-valued) Naive-Bayes classifier. There is 
               also a special <see cref="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32)">named constructor to create classifiers 
               assuming normal distributions for each variable</see>. For a discrete (integer-valued) distribution 
               classifier, please see <see cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/>. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   Wikipedia contributors. "Naive Bayes classifier." Wikipedia, The Free Encyclopedia.
                   Wikipedia, The Free Encyclopedia, 16 Dec. 2011. Web. 5 Jan. 2012.</description></item>
               </list>
             </para>  
             </remarks>
             
             <example>
             <para>
               This page contains two examples, one using text and another one using normal double vectors.
               The first example is the classic example given by Tom Mitchell. If you are not interested
               in text or in this particular example, please jump to the second example below.</para>
               
             <para>
               In the first example, we will be using a mixed-continuous version of the famous Play Tennis
               example by Tom Mitchell (1998). In Mitchell's example, one would like to infer if a person
               would play tennis or not based solely on four input variables. The original variables were
               categorical, but in this example, two of them will be categorical and two will be continuous.
               The rows, or instances presented below represent days on which the behavior of the person
               has been registered and annotated, pretty much building our set of observation instances for
               learning:</para>
             
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_mitchell_1" />
             
             <para>
               In order to estimate a discrete Naive Bayes, we will first convert this problem to a more simpler
               representation. Since some variables are categories, it does not matter if they are represented
               as strings, or numbers, since both are just symbols for the event they represent. Since numbers
               are more easily representable than text strings, we will convert the problem to use a discrete 
               alphabet through the use of a <see cref="T:Accord.Statistics.Filters.Codification">codebook</see>.</para>
             
             <para>
               A codebook effectively transforms any distinct possible value for a variable into an integer 
               symbol. For example, “Sunny” could as well be represented by the integer label 0, “Overcast” 
               by “1”, Rain by “2”, and the same goes by for the other variables. So:</para>
             
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_mitchell_2" />
            
             <para>
               Now that we already have our learning input/output pairs, we should specify our
               Bayes model. We will be trying to build a model to predict the last column, entitled
               “PlayTennis”. For this, we will be using the “Outlook”, “Temperature”, “Humidity” and
               “Wind” as predictors (variables which will we will use for our decision).
             </para>
             
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_mitchell_3" />
             
             <para>Now that we have created and estimated our classifier, we 
             can query the classifier for new input samples through the 
             <c>NaiveBayes{TDistribution}.Decide(double[])</c> method.</para>
             
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_mitchell_4" />
             
             <para>
               In this second example, we will be creating a simple multi-class
               classification problem using integer vectors and learning a discrete
               Naive Bayes on those vectors.</para>
             
             <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayes`1Test.cs" region="doc_learn" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes"/>
             <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayesLearning`1"/>
             
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0)">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. This distribution will
              be cloned and made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0[0:,0:])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0[][])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,System.Func{System.Int32,System.Int32,`0})">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              A function that can initialized the distribution components of all classes
              modeled by this Naive Bayes. This distribution will be cloned and made 
              available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property. The first argument
              in the function should be the classIndex, and the second the variableIndex.
            </param>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions">
            <summary>
            Gets the probability distributions for each class and input.
            </summary>
            <value>
            A TDistribution[,] array in with each row corresponds to a
            class, each column corresponds to an input variable. Each element
            of this double[,] array is a probability distribution modeling
            the occurrence of the input variable in the corresponding class.
            </value>
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes`1.ClassCount">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes`1.InputCount">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Estimate``1(System.Double[][],System.Int32[],System.Boolean,``0)">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Estimate(System.Double[][],System.Int32[],System.Boolean)">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Error(System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Compute(System.Double[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Compute(System.Double[],System.Double@)">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Compute(System.Double[],System.Double@,System.Double[]@)">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Save(System.IO.Stream)">
            <summary>
              Saves the Naïve Bayes model to a stream.
            </summary>
            
            <param name="stream">The stream to which the Naïve Bayes model is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.Save(System.String)">
            <summary>
              Saves the Naïve Bayes model to a stream.
            </summary>
            
            <param name="path">The path to the file to which the Naïve Bayes model is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0,System.Double[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="priors">Obsolete</param>.
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. This distribution will
              be cloned and made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0[],System.Double[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="priors">Obsolete</param>.
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0[0:,0:],System.Double[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="priors">Obsolete</param>.
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes`1.#ctor(System.Int32,System.Int32,`0[][],System.Double[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="priors">Obsolete</param>.
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. Those distributions
              will made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes`1.Distributions"/> property.
            </param>
            
        </member>
        <member name="T:Accord.MachineLearning.Bayes.NaiveBayes">
            <summary>
              Naïve Bayes Classifier.
            </summary>
            
            <remarks>
            <para>
              A naive Bayes classifier is a simple probabilistic classifier based on applying Bayes' theorem
              with strong (naive) independence assumptions. A more descriptive term for the underlying probability
              model would be "independent feature model".</para>
            <para>
              In simple terms, a naive Bayes classifier assumes that the presence (or absence) of a particular
              feature of a class is unrelated to the presence (or absence) of any other feature, given the class
              variable. In spite of their naive design and apparently over-simplified assumptions, naive Bayes 
              classifiers have worked quite well in many complex real-world situations.</para>
              
            <para>
              This class implements a discrete (integer-valued) Naive-Bayes classifier. There is also a 
              special <see cref="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32)">named constructor to create classifiers assuming normal 
              distributions for each variable</see>. For arbitrary distribution classifiers, please see
              <see cref="T:Accord.MachineLearning.Bayes.NaiveBayes`1"/>. </para>
             
            <para>
              References:
              <list type="bullet">
                <item><description>
                  Wikipedia contributors. "Naive Bayes classifier." Wikipedia, The Free Encyclopedia.
                  Wikipedia, The Free Encyclopedia, 16 Dec. 2011. Web. 5 Jan. 2012.</description></item>
              </list>
            </para>  
            </remarks>
            
            <example>
            <para>
              In this example, we will be using the famous Play Tennis example by Tom Mitchell (1998).
              In Mitchell's example, one would like to infer if a person would play tennis or not
              based solely on four input variables. Those variables are all categorical, meaning that
              there is no order between the possible values for the variable (i.e. there is no order
              relationship between Sunny and Rain, one is not bigger nor smaller than the other, but are 
              just distinct). Moreover, the rows, or instances presented below represent days on which the
              behavior of the person has been registered and annotated, pretty much building our set of 
              observation instances for learning:</para>
            
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_mitchell" />
            
            <para>
              <i>Obs: The DataTable representation is not required, and instead the NaiveBayes could
              also be trained directly on integer arrays containing the integer codewords.</i></para>
              
            <para>
              In order to estimate a discrete Naive Bayes, we will first convert this problem to a more simpler
              representation. Since all variables are categories, it does not matter if they are represented
              as strings, or numbers, since both are just symbols for the event they represent. Since numbers
              are more easily representable than text strings, we will convert the problem to use a discrete 
              alphabet through the use of a <see cref="T:Accord.Statistics.Filters.Codification">codebook</see>.</para>
            
            <para>
              A codebook effectively transforms any distinct possible value for a variable into an integer 
              symbol. For example, “Sunny” could as well be represented by the integer label 0, “Overcast” 
              by “1”, Rain by “2”, and the same goes by for the other variables. So:</para>
            
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_codebook" />
            
            <para>
              Now that we already have our learning input/output pairs, we should specify our
              Bayes model. We will be trying to build a model to predict the last column, entitled
              “PlayTennis”. For this, we will be using the “Outlook”, “Temperature”, “Humidity” and
              “Wind” as predictors (variables which will we will use for our decision). Since those
              are categorical, we must specify, at the moment of creation of our Bayes model, the
              number of each possible symbols for those variables.
            </para>
            
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_learn" />
              
            <para>Now that we have created and estimated our classifier, we 
            can query the classifier for new input samples through the 
            Decide method.</para>
            
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_test" />
            
            <para>
              Please note that, while the example uses a DataTable to exemplify how data stored into tables
              can be loaded in the framework, it is not necessary at all to use DataTables in your own, final
              code. For example, please consider the same example shown above, but without DataTables: </para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_mitchell_no_datatable" />
            
            <para>
              In this second example, we will be creating a simple multi-class
              classification problem using integer vectors and learning a discrete
              Naive Bayes on those vectors.</para>
            
            <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_multiclass" />
            
            <para>
              Like all other learning algorithms in the framework, it is also possible to obtain a better measure
              of the performance of the Naive Bayes algorithm using cross-validation, as shown in the example below:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayesLearning"/>
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes`1"/>
            <seealso cref="T:Accord.MachineLearning.Bayes.NaiveBayes`2"/>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.#ctor(System.Int32,System.Int32[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="symbols">The number of symbols for each input variable.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes.NumberOfSymbols">
            <summary>
              Gets the number of symbols for each input in the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes.Distributions">
            <summary>
              Gets the probability distributions for each class and input.
            </summary>
            
            <value>A TDistribution[,] array in with each row corresponds to a 
            class, each column corresponds to an input variable. Each element
            of this double[,] array is a probability distribution modeling
            the occurrence of the input variable in the corresponding class.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32)">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32,Accord.Statistics.Distributions.Univariate.NormalDistribution)">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. This distribution will
              be cloned and made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32,System.Double[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="classPriors">The prior probabilities for each output class.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32,Accord.Statistics.Distributions.Univariate.NormalDistribution[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. This distribution will
              be cloned and made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32,Accord.Statistics.Distributions.Univariate.NormalDistribution[],System.Double[])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. This distribution will
              be cloned and made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes.Distributions"/> property.
            </param>
            <param name="classPriors">The prior probabilities for each output class.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Normal(System.Int32,System.Int32,Accord.Statistics.Distributions.Univariate.NormalDistribution[0:,0:])">
            <summary>
              Constructs a new Naïve Bayes Classifier.
            </summary>
            
            <param name="classes">The number of output classes.</param>
            <param name="inputs">The number of input variables.</param>
            <param name="initial">
              An initial distribution to be used to initialized all independent
              distribution components of this Naive Bayes. This distribution will
              be cloned and made available in the <see cref="P:Accord.MachineLearning.Bayes.NaiveBayes.Distributions"/> property.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.#ctor(System.Int32,System.Double[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Estimate(System.Int32[][],System.Int32[],System.Boolean,System.Double)">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes.SymbolCount">
            <summary>
              Gets the number of symbols for each input in the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes.ClassCount">
            <summary>
              Gets the number of possible output classes.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bayes.NaiveBayes.InputCount">
            <summary>
              Gets the number of inputs in the model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Compute(System.Int32[])">
            <summary>
              Computes the most likely class for a given instance.
            </summary>
            
            <param name="input">The input instance.</param>
            <returns>The most likely class for the instance.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Compute(System.Int32[],System.Double@,System.Double[]@)">
            <summary>
              Computes the most likely class for a given instance.
            </summary>
            
            <param name="input">The input instance.</param>
            <param name="logLikelihood">The log-likelihood for the instance.</param>
            <param name="responses">The response probabilities for each class.</param>
            <returns>The most likely class for the instance.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Save(System.IO.Stream)">
            <summary>
              Saves the Naïve Bayes model to a stream.
            </summary>
            
            <param name="stream">The stream to which the Naïve Bayes model is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Save(System.String)">
            <summary>
              Saves the Naïve Bayes model to a stream.
            </summary>
            
            <param name="path">The path to the file to which the Naïve Bayes model is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Load(System.IO.Stream)">
            <summary>
              Loads a machine from a stream.
            </summary>
            
            <param name="stream">The stream from which the Naïve Bayes model is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Load(System.String)">
            <summary>
              Loads a machine from a file.
            </summary>
            
            <param name="path">The path to the file from which the Naïve Bayes model is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Load``1(System.IO.Stream)">
            <summary>
              Loads a machine from a stream.
            </summary>
            
            <param name="stream">The stream from which the Naïve Bayes model is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Bayes.NaiveBayes.Load``1(System.String)">
            <summary>
              Loads a machine from a file.
            </summary>
            
            <param name="path">The path to the file from which the Naïve Bayes model is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.IBagOfWords`1">
            <summary>
              Common interface for Bag of Words objects.
            </summary>
            
            <typeparam name="T">The type of the element to be 
            converted to a fixed-length vector representation.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.BagOfWords"/> 
            
        </member>
        <member name="P:Accord.MachineLearning.IBagOfWords`1.NumberOfWords">
            <summary>
              Gets the number of words in this codebook.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.IBagOfWords`1.GetFeatureVector(`0)">
            <summary>
              Gets the codeword representation of a given value.
            </summary>
            
            <param name="value">The value to be processed.</param>
            
            <returns>A double vector with the same length as words
            in the code book.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Cluster`3">
            <summary>
              Base class for a data cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Cluster`3.Owner">
            <summary>
              Gets the collection to which this cluster belongs to.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Cluster`3.Index">
            <summary>
              Gets the label for this cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Cluster`3.Proportion">
            <summary>
              Gets the proportion of samples contained in this cluster.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Cluster`3.ClusterCollection.#ctor(`0,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.KMeansClusterCollection"/> class.
            </summary>
            
            <param name="collection">The collection that contains this instance as a field.</param>
            <param name="k">The number of clusters K.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.Cluster`3.ClusterCollection.Clusters">
            <summary>
              Gets the cluster definitions.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Cluster`3.ClusterCollection.Count">
            <summary>
              Gets the number of clusters in the collection.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Cluster`3.ClusterCollection.Item(System.Int32)">
            <summary>
              Gets the cluster at the given index.
            </summary>
            
            <param name="index">The index of the cluster. This should also be the class label of the cluster.</param>
            
            <returns>An object holding information about the selected cluster.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Cluster`3.ClusterCollection.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Cluster`3.ClusterCollection.System#Collections#IEnumerable#GetEnumerator">
            <summary>
              Returns an enumerator that iterates through a collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.BinarySplit">
            <summary>
              Binary split clustering algorithm.
            </summary>
            
            <example>
              How to perform clustering with Binary Split.
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\BinarySplitTest.cs" region="doc_sample1" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="P:Accord.MachineLearning.BinarySplit.ComputeProportions">
            <summary>
              Gets or sets whether <see cref="P:Accord.MachineLearning.KMeansClusterCollection.Proportions">cluster proportions</see> 
              should be calculated after the learning algorithm has finished computing the clusters. Default
              is false.
            </summary>
            
            <value><c>true</c> if  to compute proportions after learning; otherwise, <c>false</c>.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.BinarySplit.#ctor(System.Int32,Accord.Math.Distances.IDistance{System.Double[]})">
            <summary>
              Initializes a new instance of the Binary Split algorithm
            </summary>
            
            <param name="k">The number of clusters to divide the input data into.</param>    
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BinarySplit.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the Binary Split algorithm
            </summary>
            
            <param name="k">The number of clusters to divide the input data into.</param>    
            
        </member>
        <member name="M:Accord.MachineLearning.BinarySplit.Learn(System.Double[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="T:Accord.MachineLearning.GaussianClusterCollection">
            <summary>
              Gaussian Mixture Model Cluster Collection.
            </summary>
            
            <remarks>
            <para>
              This class contains information about all <see cref="T:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster">
              Gaussian clusters</see> found during a <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> 
              estimation. </para>
            <para>
              Given a new sample, this class can be used to find the nearest cluster related
              to this sample through the Nearest method. </para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            <seealso cref="T:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster"/>
            
        </member>
        <member name="T:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster">
            <summary>
              Gaussian Mixture Model cluster.
            </summary>
            
            <remarks>
              This class contains information about a Gaussian cluster found
              during a <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> estimation. Clusters
              are often contained within a <see cref="T:Accord.MachineLearning.GaussianClusterCollection"/>.
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            <seealso cref="T:Accord.MachineLearning.GaussianClusterCollection"/>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.LogLikelihood(System.Double[])">
            <summary>
              Gets the probability density function of the
              underlying Gaussian probability distribution 
              evaluated in point <c>x</c>.
            </summary>
            
            <param name="x">An observation.</param>
            
            <returns>
              The log-probability of <c>x</c> occurring
              in the weighted Gaussian distribution.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Likelihood(System.Double[])">
            <summary>
              Gets the probability density function of the
              underlying Gaussian probability distribution 
              evaluated in point <c>x</c>.
            </summary>
            
            <param name="x">An observation.</param>
            
            <returns>
              The probability of <c>x</c> occurring
              in the weighted Gaussian distribution.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.ToDistribution">
            <summary>
              Gets a copy of the normal distribution associated with this cluster.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Deviance(System.Double[])">
            <summary>
              Gets the deviance of the points in relation to the cluster.
            </summary>
            
            <param name="points">The input points.</param>
            
            <returns>The deviance, measured as -2 * the log-likelihood
            of the input points in this cluster.</returns>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Mean">
            <summary>
              Gets the mean vector associated with this cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Variance">
            <summary>
              Gets the variance vector associated with this cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Covariance">
            <summary>
              Gets the clusters' variance-covariance matrices.
            </summary>
            
            <value>The clusters' variance-covariance matrices.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Coefficient">
            <summary>
              Gets the cluster's coefficient component.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster.Component">
            <summary>
              Gets the component distribution.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianClusterCollection"/> class.
            </summary>
            
            <param name="components">The number of components in the mixture.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Proportions">
            <summary>
            Gets the proportion of samples in each cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Means">
            <summary>
              Gets the mean vectors for the clusters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Variance">
            <summary>
              Gets the variance for each of the clusters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Covariance">
            <summary>
              Gets the covariance matrices for each of the clusters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Model">
            <summary>
              Gets the mixture model represented by this clustering.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.LogLikelihood(System.Double[],System.Int32)">
            <summary>
            Computes the log-likelihood that the given input vector
            belongs to the specified <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <returns>System.Double.</returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Deviance(System.Double[][])">
            <summary>
              Gets the deviance of the points in relation to the model.
            </summary>
            
            <param name="points">The input points.</param>
            
            <returns>The deviance, measured as -2 * the log-likelihood of the input points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.ToMixtureDistribution">
            <summary>
              Gets a copy of the mixture distribution modeled by this Gaussian Mixture Model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(Accord.MachineLearning.KMeans)">
            <summary>
              Initializes the model with initial values obtained 
              through a run of the K-Means clustering algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(Accord.Statistics.Distributions.Univariate.NormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(System.Double[],Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(System.Double[],Accord.Statistics.Distributions.Univariate.NormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(Accord.Statistics.Distributions.Multivariate.MultivariateMixture{Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution})">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Initialize(Accord.Statistics.Distributions.Univariate.Mixture{Accord.Statistics.Distributions.Univariate.NormalDistribution})">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Centroids">
            <summary>
            Gets or sets the clusters' centroids.
            </summary>
            <value>The clusters' centroids.</value>
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Clusters">
            <summary>
            Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            <value>The clusters.</value>
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Distance">
            <summary>
            Gets or sets the distance function used to measure the distance
            between a point and the cluster centroid in this clustering definition.
            </summary>
            <value>The distance.</value>
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Count">
            <summary>
            Gets the number of clusters in the collection.
            </summary>
            <value>The count.</value>
        </member>
        <member name="P:Accord.MachineLearning.GaussianClusterCollection.Item(System.Int32)">
            <summary>
            Gets the <see cref="T:Accord.MachineLearning.GaussianClusterCollection.GaussianCluster"/> at the specified index.
            </summary>
            <param name="index">The index.</param>
            <returns>GaussianCluster.</returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Distortion(System.Double[][],System.Int32[],System.Double[])">
            <summary>
            Calculates the average square distance from the data points
            to the nearest clusters' centroids.
            </summary>
            <param name="data">The data.</param>
            <param name="labels">The labels.</param>
            <param name="weights">The weights.</param>
            <returns>The average square distance from the data points to the nearest
            clusters' centroids.</returns>
            <remarks>The average distance from centroids can be used as a measure
            of the "goodness" of the clustering. The more the data are
            aggregated around the centroids, the less the average distance.</remarks>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Transform(System.Double[][],System.Double[],System.Double[][])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.Transform(System.Double[][],System.Int32[],System.Double[],System.Double[])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianClusterCollection.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="T:Accord.MachineLearning.MeanShiftClusterCollection">
            <summary>
              Mean shift cluster collection.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.MeanShift"/>
            
        </member>
        <member name="T:Accord.MachineLearning.MeanShiftClusterCollection.MeanShiftCluster">
            <summary>
              Mean shift cluster.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.MeanShift"/>
            <seealso cref="T:Accord.MachineLearning.MeanShiftClusterCollection"/>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShiftClusterCollection.Modes">
            <summary>
              Gets the cluster modes.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShiftClusterCollection.#ctor(Accord.MachineLearning.MeanShift,System.Int32,Accord.Collections.KDTree{System.Int32},System.Double[][])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.MeanShiftClusterCollection"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShiftClusterCollection.Decide(System.Double[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.MeanShiftClusterCollection.Distortion(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Calculates the average square distance from the data points 
              to the nearest clusters' centroids.
            </summary>
            
            <remarks>
              The average distance from centroids can be used as a measure
              of the "goodness" of the clustering. The more the data are 
              aggregated around the centroids, the less the average distance.
            </remarks>
            
            <returns>
              The average square distance from the data points to the nearest 
              clusters' centroids.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShiftClusterCollection.Transform(System.Double[][],System.Int32[],System.Double[],System.Double[])">
            <summary>
              Transform data points into feature vectors containing the
              distance between each point and each of the clusters.
            </summary>
            
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            
            <returns>
              A vector containing the distance between the input points and the clusters.
            </returns>
            
            <exception cref="T:System.NotSupportedException"></exception>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShiftClusterCollection.Count">
            <summary>
            Gets the number of clusters in the collection.
            </summary>
            <value>The count.</value>
        </member>
        <member name="P:Accord.MachineLearning.MeanShiftClusterCollection.Clusters">
            <summary>
            Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            <value>The clusters.</value>
        </member>
        <member name="P:Accord.MachineLearning.MeanShiftClusterCollection.Proportions">
            <summary>
            Gets the proportion of samples in each cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShiftClusterCollection.Item(System.Int32)">
            <summary>
            Gets the <see cref="T:Accord.MachineLearning.MeanShiftClusterCollection.MeanShiftCluster"/> at the specified index.
            </summary>
            <param name="index">The index.</param>
            <returns>GaussianCluster.</returns>
        </member>
        <member name="M:Accord.MachineLearning.MeanShiftClusterCollection.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.MeanShiftClusterCollection.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="T:Accord.MachineLearning.KMeansClusterCollection">
            <summary>
              k-Means cluster collection.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            
        </member>
        <member name="T:Accord.MachineLearning.KMeansClusterCollection.KMeansCluster">
            <summary>
              k-Means' cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.KMeansCluster.Covariance">
            <summary>
              Gets the covariance matrix for the samples in this cluster.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.#ctor(System.Int32,Accord.Math.Distances.IDistance{System.Double[]})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.KMeansClusterCollection"/> class.
            </summary>
            
            <param name="k">The number of clusters K.</param>
            <param name="distance">The distance metric to consider.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Dimension">
            <summary>
              Gets the dimensionality of the data space.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Covariances">
            <summary>
              Gets the clusters' variance-covariance matrices.
            </summary>
            
            <value>The clusters' variance-covariance matrices.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Centroids">
            <summary>
              Gets or sets the clusters' centroids.
            </summary>
            
            <value>The clusters' centroids.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Proportions">
            <summary>
            Gets the proportion of samples in each cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Clusters">
            <summary>
            Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            <value>The clusters.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Distance">
            <summary>
            Gets or sets the distance function used to measure the distance
            between a point and the cluster centroid in this clustering definition.
            </summary>
            <value>The distance.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Count">
            <summary>
            Gets the number of clusters in the collection.
            </summary>
            <value>The count.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Item(System.Int32)">
            <summary>
            Gets the <see cref="T:Accord.MachineLearning.KMeansClusterCollection.KMeansCluster"/> at the specified index.
            </summary>
            <param name="index">The index.</param>
            <returns>GaussianCluster.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.Distortion(System.Double[][],System.Int32[],System.Double[])">
            <summary>
            Calculates the average square distance from the data points
            to the nearest clusters' centroids.
            </summary>
            <param name="data">The data.</param>
            <param name="labels">The labels.</param>
            <param name="weights">The weights.</param>
            <returns>The average square distance from the data points to the nearest
            clusters' centroids.</returns>
            <remarks>The average distance from centroids can be used as a measure
            of the "goodness" of the clustering. The more the data are
            aggregated around the centroids, the less the average distance.</remarks>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.Transform(System.Double[][],System.Double[],System.Double[][])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.Transform(System.Double[][],System.Int32[],System.Double[],System.Double[])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.Score(System.Double[],System.Int32)">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <returns>System.Double.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeansClusterCollection.Randomize(System.Double[][],Accord.MachineLearning.Seeding)">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            
            <param name="points">The data to randomize the algorithm.</param>
            <param name="strategy">The seeding strategy to be used. Default is <see cref="F:Accord.MachineLearning.Seeding.KMeansPlusPlus"/>.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.IClusteringAlgorithm`1">
            <summary>
              Common interface for clustering algorithms.
            </summary>
            
            <typeparam name="TData">The type of the data being clustered, such as <see cref="T:double[]"/>.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.KModes`1"/>
            <seealso cref="T:Accord.MachineLearning.BinarySplit"/>
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="M:Accord.MachineLearning.IClusteringAlgorithm`1.Compute(`0[])">
            <summary>
              Divides the input data into a number of clusters. 
            </summary>  
            
            <param name="points">The data where to compute the algorithm.</param>
            
            <returns>
              The labellings for the input data.
            </returns>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusteringAlgorithm`1.Clusters">
            <summary>
              Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.IClusteringAlgorithm`2">
            <summary>
              Common interface for clustering algorithms.
            </summary>
            
            <typeparam name="TData">The type of the data being clustered, such as <see cref="T:double[]"/>.</typeparam>
            <typeparam name="TWeights">The type of the weights associated with each point, such as <see cref="T:double[]"/> or <see cref="T:double[]"/>.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.KModes`1"/>
            <seealso cref="T:Accord.MachineLearning.BinarySplit"/>
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="M:Accord.MachineLearning.IClusteringAlgorithm`2.Compute(`0[],`1[])">
            <summary>
              Divides the input data into a number of clusters. 
            </summary>  
            
            <param name="points">The data where to compute the algorithm.</param>
            <param name="weights">The weight associated with each data point.</param>
            
            <returns>
              The labellings for the input data.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.IClusterCollection`1">
            <summary>
              Common interface for cluster collections.
            </summary>
            
            <typeparam name="TData">The type of the data being clustered, such as <see cref="T:double[]"/>.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusterCollection`1.Count">
            <summary>
              Gets the number of clusters in the collection.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.IClusterCollection`2">
            <summary>
              Common interface for cluster collections.
            </summary>
            
            <typeparam name="TData">The type of the data being clustered, such as <see cref="T:double[]"/>.</typeparam>
            <typeparam name="TCluster">The type of the clusters considered by a clustering algorithm.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.IClusterCollection`2.Item(System.Int32)">
            <summary>
              Gets the cluster at the given index.
            </summary>
            
            <param name="index">The index of the cluster. This should also be the class label of the cluster.</param>
            
            <returns>An object holding information about the selected cluster.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.KModesClusterCollection`1">
            <summary>
              k-Modes cluster collection.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.KModes`1"/>
            
        </member>
        <member name="T:Accord.MachineLearning.KModesClusterCollection`1.KModesCluster">
            <summary>
              k-Modes' cluster.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.KModes`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Dimension">
            <summary>
              Gets the dimensionality of the data space.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.#ctor(System.Int32,Accord.Math.Distances.IDistance{`0[]})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.KModesClusterCollection`1"/> class.
            </summary>
            
            <param name="k">The number of clusters K.</param>
            <param name="distance">The distance metric to use.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Centroids">
            <summary>
            Gets or sets the clusters' centroids.
            </summary>
            <value>The clusters' centroids.</value>
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Distance">
            <summary>
            Gets or sets the distance function used to measure the distance
            between a point and the cluster centroid in this clustering definition.
            </summary>
            <value>The distance.</value>
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Clusters">
            <summary>
            Gets the collection of clusters currently modeled by the clustering algorithm.
            </summary>
            <value>The clusters.</value>
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Proportions">
            <summary>
            Gets the proportion of samples in each cluster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Count">
            <summary>
            Gets the number of clusters in the collection.
            </summary>
            <value>The count.</value>
        </member>
        <member name="P:Accord.MachineLearning.KModesClusterCollection`1.Item(System.Int32)">
            <summary>
            Gets the <see cref="T:Accord.MachineLearning.KModesClusterCollection`1.KModesCluster"/> at the specified index.
            </summary>
            <param name="index">The index.</param>
            <returns>GaussianCluster.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.Randomize(`0[][],Accord.MachineLearning.Seeding)">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            
            <param name="points">The data to randomize the algorithm.</param>
            <param name="strategy">The seeding strategy to be used. Default is <see cref="F:Accord.MachineLearning.Seeding.KMeansPlusPlus"/>.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.Distortion(`0[][],System.Int32[],System.Double[])">
            <summary>
            Calculates the average square distance from the data points
            to the nearest clusters' centroids.
            </summary>
            <param name="data">The data.</param>
            <param name="labels">The labels.</param>
            <param name="weights">The weights.</param>
            <returns>The average square distance from the data points to the nearest
            clusters' centroids.</returns>
            <remarks>The average distance from centroids can be used as a measure
            of the "goodness" of the clustering. The more the data are
            aggregated around the centroids, the less the average distance.</remarks>
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.Transform(`0[][],System.Double[],System.Double[][])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.Transform(`0[][],System.Int32[],System.Double[],System.Double[])">
            <summary>
            Transform data points into feature vectors containing the
            distance between each point and each of the clusters.
            </summary>
            <param name="points">The input points.</param>
            <param name="labels">The label of each input point.</param>
            <param name="weights">The weight associated with each point.</param>
            <param name="result">An optional matrix to store the computed transformation.</param>
            <returns>A vector containing the distance between the input points and the clusters.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through a collection.
            </summary>
            <returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KModesClusterCollection`1.Score(`0[],System.Int32)">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <returns>System.Double.</returns>
        </member>
        <member name="T:Accord.MachineLearning.MeanShift">
            <summary>
              Mean shift clustering algorithm.
            </summary>
            
            <remarks>
            <para>
              Mean shift is a non-parametric feature-space analysis technique originally 
              presented in 1975 by Fukunaga and Hostetler. It is a procedure for locating
              the maxima of a density function given discrete data sampled from that function.
              The method iteratively seeks the location of the modes of the distribution using
              local updates. </para>
            <para>
              As it is, the method would be intractable; however, some clever optimizations such as
              the use of appropriate data structures and seeding strategies as shown in Lee (2011)
              and Carreira-Perpinan (2006) can improve its computational speed.</para> 
            
            <para>
              References:
              <list type="bullet">
                <item><description>
                  Wikipedia, The Free Encyclopedia. Mean-shift. Available on:
                  http://en.wikipedia.org/wiki/Mean-shift </description></item>
                <item><description>
                  Comaniciu, Dorin, and Peter Meer. "Mean shift: A robust approach toward 
                  feature space analysis." Pattern Analysis and Machine Intelligence, IEEE 
                  Transactions on 24.5 (2002): 603-619. Available at:
                  http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1000236 </description></item>
                <item><description>
                  Conrad Lee. Scalable mean-shift clustering in a few lines of python. The
                  Sociograph blog, 2011. Available at: 
                  http://sociograph.blogspot.com.br/2011/11/scalable-mean-shift-clustering-in-few.html </description></item>
                <item><description>
                  Carreira-Perpinan, Miguel A. "Acceleration strategies for Gaussian mean-shift image
                  segmentation." Computer Vision and Pattern Recognition, 2006 IEEE Computer Society 
                  Conference on. Vol. 1. IEEE, 2006. Available at:
                  http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1640881
                </description></item>
              </list></para>
            </remarks>
            
            <example>
            <para>
              The following example demonstrates how to use the Mean Shift algorithm with 
              a <see cref="T:Accord.Statistics.Distributions.DensityKernels.UniformKernel">uniform kernel</see> to solve a clustering task:</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\MeanShiftTest.cs" region="doc_sample1" />
            
            <para>
              The following example demonstrates how to use the Mean Shift algorithm for color clustering. It is the same code which can be
              found in the <a href="https://github.com/accord-net/framework/wiki/Sample-applications#clustering-k-means-and-meanshift">
              color clustering sample application</a>.</para>
              
            <code source="Unit Tests\Accord.Tests.Vision\ColorClusteringTest.cs" region="doc_meanshift" />
            
            <para>
              The original image is shown below:</para>
            
              <img src="..\images\mean-shift-start.png" />
              
            <para>
              The resulting image will be:</para>
            
              <img src="..\images\mean-shift-end.png" />
            
            </example>
                
            <see cref="T:Accord.MachineLearning.KMeans"/>
            <see cref="T:Accord.MachineLearning.KModes`1"/>
            <see cref="T:Accord.MachineLearning.BinarySplit"/>
            <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Clusters">
            <summary>
              Gets the clusters found by Mean Shift.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Distance">
            <summary>
              Gets or sets the <see cref="T:Accord.Math.Distances.IMetric`1"/> used to 
              compute distances between points in the clustering.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Bandwidth">
            <summary>
              Gets or sets the bandwidth (radius, or smoothness)
              parameter to be used in the mean-shift algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Maximum">
            <summary>
              Gets or sets the maximum number of neighbors which should be
              used to determine the direction of the mean-shift during the
              computations. Default is zero (unlimited number of neighbors).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.UseParallelProcessing">
            <summary>
              Gets or sets whether the algorithm can use parallel
              processing to speedup computations. Enabling parallel
              processing can, however, result in different results 
              at each run.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.UseAgglomeration">
            <summary>
              Gets or sets whether to use the agglomeration shortcut,
              meaning the algorithm will stop early when it detects that
              a sample is going to follow the same path as another sample
              when running in parallel.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.UseSeeding">
            <summary>
              Gets or sets whether to use seeding to initialize the algorithm.
              With seeding, new points will be sampled from an uniform grid in
              the range of the input points to be used as seeds. Otherwise, the
              input points themselves will be used as the initial centroids for 
              the algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.ComputeLabels">
            <summary>
              Gets or sets whether cluster labels should be computed
              at the end of the learning iteration. Setting to <c>False</c>
              might save a few computations in case they are not necessary.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.ComputeProportions">
            <summary>
              Gets or sets whether cluster proportions should be computed
              at the end of the learning iteration. Setting to <c>False</c>
              might save a few computations in case they are not necessary.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Dimension">
            <summary>
              Gets the dimension of the samples being 
              modeled by this clustering algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations to
              be performed by the method. If set to zero, no
              iteration limit will be imposed. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Tolerance">
            <summary>
              Gets or sets the relative convergence threshold
              for stopping the algorithm. Default is 1e-3.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.MeanShift.Kernel">
            <summary>
              Gets or sets the density kernel to be used in the algorithm.
              Default is to use the <see cref="T:Accord.Statistics.Distributions.DensityKernels.UniformKernel"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.#ctor">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.MeanShift"/> algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.#ctor(Accord.Statistics.Distributions.DensityKernels.IRadiallySymmetricKernel,System.Double)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.MeanShift"/> algorithm.
            </summary>
            
            <param name="bandwidth">The bandwidth (also known as radius) to consider around samples.</param>
            <param name="kernel">The density kernel function to use.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.#ctor(System.Int32,Accord.Statistics.Distributions.DensityKernels.IRadiallySymmetricKernel,System.Double)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.MeanShift"/> algorithm.
            </summary>
            
            <param name="dimension">The dimension of the samples to be clustered.</param>
            <param name="bandwidth">The bandwidth (also known as radius) to consider around samples.</param>
            <param name="kernel">The density kernel function to use.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.Compute(System.Double[][])">
            <summary>
              Divides the input data into clusters. 
            </summary>     
            
            <param name="points">The data where to compute the algorithm.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.Compute(System.Double[][],System.Int32[])">
            <summary>
              Divides the input data into clusters. 
            </summary>     
            
            <param name="points">The data where to compute the algorithm.</param>
            <param name="weights">The weight associated with each data point.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.Learn(System.Double[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.MeanShift.Learn(System.Double[][],System.Int32[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Clustering.TSNE">
            <summary>
              Barnes-Hutt t-SNE.
            </summary>
            
            <remarks>
            <para>
              The code contained in this class was adapted from Laurens van der Maaten excellent 
              BH T-SNE code from https://github.com/lvdmaaten/bhtsne/. The original license is 
              listed below:</para>
            <code>
               Copyright (c) 2014, Laurens van der Maaten (Delft University of Technology)
               All rights reserved.
              
               Redistribution and use in source and binary forms, with or without
               modification, are permitted provided that the following conditions are met:
               1. Redistributions of source code must retain the above copyright
                  notice, this list of conditions and the following disclaimer.
               2. Redistributions in binary form must reproduce the above copyright
                  notice, this list of conditions and the following disclaimer in the
                  documentation and/or other materials provided with the distribution.
               3. All advertising materials mentioning features or use of this software
                  must display the following acknowledgement:
                  This product includes software developed by the Delft University of Technology.
               4. Neither the name of the Delft University of Technology nor the names of 
                  its contributors may be used to endorse or promote products derived from 
                  this software without specific prior written permission.
              
               THIS SOFTWARE IS PROVIDED BY LAURENS VAN DER MAATEN ''AS IS'' AND ANY EXPRESS
               OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES 
               OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO 
               EVENT SHALL LAURENS VAN DER MAATEN BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, 
               SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
               PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR 
               BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN 
               CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING 
               IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY 
               OF SUCH DAMAGE.
            </code> 
            </remarks>
            
            <example>
            <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\TSNETest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.Clustering.TSNE.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.Clustering.TSNE"/> class.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Clustering.TSNE.Perplexity">
            <summary>
              Gets or sets t-SNE's perplexity value. Default is 50.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Clustering.TSNE.Theta">
            <summary>
              Gets or sets t-SNE's Theta value. Default is 0.5
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Clustering.TSNE.Transform(System.Double[],System.Double[])">
            <summary>
              Not supported.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Clustering.TSNE.Transform(System.Double[][],System.Double[][])">
            <summary>
              Applies the transformation to an input, producing an associated output.
            </summary>
            
            <param name="input">The input data to which the transformation should be applied.</param>
            <param name="result">The location to where to store the result of this transformation.</param>
            <returns>
              The output generated by applying this transformation to the given input.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.BoltzmannExploration">
            <summary>
            Boltzmann distribution exploration policy.
            </summary>
            
            <remarks><para>The class implements exploration policy base on Boltzmann distribution.
            Acording to the policy, action <b>a</b> at state <b>s</b> is selected with the next probability:</para>
            <code lang="none">
                              exp( Q( s, a ) / t )
            p( s, a ) = -----------------------------
                         SUM( exp( Q( s, b ) / t ) )
                          b
            </code>
            <para>where <b>Q(s, a)</b> is action's <b>a</b> estimation (usefulness) at state <b>s</b> and
            <b>t</b> is <see cref="P:Accord.MachineLearning.BoltzmannExploration.Temperature"/>.</para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.RouletteWheelExploration"/>
            <seealso cref="T:Accord.MachineLearning.EpsilonGreedyExploration"/>
            <seealso cref="T:Accord.MachineLearning.TabuSearchExploration"/>
            
        </member>
        <member name="P:Accord.MachineLearning.BoltzmannExploration.Temperature">
            <summary>
              Temperature parameter of Boltzmann distribution. Should be greater than 0.
            </summary>
            
            <remarks><para>The property sets the balance between exploration and greedy actions.
            If temperature is low, then the policy tends to be more greedy.</para></remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.BoltzmannExploration.#ctor(System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.BoltzmannExploration"/> class.
            </summary>
            
            <param name="temperature">Temperature parameter of Boltzmann distribution.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BoltzmannExploration.ChooseAction(System.Double[])">
            <summary>
            Choose an action.
            </summary>
            
            <param name="actionEstimates">Action estimates.</param>
            
            <returns>Returns selected action.</returns>
            
            <remarks>The method chooses an action depending on the provided estimates. The
            estimates can be any sort of estimate, which values usefulness of the action
            (expected summary reward, discounted reward, etc).</remarks>
            
        </member>
        <member name="T:Accord.MachineLearning.EpsilonGreedyExploration">
            <summary>
            Epsilon greedy exploration policy.
            </summary>
            
            <remarks><para>The class implements epsilon greedy exploration policy. According to the policy,
            the best action is chosen with probability <b>1-epsilon</b>. Otherwise,
            with probability <b>epsilon</b>, any other action, except the best one, is
            chosen randomly.</para>
            
            <para>According to the policy, the epsilon value is known also as exploration rate.</para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.RouletteWheelExploration"/>
            <seealso cref="T:Accord.MachineLearning.BoltzmannExploration"/>
            <seealso cref="T:Accord.MachineLearning.TabuSearchExploration"/>
            
        </member>
        <member name="P:Accord.MachineLearning.EpsilonGreedyExploration.Epsilon">
            <summary>
            Epsilon value (exploration rate), [0, 1].
            </summary>
            
            <remarks><para>The value determines the amount of exploration driven by the policy.
            If the value is high, then the policy drives more to exploration - choosing random
            action, which excludes the best one. If the value is low, then the policy is more
            greedy - choosing the beat so far action.
            </para></remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.EpsilonGreedyExploration.#ctor(System.Double)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.EpsilonGreedyExploration"/> class.
            </summary>
            
            <param name="epsilon">Epsilon value (exploration rate).</param>
            
        </member>
        <member name="M:Accord.MachineLearning.EpsilonGreedyExploration.ChooseAction(System.Double[])">
            <summary>
            Choose an action.
            </summary>
            
            <param name="actionEstimates">Action estimates.</param>
            
            <returns>Returns selected action.</returns>
            
            <remarks>The method chooses an action depending on the provided estimates. The
            estimates can be any sort of estimate, which values usefulness of the action
            (expected summary reward, discounted reward, etc).</remarks>
            
        </member>
        <member name="T:Accord.MachineLearning.IExplorationPolicy">
            <summary>
            Exploration policy interface.
            </summary>
            
            <remarks>The interface describes exploration policies, which are used in Reinforcement
            Learning to explore state space.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.IExplorationPolicy.ChooseAction(System.Double[])">
            <summary>
            Choose an action.
            </summary>
            
            <param name="actionEstimates">Action estimates.</param>
            
            <returns>Returns selected action.</returns>
            
            <remarks>The method chooses an action depending on the provided estimates. The
            estimates can be any sort of estimate, which values usefulness of the action
            (expected summary reward, discounted reward, etc).</remarks>
            
        </member>
        <member name="T:Accord.MachineLearning.RouletteWheelExploration">
            <summary>
            Roulette wheel exploration policy.
            </summary>
            
            <remarks><para>The class implements roulette whell exploration policy. Acording to the policy,
            action <b>a</b> at state <b>s</b> is selected with the next probability:</para>
            <code lang="none">
                              Q( s, a )
            p( s, a ) = ------------------
                         SUM( Q( s, b ) )
                          b
            </code>
            <para>where <b>Q(s, a)</b> is action's <b>a</b> estimation (usefulness) at state <b>s</b>.</para>
            
            <para><note>The exploration policy may be applied only in cases, when action estimates (usefulness)
            are represented with positive value greater then 0.</note></para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.BoltzmannExploration"/>
            <seealso cref="T:Accord.MachineLearning.EpsilonGreedyExploration"/>
            <seealso cref="T:Accord.MachineLearning.TabuSearchExploration"/>
            
        </member>
        <member name="M:Accord.MachineLearning.RouletteWheelExploration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.RouletteWheelExploration"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.RouletteWheelExploration.ChooseAction(System.Double[])">
            <summary>
            Choose an action.
            </summary>
            
            <param name="actionEstimates">Action estimates.</param>
            
            <returns>Returns selected action.</returns>
            
            <remarks>The method chooses an action depending on the provided estimates. The
            estimates can be any sort of estimate, which values usefulness of the action
            (expected summary reward, discounted reward, etc).</remarks>
            
        </member>
        <member name="T:Accord.MachineLearning.TabuSearchExploration">
            <summary>
            Tabu search exploration policy.
            </summary>
            
            <remarks>The class implements simple tabu search exploration policy,
            allowing to set certain actions as tabu for a specified amount of
            iterations. The actual exploration and choosing from non-tabu actions
            is done by <see cref="P:Accord.MachineLearning.TabuSearchExploration.BasePolicy">base exploration policy</see>.</remarks>
            
            <seealso cref="T:Accord.MachineLearning.BoltzmannExploration"/>
            <seealso cref="T:Accord.MachineLearning.EpsilonGreedyExploration"/>
            <seealso cref="T:Accord.MachineLearning.RouletteWheelExploration"/>
            
        </member>
        <member name="P:Accord.MachineLearning.TabuSearchExploration.BasePolicy">
            <summary>
            Base exploration policy.
            </summary>
            
            <remarks>Base exploration policy is the policy, which is used
            to choose from non-tabu actions.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.TabuSearchExploration.#ctor(System.Int32,Accord.MachineLearning.IExplorationPolicy)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.TabuSearchExploration"/> class.
            </summary>
            
            <param name="actions">Total actions count.</param>
            <param name="basePolicy">Base exploration policy.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.TabuSearchExploration.ChooseAction(System.Double[])">
            <summary>
            Choose an action.
            </summary>
            
            <param name="actionEstimates">Action estimates.</param>
            
            <returns>Returns selected action.</returns>
            
            <remarks>The method chooses an action depending on the provided estimates. The
            estimates can be any sort of estimate, which values usefulness of the action
            (expected summary reward, discounted reward, etc). The action is choosed from
            non-tabu actions only.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.TabuSearchExploration.ResetTabuList">
            <summary>
            Reset tabu list.
            </summary>
            
            <remarks>Clears tabu list making all actions allowed.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.TabuSearchExploration.SetTabuAction(System.Int32,System.Int32)">
            <summary>
            Set tabu action.
            </summary>
            
            <param name="action">Action to set tabu for.</param>
            <param name="tabuTime">Tabu time in iterations.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Geometry.RansacCircle">
            <summary>
              Robust circle estimator with RANSAC.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Geometry.RansacCircle.Ransac">
            <summary>
              Gets the RANSAC estimator used.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Geometry.RansacCircle.Inliers">
            <summary>
              Gets the final set of inliers detected by RANSAC.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacCircle.#ctor(System.Double,System.Double)">
            <summary>
              Creates a new RANSAC 2D circle estimator.
            </summary>
            
            <param name="threshold">Inlier threshold.</param>
            <param name="probability">Inlier probability.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacCircle.Estimate(System.Collections.Generic.IEnumerable{Accord.IntPoint})">
            <summary>
              Produces a robust estimation of the circle
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The circle passing through the points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacCircle.Estimate(System.Collections.Generic.IEnumerable{Accord.Point})">
            <summary>
              Produces a robust estimation of the circle
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The circle passing through the points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacCircle.Estimate(Accord.IntPoint[])">
            <summary>
              Produces a robust estimation of the circle
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The circle passing through the points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacCircle.Estimate(Accord.Point[])">
            <summary>
              Produces a robust estimation of the circle
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The circle passing through the points.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Geometry.RansacLine">
            <summary>
              Robust line estimator with RANSAC.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Geometry.RansacLine.Ransac">
            <summary>
              Gets the RANSAC estimator used.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Geometry.RansacLine.Inliers">
            <summary>
              Gets the final set of inliers detected by RANSAC.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacLine.#ctor(System.Double,System.Double)">
            <summary>
              Creates a new RANSAC line estimator.
            </summary>
            
            <param name="threshold">Inlier threshold.</param>
            <param name="probability">Inlier probability.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacLine.Estimate(System.Collections.Generic.IEnumerable{Accord.IntPoint})">
            <summary>
              Produces a robust estimation of the line
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The line passing through the points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacLine.Estimate(System.Collections.Generic.IEnumerable{Accord.Point})">
            <summary>
              Produces a robust estimation of the line
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The line passing through the points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacLine.Estimate(Accord.IntPoint[])">
            <summary>
              Produces a robust estimation of the line
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The line passing through the points.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacLine.Estimate(Accord.Point[])">
            <summary>
              Produces a robust estimation of the line
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The line passing through the points.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.Geometry.RansacPlane">
            <summary>
              Robust plane estimator with RANSAC.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Geometry.RansacPlane.Ransac">
            <summary>
              Gets the RANSAC estimator used.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Geometry.RansacPlane.Inliers">
            <summary>
              Gets the final set of inliers detected by RANSAC.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacPlane.#ctor(System.Double,System.Double)">
            <summary>
              Creates a new RANSAC 3D plane estimator.
            </summary>
            
            <param name="threshold">Inlier threshold.</param>
            <param name="probability">Inlier probability.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Geometry.RansacPlane.Estimate(Accord.Math.Point3[])">
            <summary>
              Produces a robust estimation of the plane
              passing through the given (noisy) points.
            </summary>
            
            <param name="points">A set of (possibly noisy) points.</param>
            
            <returns>The plane passing through the points.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.KNearestNeighbors`1">
            <summary>
              K-Nearest Neighbor (k-NN) algorithm.
            </summary>
            
            <typeparam name="TInput">The type of the input data.</typeparam>
            
            <remarks>
            <para> The k-nearest neighbor algorithm (k-NN) is a method for classifying objects
              based on closest training examples in the feature space. It is amongst the simplest
              of all machine learning algorithms: an object is classified by a majority vote of
              its neighbors, with the object being assigned to the class most common amongst its 
              k nearest neighbors (k is a positive integer, typically small).</para>
              
            <para>If k = 1, then the object is simply assigned to the class of its nearest neighbor.</para>
            
            <para>
              References:
              <list type="bullet">
                <item><description>
                  Wikipedia contributors. "K-nearest neighbor algorithm." Wikipedia, The
                  Free Encyclopedia. Wikipedia, The Free Encyclopedia, 10 Oct. 2012. Web.
                  9 Nov. 2012. http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm </description></item>
              </list>
            </para>
            </remarks>
            
            <example>
            <para>
              The first example shows how to create and use a k-Nearest Neighbor algorithm to classify
              a set of numeric vectors in a multi-class decision problem involving 3 classes. It also shows
              how to compute class decisions for a new sample and how to measure the performance of a classifier.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_learn" />
            <code source="Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_serialization" />
            
            <para>
              The second example show how to use a different distance metric when computing k-NN:</para>
              <code source = "Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_learn_distance" />
            
            <para>
              The k-Nearest neighbor algorithm implementation in the framework can also be used with any instance 
              data type. For such cases, the framework offers a generic version of the classifier. The third example
              shows how to use the generic kNN classifier to perform the direct classification of actual text samples:</para>
            <code source = "Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_learn_text" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.KNearestNeighbors"/>
            
        </member>
        <member name="P:Accord.MachineLearning.KNearestNeighbors`1.ParallelOptions">
            <summary>
              Gets or sets the parallelization options for this algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.#ctor">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.#ctor(System.Int32,Accord.Math.Distances.IDistance{`0})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.Scores(`0,System.Double[])">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and each class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the result will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns>System.Double[].</returns>
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.Scores(`0[],System.Double[][])">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and each class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the scores will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns>System.Double[][].</returns>
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.GetNearestNeighbors(`0,System.Int32[]@)">
            <summary>
              Gets the top <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K"/> points
              that are the closest to a given <paramref name="input"> reference point</paramref>.
            </summary>
            
            <param name="input">The query point whose neighbors will be found.</param>
            <param name="labels">The label for each neighboring point.</param>
            
            <returns>
              An array containing the top <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K"/> points that are 
              at the closest possible distance to <paramref name="input"/>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.Learn(`0[],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.#ctor(System.Int32,`0[],System.Int32[],Accord.Math.Distances.IDistance{`0})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
            <param name="k">The number of nearest neighbors to be used in the decision.</param>
            
            <param name="inputs">The input data points.</param>
            <param name="outputs">The associated labels for the input points.</param>
            <param name="distance">The distance measure to use in the decision.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.#ctor(System.Int32,System.Int32,`0[],System.Int32[],Accord.Math.Distances.IDistance{`0})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
            <param name="k">The number of nearest neighbors to be used in the decision.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            
            <param name="inputs">The input data points.</param>
            <param name="outputs">The associated labels for the input points.</param>
            <param name="distance">The distance measure to use in the decision.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.KNearestNeighbors`1.ClassCount">
            <summary>
              Gets the number of class labels
              handled by this classifier.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.Compute(`0)">
            <summary>
              Computes the most likely label of a new given point.
            </summary>
            
            <param name="input">A point to be classified.</param>
            
            <returns>The most likely label for the given point.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.Compute(`0,System.Double@)">
            <summary>
              Computes the most likely label of a new given point.
            </summary>
            
            <param name="input">A point to be classified.</param>
            <param name="response">A value between 0 and 1 giving 
            the strength of the classification in relation to the
            other classes.</param>
            
            <returns>The most likely label for the given point.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors`1.Compute(`0,System.Double[]@)">
            <summary>
              Computes the most likely label of a new given point.
            </summary>
            
            <param name="input">A point to be classified.</param>
            <param name="scores">The distance score for each possible class.</param>
            
            <returns>The most likely label for the given point.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.ClassPair">
            <summary>
              Pair of class labels.
            </summary>
            
            <remarks>
              The <see cref="T:Accord.MachineLearning.Decision"/> structure is the equivalent of a <see cref="T:Accord.Compat.Tuple`2"/>
              where the tuple elements are called <see cref="P:Accord.MachineLearning.ClassPair.Class1"/> and <see cref="P:Accord.MachineLearning.ClassPair.Class2"/> instead of
              <see cref="P:Accord.Compat.Tuple`2.Item1"/> and <see cref="P:Accord.Compat.Tuple`2.Item2"/>. It is
              mainly used to index or provide access to individual binary models within a <see cref="T:Accord.MachineLearning.OneVsOne`1"/>
              (i.e. through <see cref="P:Accord.MachineLearning.OneVsOne`2.Indices"/> and 
              <see cref="M:Accord.MachineLearning.OneVsOne`2.GetEnumerator"/>) and in the definition of the
              <see cref="T:Accord.MachineLearning.Decision"/> structure.
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.Decision"/>
            <seealso cref="T:Accord.MachineLearning.OneVsOneLearning`2"/>
            <seealso cref="T:Accord.MachineLearning.OneVsRestLearning`2"/>
            
        </member>
        <member name="P:Accord.MachineLearning.ClassPair.Class1">
            <summary>
              Gets the first class in the pair.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.ClassPair.Class2">
            <summary>
              Gets the second class in the pair.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.ClassPair.#ctor(System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.ClassPair"/> struct.
            </summary>
            <param name="i">The first class index in the pair.</param>
            <param name="j">The second class index in the pair.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.ClassPair.ToTuple">
            <summary>
              Converts to a tuple (class_a, class_b).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.ClassPair.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.ClassPair.Equals(Accord.MachineLearning.ClassPair)">
            <summary>
            Indicates whether the current object is equal to another object of the same type.
            </summary>
            <param name="other">An object to compare with this object.</param>
            <returns>true if the current object is equal to the <paramref name="other" /> parameter; otherwise, false.</returns>
        </member>
        <member name="M:Accord.MachineLearning.ClassPair.Equals(System.Object)">
            <summary>
            Determines whether the specified <see cref="T:System.Object" /> is equal to this instance.
            </summary>
            <param name="obj">The object to compare with the current instance.</param>
            <returns><c>true</c> if the specified <see cref="T:System.Object" /> is equal to this instance; otherwise, <c>false</c>.</returns>
        </member>
        <member name="M:Accord.MachineLearning.ClassPair.GetHashCode">
            <summary>
            Returns a hash code for this instance.
            </summary>
            <returns>A hash code for this instance, suitable for use in hashing algorithms and data structures like a hash table.</returns>
        </member>
        <member name="T:Accord.MachineLearning.Decision">
            <summary>
              Decision between two class labels. Indicates the class index of the first 
              class, the class index of the adversary, and the class index of the winner.
            </summary>
            
            <remarks>
            <para>
              The <see cref="T:Accord.MachineLearning.Decision"/> structure is used to represent the outcome of a binary classifier for the 
              problem of deciding between two classes. For example, let's say we would like to represent that, given
              the problem of deciding between class #4 and class #2, a binary classsifier has opted for deciding that 
              class #2 was more likely than class #4. This could be represented by a <see cref="T:Accord.MachineLearning.Decision"/> structure 
              by instantiating it using <c>Decision(i: 4, j: 2, winner: 2)</c>.</para>
            </remarks>
            
            <example>
              <para>The <see cref="T:Accord.MachineLearning.Decision"/> structure is more likely to be used or found when dealing with strategies 
              for creating multi-class and/or multi-label classifiers using a set of binary classifiers, such as when using 
              <see cref="T:Accord.MachineLearning.OneVsOne`2"/> and <see cref="T:Accord.MachineLearning.OneVsRest`2"/>. In the example below, we 
              will extract the sequence of binary classification problems and their respective decisions when evaluating a 
              multi-class SVM using the one-vs-one decision strategy for multi-class problems:</para>
            
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_decision_path" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.ClassPair"/>
            <seealso cref="T:Accord.MachineLearning.OneVsOne`2"/>
            <seealso cref="T:Accord.MachineLearning.OneVsRest`2"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Decision.Pair">
            <summary>
              Gets the adversarial classes.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Decision.Winner">
            <summary>
              Gets the class label of the winner.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Decision.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Decision"/> struct.
            </summary>
            <param name="i">The first class index.</param>
            <param name="j">The second class index.</param>
            <param name="winner">The class index that won.</param>
        </member>
        <member name="M:Accord.MachineLearning.Decision.ToTuple">
            <summary>
              Converts to a triplet (class_a, class_b, winner).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Decision.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.InnerParameters`2">
            <summary>
              Parameters for learning a binary decision model. An object of this class is passed by
              <see cref="T:Accord.MachineLearning.OneVsRestLearning`2"/> or <see cref="T:Accord.MachineLearning.OneVsOneLearning`2"/> 
              to instruct how binary learning algorithms should create their binary classifiers.
            </summary>
            
            <typeparam name="TBinary">The type of the binary model to be learned.</typeparam>
            <typeparam name="TInput">The input type for the binary classifiers.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.InnerParameters`2.Model">
            <summary>
              Gets or sets the binary model to be learned.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.InnerParameters`2.Inputs">
            <summary>
              Gets or sets the input data that should be used to train the classifier.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.InnerParameters`2.Outputs">
            <summary>
              Gets or sets the output data that should be used to train the classifier.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.InnerParameters`2.Pair">
            <summary>
              Gets or sets the class pair that the classifier will be designated
              to learn. For <see cref="T:Accord.MachineLearning.OneVsRest`2"/> classifiers, the first element
              in the pair designates the class to be learned against all others.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.InnerParameters`2.#ctor(`0,`1[],System.Boolean[],Accord.MachineLearning.ClassPair)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.InnerParameters`2"/> class.
            </summary>
            
            <param name="model">The binary model to be learned.</param>
            <param name="inputs">The inputs to be used.</param>
            <param name="outputs">The outputs to be used.</param>
            <param name="pair">The class labels for the problem to be learned.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsRestLearning`2">
            <summary>
              Base learning algorithm for <see cref="T:Accord.MachineLearning.OneVsRest`2"/> multi-class classifiers.
            </summary>
            
            <typeparam name="TBinary">The type for the inner binary classifiers used in the one-vs-rest approach.</typeparam>
            <typeparam name="TModel">The type of the model being learned.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsRestLearning`3">
             <summary>
               Base learning algorithm for <see cref="T:Accord.MachineLearning.OneVsRest`2"/> multi-class classifiers.
             </summary>
             
             <typeparam name="TInput">The type for the samples handled by the classifier. Default is double[].</typeparam>
             <typeparam name="TBinary">The type for the inner binary classifiers used in the one-vs-rest approach.</typeparam>
             <typeparam name="TModel">The type of the model being learned.</typeparam>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRestLearning`3.Model">
            <summary>
              Gets or sets the model being learned.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRestLearning`3.Learner">
            <summary>
              Gets or sets a function that takes a set of parameters and creates
              a learning algorithm for learning each of the binary inner classifiers
              needed by the one-vs-rest classification strategy.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRestLearning`3.AggregateExceptions">
            <summary>
              Gets or sets a value indicating whether the entire training algorithm should stop
              in case an exception has been detected at just one of the inner binary learning
              problems. Default is true (execution will not be stopped).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRestLearning`3.IsMultilabel">
            <summary>
              Gets or sets a value indicating whether the learning algorithm should generate multi-label
              (as opposed to multi-class) models. If left unspecified, the type of the model will be determined
              automatically depending on which overload of the <see cref="M:Accord.MachineLearning.OneVsRestLearning`3.Learn(`0[],System.Boolean[][],System.Double[])"/>
              method will be called first by the executing code.
            </summary>
            
        </member>
        <member name="E:Accord.MachineLearning.OneVsRestLearning`3.SubproblemStarted">
            <summary>
              Occurs when the learning of a subproblem has started.
            </summary>
            
        </member>
        <member name="E:Accord.MachineLearning.OneVsRestLearning`3.SubproblemFinished">
            <summary>
              Occurs when the learning of a subproblem has finished.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.OneVsRestLearning`3"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.Configure``2(System.Func{``0,``1})">
            <summary>
              Sets a callback function that takes a set of parameters and creates
              a learning algorithm for learning each of the binary inner classifiers
              needed by the one-vs-rest classification strategy. Calling this method
              sets the <see cref="P:Accord.MachineLearning.OneVsRestLearning`3.Learner"/> property.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.Configure``1(System.Func{``0})">
            <summary>
              Sets a callback function that takes a set of parameters and creates
              a learning algorithm for learning each of the binary inner classifiers
              needed by the one-vs-rest classification strategy. Calling this method
              sets the <see cref="P:Accord.MachineLearning.OneVsRestLearning`3.Learner"/> property.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.Create(System.Int32,System.Int32,System.Boolean)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.Learn(`0[],System.Int32[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.Learn(`0[],System.Int32[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.Learn(`0[],System.Boolean[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.OnSubproblemFinished(Accord.MachineLearning.SubproblemEventArgs)">
            <summary>
              Raises the <see cref="E:SubproblemFinished"/> event.
            </summary>
            
            <param name="args">The <see cref="T:Accord.MachineLearning.SubproblemEventArgs"/> instance containing the event data.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRestLearning`3.OnSubproblemStarted(Accord.MachineLearning.SubproblemEventArgs)">
            <summary>
              Raises the <see cref="E:SubproblemStarted"/> event.
            </summary>
            
            <param name="args">The <see cref="T:Accord.MachineLearning.SubproblemEventArgs"/> instance containing the event data.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsOneLearning`2">
            <summary>
              Base learning algorithm for <see cref="T:Accord.MachineLearning.OneVsOne`2"/> multi-class classifiers.
            </summary>
            
            <typeparam name="TBinary">The type for the inner binary classifiers used in the one-vs-one approach.</typeparam>
            <typeparam name="TModel">The type of the model being learned.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsOneLearning`3">
            <summary>
              Base learning algorithm for <see cref="T:Accord.MachineLearning.OneVsOne`2"/> multi-class classifiers.
            </summary>
            
            <typeparam name="TInput">The type for the samples handled by the classifier. Default is double[].</typeparam>
            <typeparam name="TBinary">The type for the inner binary classifiers used in the one-vs-one approach.</typeparam>
            <typeparam name="TModel">The type of the model being learned.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOneLearning`3.Model">
            <summary>
              Gets or sets the model being learned.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOneLearning`3.Learner">
            <summary>
              Gets or sets a function that takes a set of parameters and creates
              a learning algorithm for learning each of the binary inner classifiers
              needed by the one-vs-one classification strategy.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOneLearning`3.AggregateExceptions">
            <summary>
              Gets or sets a value indicating whether the entire training algorithm should stop
              in case an exception has been detected at just one of the inner binary learning
              problems. Default is true (execution will not be stopped).
            </summary>
            
        </member>
        <member name="E:Accord.MachineLearning.OneVsOneLearning`3.SubproblemStarted">
            <summary>
              Occurs when the learning of a subproblem has started.
            </summary>
            
        </member>
        <member name="E:Accord.MachineLearning.OneVsOneLearning`3.SubproblemFinished">
            <summary>
              Occurs when the learning of a subproblem has finished.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOneLearning`3.Create(System.Int32,System.Int32)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOneLearning`3.Configure``2(System.Func{``0,``1})">
            <summary>
              Sets a callback function that takes a set of parameters and creates
              a learning algorithm for learning each of the binary inner classifiers
              needed by the one-vs-rest classification strategy. Calling this method
              sets the <see cref="P:Accord.MachineLearning.OneVsOneLearning`3.Learner"/> property.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOneLearning`3.Configure``1(System.Func{``0})">
            <summary>
              Sets a callback function that takes a set of parameters and creates
              a learning algorithm for learning each of the binary inner classifiers
              needed by the one-vs-rest classification strategy. Calling this method
              sets the <see cref="P:Accord.MachineLearning.OneVsOneLearning`3.Learner"/> property.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOneLearning`3.Learn(`0[],System.Int32[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsOneLearning`3.OnSubproblemFinished(Accord.MachineLearning.SubproblemEventArgs)">
            <summary>
              Raises the <see cref="E:SubproblemFinished"/> event.
            </summary>
            
            <param name="args">The <see cref="T:Accord.MachineLearning.SubproblemEventArgs"/> instance containing the event data.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOneLearning`3.OnSubproblemStarted(Accord.MachineLearning.SubproblemEventArgs)">
            <summary>
              Raises the <see cref="E:SubproblemStarted"/> event.
            </summary>
            
            <param name="args">The <see cref="T:Accord.MachineLearning.SubproblemEventArgs"/> instance containing the event data.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.SubproblemEventArgs">
            <summary>
              Subproblem progress event argument.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SubproblemEventArgs.Class1">
            <summary>
              One of the classes belonging to the subproblem.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SubproblemEventArgs.Class2">
            <summary>
             One of the classes belonging to the subproblem.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SubproblemEventArgs.Progress">
            <summary>
              Gets the progress of the overall problem,
              ranging from zero up to <see cref="P:Accord.MachineLearning.SubproblemEventArgs.Maximum"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SubproblemEventArgs.Maximum">
            <summary>
              Gets the maximum value for the current <see cref="P:Accord.MachineLearning.SubproblemEventArgs.Progress"/>.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.SubproblemEventArgs.#ctor(System.Int32,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.SubproblemEventArgs"/> class.
            </summary>
            
            <param name="class1">One of the classes in the subproblem.</param>
            <param name="class2">The other class in the subproblem.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsRest`2">
            <summary>
              Base class for multi-class classifiers based on the 
              "one-vs-rest" construction based on binary classifiers.
            </summary>
            
            <typeparam name="TModel">The type for the inner binary classifiers.</typeparam>
            <typeparam name="TInput">The input type handled by the classifiers. Default is double.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.#ctor(System.Int32,System.Func{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.OneVsRest`2"/> class.
            </summary>
            
            <param name="classes">The number of classes in the multi-label classification problem.</param>
            <param name="initializer">A function to create the inner binary classifiers.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.GetClassifierForClass(System.Int32)">
            <summary>
              Gets the binary classifier for particular class index.
            </summary>
            
            <param name="classIndex">Index of the class.</param>
            
            <returns>
              A <see cref="T:Accord.MachineLearning.IBinaryClassifier`1"/> that has been trained
              to distinguish between the chosen class and all other classes.
            </returns>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRest`2.Item(System.Int32)">
            <summary>
              Gets or sets the inner binary classifiers used to distinguish
              between each class and all other classes.
            </summary>
            
            <param name="classIndex">The classifier index.</param>
            
            <returns>
              A <see cref="T:Accord.MachineLearning.IBinaryClassifier`1"/> that has been trained
              to distinguish between the chosen class and all other classes.
            </returns>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRest`2.Models">
            <summary>
              Gets or sets the binary classifiers that have been trained
              to distinguish between each class and all other classes.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsRest`2.Count">
            <summary>
              Gets the total number of binary models in this one-vs-rest 
              multi-label configuration. Should be equal to the 
              <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs"/> (number of classes).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.Score(`1,System.Int32,System.Boolean@)">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <param name="decision">The class label associated with the input
            vector, as predicted by the classifier.</param>
            <returns></returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.Decide(`1,System.Int32)">
            <summary>
            Computes whether a class label applies to an <paramref name="input" /> vector.
            </summary>
            <param name="input">The input vectors that should be classified as
            any of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="classIndex">The class label index to be tested.</param>
            <returns>
            A boolean value indicating whether the given <paramref name="classIndex">
            class label</paramref> applies to the <paramref name="input" /> vector.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.LogLikelihood(`1,System.Int32,System.Boolean@)">
            <summary>
            Computes a log-likelihood measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <param name="decision">The class label associated with the input
            vector, as predicted by the classifier.</param>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>
            A <see cref="T:System.Collections.Generic.IEnumerator`1" /> that can be used to iterate through the collection.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`2.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Returns an enumerator that iterates through the collection.
            </summary>
            <returns>
            A <see cref="T:System.Collections.Generic.IEnumerator`1" /> that can be used to iterate through the collection.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.OneVsRest`1">
            <summary>
              Base class for multi-class classifiers based on the 
              "one-vs-rest" construction based on binary classifiers.
            </summary>
            
            <typeparam name="TModel">The type for the inner binary classifiers.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsRest`1.#ctor(System.Int32,System.Func{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.OneVsRest`1"/> class.
            </summary>
            
            <param name="classes">The number of classes in the multi-label classification problem.</param>
            <param name="initializer">A function to create the inner binary classifiers.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod">
            <summary>
              Decision strategies for <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1">
              Multi-class Support Vector Machines</see>.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod.Voting">
            <summary>
              Max-voting method (also known as 1-vs-1 decision).
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod.Elimination">
            <summary>
              Elimination method (also known as DAG decision).
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.NamespaceDoc">
            <summary>
             Contains classes related to <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">Support Vector Machines</see> (SVMs). 
             Contains <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">linear machines</see>, <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">
             kernel machines</see>, <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1">multi-class machines</see>, SVM-DAGs 
             (Directed Acyclic Graphs), <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1">multi-label classification</see>
             and also offers support for the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration">probabilistic output calibration
             </see> of SVM outputs.
            </summary>
            
            <remarks>
            <para>
              This namespace contains both standard <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>s and the
              kernel extension given by <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1"/>s. For multiple
              classes or categories, the framework offers <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              and <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/>s. Multi-class machines can be used for
              cases where a single class should be picked up from a list of several class labels, and
              the multi-label machine for cases where multiple class labels might be detected for a 
              single input vector. The multi-class machines also support two types of classification:
              the faster decision based on Decision Directed Acyclic Graphs, and the more traditional
              based on a Voting scheme.</para>
              
            <para>
              Learning can be achieved using the standard <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
              (SMO) algorithm. However, the framework can also learn Least Squares SVMs (LS-SVMs) using <see 
              cref="T:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning"/>, and even calibrate SVMs to produce probabilistic outputs
              using <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>. A <see cref="N:Accord.Statistics.Kernels">
              huge variety of kernels functions is available in the statistics namespace</see>, and
              new kernels can be created easily using the <see cref="T:Accord.Statistics.Kernels.IKernel"/> interface.</para>
              
            <para>
              The namespace class diagram is shown below. </para>
              <img src="..\diagrams\classes\Accord.MachineLearning.VectorMachines.png" />
              
            <para>
              Please note that class diagrams for each of the inner namespaces are 
              also available within their own documentation pages.</para>
            </remarks>
            
            <seealso cref="N:Accord.MachineLearning.VectorMachines.Learning"/>
            <seealso cref="N:Accord.Statistics.Kernels"/>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1">
            <summary>
              Common interface for binary support vector machines.
            </summary>
            
            <typeparam name="TInput">The type of the input data handled by the machine.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1.Weights">
             <summary>
               Gets or sets the collection of weights used by this machine.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1.SupportVectors">
             <summary>
               Gets or sets the collection of support vectors used by this machine.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1.Threshold">
             <summary>
               Gets or sets the threshold (bias) term for this machine.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1.Kernel">
            <summary>
              Gets or sets the kernel used by this machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1.IsProbabilistic">
            <summary>
              Gets whether this machine has been calibrated to
              produce probabilistic outputs (through the Probability
              method).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.ISupportVectorMachine`1.Compress">
            <summary>
              If this machine has a linear kernel, compresses all
              support vectors into a single parameter vector.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.#ctor(Accord.Statistics.Kernels.IKernel{System.Double[]},System.Int32)">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.#ctor(Accord.Statistics.Kernels.IKernel,System.Int32)">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.Kernel">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.Clone">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3">
            <summary>
              Base class for <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> calibration algorithms.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Token">
            <summary>
            Gets or sets a cancellation token that can be used to
            stop the learning algorithm while it is running.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Input">
            <summary>
              Gets or sets the input vectors for training.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Output">
            <summary>
              Gets or sets the output labels for each training vector.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.#ctor(`0)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3"/> class.
            </summary>
            <param name="machine">The machine to be calibrated.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Create(System.Int32,`1)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3"/> class.
            </summary>
            <param name="machine">The machine to be calibrated.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3"/> class.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.IsLinear">
            <summary>
              Gets whether the machine being learned is linear.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Kernel">
            <summary>
              Gets the machine's <see cref="T:Accord.Statistics.Kernels.IKernel"/> function.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Model">
            <summary>
              Gets the machine to be taught.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Learn(`2[],System.Double[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Learn(`2[],System.Int32[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Learn(`2[],System.Int32[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Learn(`2[],System.Boolean[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Learn(`2[],System.Boolean[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorCalibration`3.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3">
            <summary>
              Base class for <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithms.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Inputs">
            <summary>
              Gets or sets the input vectors for training.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Outputs">
            <summary>
              Gets or sets the output labels for each training vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Complexity">
            <summary>
              Complexity (cost) parameter C. Increasing the value of C forces the creation
              of a more accurate model that may not generalize well. If this value is not
              set and <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseComplexityHeuristic"/> is set to <c>true</c>, the framework
              will automatically guess a value for <c>C</c>. If this value is manually set to 
              something else, then <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseComplexityHeuristic"/> will be automatically 
              disabled and the given value will be used instead.
            </summary>
            
            <remarks>
            <para>
              The cost parameter C controls the trade off between allowing training
              errors and forcing rigid margins. It creates a soft margin that permits
              some misclassifications. Increasing the value of C increases the cost of
              misclassifying points and forces the creation of a more accurate model
              that may not generalize well.</para>
              
            <para>
              If this value is not set and <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseComplexityHeuristic"/> is set to 
              <c>true</c>, the framework will automatically guess a suitable value for C by
              calling <see cref="M:Accord.Statistics.Kernels.Kernel.EstimateComplexity``2(``0,``1[])"/>.  If this value 
              is manually set to something else, then the class will respect the new value 
              and automatically disable <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseComplexityHeuristic"/>. </para>
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.PositiveWeight">
            <summary>
              Gets or sets the positive class weight. This should be a
              value higher than 0 indicating how much of the <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Complexity"/>
              parameter C should be applied to instances carrying the positive label.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.NegativeWeight">
            <summary>
              Gets or sets the negative class weight. This should be a
              value higher than 0 indicating how much of the <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Complexity"/>
              parameter C should be applied to instances carrying the negative label.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.WeightRatio">
            <summary>
              Gets or sets the weight ratio between positive and negative class
              weights. This ratio controls how much of the <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Complexity"/>
              parameter C should be applied to the positive class. 
            </summary>
            
            <remarks>
             <para>
              A weight ratio lesser than one, such as 1/10 (0.1) means 10% of C will
              be applied to the positive class, while 100% of C will be applied to the
              negative class.</para>
             <para>
              A weight ratio greater than one, such as 10/1 (10) means that 100% of C will
              be applied to the positive class, while 10% of C will be applied to the 
              negative class.</para>
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseComplexityHeuristic">
            <summary>
              Gets or sets a value indicating whether the Complexity parameter C
              should be computed automatically by employing an heuristic rule.
              Default is true.
            </summary>
            
            <value>
            	<c>true</c> if complexity should be computed automatically; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseKernelEstimation">
            <summary>
              Gets or sets whether initial values for some kernel parameters
              should be estimated from the data, if possible. Default is true.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseClassProportions">
            <summary>
              Gets or sets a value indicating whether the weight ratio to be used between
              <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Complexity"/> values for negative and positive instances should
              be computed automatically from the data proportions. Default is false.
            </summary>
            
            <value>
            	<c>true</c> if the weighting coefficient should be computed 
            	automatically from the data; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Kernel">
            <summary>
              Gets or sets the kernel function use to create a 
              kernel Support Vector Machine. If this property
              is set, <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.UseKernelEstimation"/> will be
              set to false.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.C">
            <summary>
              Gets or sets the cost values associated with each input vector.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Create(System.Int32,`1)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Learn(`2[],System.Boolean[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.InnerRun">
            <summary>
              Runs the main body of the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.ComputeError(`2[],System.Int32[])">
            <summary>
              Computes the error rate for a given set of input and outputs.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Run">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorClassification`3.Run(System.Boolean)">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3">
            <summary>
              Base class for <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> regression learning algorithms.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Token">
            <summary>
            Gets or sets a cancellation token that can be used to
            stop the learning algorithm while it is running.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.C">
            <summary>
              Gets or sets the cost values associated with each input vector.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Double[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Complexity">
            <summary>
              Complexity (cost) parameter C. Increasing the value of C forces the creation
              of a more accurate model that may not generalize well. If this value is not
              set and <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseComplexityHeuristic"/> is set to <c>true</c>, the framework
              will automatically guess a value for <c>C</c>. If this value is manually set to 
              something else, then <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseComplexityHeuristic"/> will be automatically 
              disabled and the given value will be used instead.
            </summary>
            
            <remarks>
            <para>
              The cost parameter C controls the trade off between allowing training
              errors and forcing rigid margins. It creates a soft margin that permits
              some misclassifications. Increasing the value of C increases the cost of
              misclassifying points and forces the creation of a more accurate model
              that may not generalize well.</para>
              
            <para>
              If this value is not set and <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseComplexityHeuristic"/> is set to 
              <c>true</c>, the framework will automatically guess a suitable value for C by
              calling <see cref="M:Accord.Statistics.Kernels.Kernel.EstimateComplexity``2(``0,``1[])"/>.  If this value 
              is manually set to something else, then the class will respect the new value 
              and automatically disable <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseComplexityHeuristic"/>. </para>
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Epsilon">
            <summary>
              Insensitivity zone ε. Increasing the value of ε can result in fewer 
              support vectors in the created model. Default value is 1e-3.
            </summary>
            
            <remarks>
              Parameter ε controls the width of the ε-insensitive zone, used to fit the training
              data. The value of ε can affect the number of support vectors used to construct the
              regression function. The bigger ε, the fewer support vectors are selected. On the
              other hand, bigger ε-values results in more flat estimates.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Weights">
            <summary>
              Gets or sets the individual weight of each sample in the training set. If set
              to <c>null</c>, all samples will be assumed equal weight. Default is <c>null</c>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseComplexityHeuristic">
            <summary>
              Gets or sets a value indicating whether the Complexity parameter C
              should be computed automatically by employing an heuristic rule.
              Default is false.
            </summary>
            
            <value>
            	<c>true</c> if complexity should be computed automatically; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseKernelEstimation">
            <summary>
              Gets or sets whether initial values for some kernel parameters
              should be estimated from the data, if possible. Default is true.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.IsLinear">
            <summary>
              Gets whether the machine to be learned
              has a <see cref="T:Accord.Statistics.Kernels.Linear"/> kernel.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Kernel">
            <summary>
              Gets or sets the kernel function use to create a 
              kernel Support Vector Machine. If this property
              is set, <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.UseKernelEstimation"/> will be
              set to false.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Inputs">
            <summary>
              Gets or sets the input vectors for training.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Outputs">
            <summary>
              Gets or sets the output values for each calibration vector.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Model">
            <summary>
              Gets the machine to be taught.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Create(System.Int32,`1)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Learn(`2[],System.Double[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.ComputeError(`2[],System.Double[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSupportVectorRegression`3.Run">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ILinearSupportVectorMachineLearning">
            <summary>
              Common interface for Support Machine Vector learning algorithms.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning">
            <summary>
              Common interface for Support Machine Vector learning algorithms.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`1">
            <summary>
              Common interface for Support Machine Vector learning algorithms.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`1.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`1.Run(System.Boolean)">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`2">
            <summary>
              Common interface for Support Machine Vector learning algorithms.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`2.Model">
            <summary>
              Gets or sets the support vector machine being learned.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`2.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning`2.Run(System.Boolean)">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning">
            <summary>
              Least Squares SVM (LS-SVM) learning algorithm.
            </summary>
            
            <remarks>
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6438">
                  Suykens, J. A. K., et al. "Least squares support vector machine classifiers: a large scale 
                  algorithm." European Conference on Circuit Theory and Design, ECCTD. Vol. 99. 1999. Available on:
                  http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6438 </a>
                  </description></item>
                </list></para>  
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning.Create(System.Int32,Accord.Statistics.Kernels.IKernel{System.Double[]})">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning`2">
            <summary>
              Least Squares SVM (LS-SVM) learning algorithm.
            </summary>
            
            <remarks>
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6438">
                  Suykens, J. A. K., et al. "Least squares support vector machine classifiers: a large scale 
                  algorithm." European Conference on Circuit Theory and Design, ECCTD. Vol. 99. 1999. Available on:
                  http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.6438 </a>
                  </description></item>
                </list></para>  
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearning`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearningBase`3">
            <summary>
              Base class for Least Squares SVM (LS-SVM) learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearningBase`3.#ctor">
            <summary>
              Constructs a new Least Squares SVM (LS-SVM) learning algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearningBase`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-6.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 1e-6.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearningBase`3.CacheSize">
            <summary>
              Gets or sets the cache size to partially
              stored the kernel matrix. Default is the
              same number of input vectors.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearningBase`3.InnerRun">
            <summary>
            Runs the main body of the learning algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LeastSquaresLearningBase`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent">
            <summary>
              Averaged Stochastic Gradient Descent (ASGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_nonlinear" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`1">
            <summary>
              Averaged Stochastic Gradient Descent (ASGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_nonlinear" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`1.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            <returns>BaseAveragedStochasticGradientDescent&lt;SupportVectorMachine&lt;TKernel&gt;, TKernel, System.Double[]&gt;.</returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`2">
            <summary>
              Averaged Stochastic Gradient Descent (ASGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_nonlinear" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`2.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            <returns>BaseAveragedStochasticGradientDescent&lt;SupportVectorMachine&lt;TKernel, TInput&gt;, TKernel, TInput&gt;.</returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`3">
            <summary>
              Averaged Stochastic Gradient Descent (ASGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\AveragedStochasticGradientDescentTest.cs" region="doc_learn_nonlinear" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`3.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent`3.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            <returns>BaseAveragedStochasticGradientDescent&lt;SupportVectorMachine&lt;TKernel, TInput&gt;, TKernel, TInput&gt;.</returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4">
            <summary>
              Base class for Averaged Stochastic Gradient Descent algorithm implementations.
            </summary>
            
            <remarks>
              The <see cref="T:Accord.Statistics.Kernels.IKernel"/> and <see cref="T:Accord.Math.Optimization.Losses.IDifferentiableLoss`3"/>
              are passed as generic parameters (constrained to be structs) because this is the only
              way to force the compiler to emit a separate native code for this class whose performance
              critical sections can be inlined.
            </remarks>
            
            <typeparam name="TModel">The type of the model being learned.</typeparam>
            <typeparam name="TKernel">The type of the kernel function to use.</typeparam>
            <typeparam name="TInput">The type of the input to consider.</typeparam>
            <typeparam name="TLoss">The type of the loss function to use.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent"/>
            <seealso cref="T:Accord.MachineLearning.BinaryLearningBase`2" />
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Kernel">
            <summary>
              Gets or sets the kernel function use to create a 
              kernel Support Vector Machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Loss">
            <summary>
              Gets or sets the loss function to be used. 
              Default is to use the <see cref="T:Accord.Math.Optimization.Losses.LogisticLoss"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.LearningRate">
            <summary>
              Gets or sets the learning rate for the SGD algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.MaxIterations">
            <summary>
              Gets or sets the number of iterations that should be
              performed by the algorithm when calling <see cref="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Learn(`2[],System.Boolean[],System.Double[])"/>.
              Default is 0 (iterate until convergence).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Iterations">
            <summary>
              Please use MaxIterations instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.CurrentEpoch">
            <summary>
              Gets or sets the current epoch counter.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.ParallelOptions">
            <summary>
              Gets or sets the parallelization options for this algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Token">
            <summary>
            Gets or sets a cancellation token that can be used
            to cancel the algorithm while it is running.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Tolerance">
            <summary>
              Gets or sets the maximum relative change in the watched value
              after an iteration of the algorithm used to detect convergence.
              Default is 1e-3. If set to 0, the loss will not be computed 
              during learning and execution will be faster.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Lambda">
            <summary>
              Gets or sets the lambda regularization term. Default is 0.5.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Create(System.Int32,`1)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.renorm">
            <summary>
              Renormalize the weights.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.wnorm">
            <summary>
              Compute the norm of the weights.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.anorm">
            <summary>
              Compute the norm of the averaged weights.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.trainOne(`2,System.Boolean,System.Double,System.Double)">
            <summary>
              Perform one iteration of the SGD algorithm with specified gains
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Learn(`2[],System.Boolean[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>A new object that is a copy of this instance.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseAveragedStochasticGradientDescent`4.InnerClone">
            <summary>
              Inheritors should implement this function to produce a new instance
              with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.FanChenLinSupportVectorRegression">
            <summary>
              Support vector regression using <see cref="T:Accord.Math.Optimization.FanChenLinQuadraticOptimization"/> (LibSVM) algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.FanChenLinSupportVectorRegression.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.FanChenLinSupportVectorRegression`1">
            <summary>
              Support vector regression using <see cref="T:Accord.Math.Optimization.FanChenLinQuadraticOptimization"/> (LibSVM)  algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.FanChenLinSupportVectorRegression`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.FanChenLinSupportVectorRegression`2">
            <summary>
              Support vector regression using <see cref="T:Accord.Math.Optimization.FanChenLinQuadraticOptimization"/>  (LibSVM) algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.FanChenLinSupportVectorRegression`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3">
            <summary>
              Base class for Fan-Chen-Lin (LibSVM) regression algorithms.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3.#ctor(`0)">
            <summary>
              Constructs a new one-class support vector learning algorithm.
            </summary>
            
            <param name="machine">A support vector machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3.#ctor">
            <summary>
              Constructs a new one-class support vector learning algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3.Lagrange">
            <summary>
              Gets the value for the Lagrange multipliers
              (alpha) for every observation vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-2.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.01.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3.Shrinking">
            <summary>
              Gets or sets a value indicating whether to use 
              shrinking heuristics during learning. Default is true.
            </summary>
            
            <value>
              <c>true</c> to use shrinking; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseFanChenLinSupportVectorRegression`3.InnerRun">
            <summary>
            Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent">
            <summary>
              Stochastic Gradient Descent (SGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`1">
            <summary>
              Stochastic Gradient Descent (SGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`1.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`2">
            <summary>
              Stochastic Gradient Descent (SGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`2.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`3">
            <summary>
              Stochastic Gradient Descent (SGD) for training linear support vector machines.
            </summary>
            
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
            <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multiclass" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\StochasticGradientDescentTest.cs" region="doc_learn_multilabel" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`3.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent`3.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new instance
            with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4">
            <summary>
              Base class for Averaged Stochastic Gradient Descent algorithm implementations.
            </summary>
            
            <typeparam name="TModel">The type of the model being learned.</typeparam>
            <typeparam name="TKernel">The type of the kernel function to use.</typeparam>
            <typeparam name="TInput">The type of the input to consider.</typeparam>
            <typeparam name="TLoss">The type of the loss function to use.</typeparam>
            
            <remarks>
              The <see cref="T:Accord.Statistics.Kernels.IKernel"/> and <see cref="T:Accord.Math.Optimization.Losses.IDifferentiableLoss`3"/>
              are passed as generic parameters (constrained to be structs) because this is the only
              way to force the compiler to emit a separate native code for this class whose performance
              critical sections can be inlined.
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.StochasticGradientDescent"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.AveragedStochasticGradientDescent"/>
            <seealso cref="T:Accord.MachineLearning.BinaryLearningBase`2" />
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Kernel">
            <summary>
              Gets or sets the kernel function use to create a 
              kernel Support Vector Machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Loss">
            <summary>
              Gets or sets the loss function to be used. 
              Default is to use the <see cref="T:Accord.Math.Optimization.Losses.LogisticLoss"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.LearningRate">
            <summary>
              Gets or sets the learning rate for the SGD algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Iterations">
            <summary>
              Please use MaxIterations instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.MaxIterations">
            <summary>
              Gets or sets the number of iterations that should be
              performed by the algorithm when calling <see cref="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Learn(`2[],System.Boolean[],System.Double[])"/>.
              Default is 0 (iterate until convergence).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Tolerance">
            <summary>
              Gets or sets the maximum relative change in the watched value
              after an iteration of the algorithm used to detect convergence.
              Default is 1e-5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Lambda">
            <summary>
              Gets or sets the lambda regularization term. Default is 0.5.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Create(System.Int32,`1)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.renorm">
            <summary>
              Renormalize the weights
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.wnorm">
            <summary>
              Compute the norm of the weights
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.trainOne(`2,System.Boolean,System.Double)">
            <summary>
              Perform one iteration of the SGD algorithm with specified gains
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Learn(`2[],System.Boolean[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>A new object that is a copy of this instance.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseStochasticGradientDescent`4.InnerClone">
            <summary>
            Inheritors should implement this function to produce a new 
            instance with the same characteristics of the current object.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent">
             <summary>
               L1-regularized L2-loss support vector 
               Support Vector Machine learning (-s 5).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L1-regularized, 
               L2-loss coordinate descent learning algorithm for optimizing the primal form of
               learning. The code has been based on liblinear's method <c>solve_l1r_l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 5</c>: <c>L1R_L2LOSS_svc</c>. A coordinate descent 
               algorithm for L2-loss SVM problems in the primal.
             </para>
             
             <code>
              min_w \sum |wj| + C \sum max(0, 1-yi w^T xi)^2,
             </code>
             
             <para>
               Given: x, y, Cp, Cn and eps as the stopping tolerance</para>
            
             <para>
               See Yuan et al. (2010) and appendix of LIBLINEAR paper, Fan et al. (2008)</para>
             </remarks>
             
             <examples>
             <para>
               The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> 
               from a linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains exactly the same data 
               used in the <see cref="T:Accord.Statistics.Models.Regression.Linear.OrdinaryLeastSquares"/> documentation page for 
               <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/>.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\LinearCoordinateDescentTest.cs" region="doc_linreg"/>
             </examples>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent`1">
             <summary>
               L1-regularized L2-loss support vector 
               Support Vector Machine learning (-s 5).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L1-regularized, 
               L2-loss coordinate descent learning algorithm for optimizing the primal form of
               learning. The code has been based on liblinear's method <c>solve_l1r_l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 5</c>: <c>L1R_L2LOSS_svc</c>. A coordinate descent 
               algorithm for L2-loss SVM problems in the primal.
             </para>
             
             <code>
              min_w \sum |wj| + C \sum max(0, 1-yi w^T xi)^2,
             </code>
             
             <para>
               Given: x, y, Cp, Cn and eps as the stopping tolerance</para>
            
             <para>
               See Yuan et al. (2010) and appendix of LIBLINEAR paper, Fan et al. (2008)</para>
             </remarks>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2">
            <summary>
              Base class for linear coordinate descent learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2.#ctor">
            <summary>
              Constructs a new coordinate descent algorithm for L1-loss and L2-loss SVM dual problems.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2.Lagrange">
            <summary>
              Gets the value for the Lagrange multipliers
              (alpha) for every observation vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.1.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.1.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearCoordinateDescent`2.#ctor(`0,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.Loss">
            <summary>
              Different categories of loss functions that can be used to learn 
              <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">support vector machines</see>.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.Learning.Loss.L1">
            <summary>
              Hinge-loss function. 
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.Learning.Loss.L2">
            <summary>
              Squared hinge-loss function.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent">
             <summary>
               L2-regularized, L1 or L2-loss dual formulation 
               Support Vector Machine learning (-s 1 and -s 3).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L2-regularized, L1
               or L2-loss coordinate descent learning algorithm for optimizing the dual form of
               learning. The code has been based on liblinear's method <c>solve_l2r_l1l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 1</c>: <c>L2R_L2LOSS_SVC_DUAL</c> and <c>-s 3</c>: 
               <c>L2R_L1LOSS_SVC_DUAL</c>. A coordinate descent algorithm for L1-loss and 
               L2-loss SVM problems in the dual.
             </para>
             
             <code>
              min_\alpha  0.5(\alpha^T (Q + D)\alpha) - e^T \alpha,
                s.t.      0 &lt;= \alpha_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where Qij = yi yj xi^T xj and
              D is a diagonal matrix </para>
            
             <para>
             In L1-SVM case:</para>
             <code>
                     upper_bound_i = Cp if y_i = 1
                     upper_bound_i = Cn if y_i = -1
                     D_ii = 0
             </code>
             <para>
             In L2-SVM case:</para>
             <code>
                     upper_bound_i = INF
                     D_ii = 1/(2*Cp)	if y_i = 1
                     D_ii = 1/(2*Cn)	if y_i = -1
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 3 of Hsieh et al., ICML 2008.</para>
             </remarks>
             
             <example>
               <para>The next example shows how to solve a multi-class problem using a one-vs-one SVM 
               where the binary machines are learned using the Linear Dual Coordinate Descent algorithm.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
               
             <para>
               The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> 
               from a linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains exactly the same data 
               used in the <see cref="T:Accord.Statistics.Models.Regression.Linear.OrdinaryLeastSquares"/> documentation page for 
               <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/>.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\LinearDualCoordinateDescentTest.cs" region="doc_linreg"/>
             </example>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent`1">
             <summary>
               L2-regularized, L1 or L2-loss dual formulation 
               Support Vector Machine learning (-s 1 and -s 3).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L2-regularized, L1
               or L2-loss coordinate descent learning algorithm for optimizing the dual form of
               learning. The code has been based on liblinear's method <c>solve_l2r_l1l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 1</c>: <c>L2R_L2LOSS_SVC_DUAL</c> and <c>-s 3</c>: 
               <c>L2R_L1LOSS_SVC_DUAL</c>. A coordinate descent algorithm for L1-loss and 
               L2-loss SVM problems in the dual.
             </para>
             
             <code>
              min_\alpha  0.5(\alpha^T (Q + D)\alpha) - e^T \alpha,
                s.t.      0 &lt;= \alpha_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where Qij = yi yj xi^T xj and
              D is a diagonal matrix </para>
            
             <para>
             In L1-SVM case:</para>
             <code>
                     upper_bound_i = Cp if y_i = 1
                     upper_bound_i = Cn if y_i = -1
                     D_ii = 0
             </code>
             <para>
             In L2-SVM case:</para>
             <code>
                     upper_bound_i = INF
                     D_ii = 1/(2*Cp)	if y_i = 1
                     D_ii = 1/(2*Cn)	if y_i = -1
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 3 of Hsieh et al., ICML 2008.</para>
             </remarks>
             
             <example>
               <para>The next example shows how to solve a multi-class problem using a one-vs-one SVM 
               where the binary machines are learned using the Linear Dual Coordinate Descent algorithm.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             </example>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent`2">
             <summary>
               L2-regularized, L1 or L2-loss dual formulation 
               Support Vector Machine learning (-s 1 and -s 3).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L2-regularized, L1
               or L2-loss coordinate descent learning algorithm for optimizing the dual form of
               learning. The code has been based on liblinear's method <c>solve_l2r_l1l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 1</c>: <c>L2R_L2LOSS_SVC_DUAL</c> and <c>-s 3</c>: 
               <c>L2R_L1LOSS_SVC_DUAL</c>. A coordinate descent algorithm for L1-loss and 
               L2-loss SVM problems in the dual.
             </para>
             
             <code>
              min_\alpha  0.5(\alpha^T (Q + D)\alpha) - e^T \alpha,
                s.t.      0 &lt;= \alpha_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where Qij = yi yj xi^T xj and
              D is a diagonal matrix </para>
            
             <para>
             In L1-SVM case:</para>
             <code>
                     upper_bound_i = Cp if y_i = 1
                     upper_bound_i = Cn if y_i = -1
                     D_ii = 0
             </code>
             <para>
             In L2-SVM case:</para>
             <code>
                     upper_bound_i = INF
                     D_ii = 1/(2*Cp)	if y_i = 1
                     D_ii = 1/(2*Cn)	if y_i = -1
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 3 of Hsieh et al., ICML 2008.</para>
             </remarks>
             
             <example>
               <para>The next example shows how to solve a multi-class problem using a one-vs-one SVM 
               where the binary machines are learned using the Linear Dual Coordinate Descent algorithm.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             </example>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3">
            <summary>
              Base class for Linear Dual Coordinate Descent.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.#ctor">
            <summary>
              Constructs a new coordinate descent algorithm for L1-loss and L2-loss SVM dual problems.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.Loss">
            <summary>
              Gets or sets the <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.Loss"/> cost function that
              should be optimized. Default is 
              <see cref="F:Accord.MachineLearning.VectorMachines.Learning.Loss.L2"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.Lagrange">
            <summary>
              Gets the value for the Lagrange multipliers
              (alpha) for every observation vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.1.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.1.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearDualCoordinateDescent`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod">
            <summary>
              L2-regularized L2-loss linear support vector classification (primal).
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss support vector machine
              learning algorithm that operates in the primal form of the optimization
              problem. This method has been based on liblinear's <c>l2r_l2_svc_fun</c>
              problem specification, optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod">
              Trust-region Newton method</see>. This method might be faster than the often
              preferred <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>. </para>
              
            <para>
              Liblinear's solver <c>-s 2</c>: <c>L2R_L2LOSS_SVC</c>. A trust region newton
              algorithm for the primal of L2-regularized, L2-loss linear support vector 
              classification.
            </para>
            </remarks>
            
            <examples>
            <para>
              The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> 
              from a linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains exactly the same data 
              used in the <see cref="T:Accord.Statistics.Models.Regression.Linear.OrdinaryLeastSquares"/> documentation page for 
              <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/>.</para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\LinearNewtonMethodTest.cs" region="doc_linreg"/>
            </examples>
            
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod`2">
            <summary>
              L2-regularized L2-loss linear support vector classification (primal).
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss support vector machine
              learning algorithm that operates in the primal form of the optimization
              problem. This method has been based on liblinear's <c>l2r_l2_svc_fun</c>
              problem specification, optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod">
              Trust-region Newton method</see>. This method might be faster than the often
              preferred <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>. </para>
              
            <para>
              Liblinear's solver <c>-s 2</c>: <c>L2R_L2LOSS_SVC</c>. A trust region newton
              algorithm for the primal of L2-regularized, L2-loss linear support vector 
              classification.
            </para>
            </remarks>
            
            <examples>
            <para>
              The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> 
              from a linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains exactly the same data 
              used in the <see cref="T:Accord.Statistics.Models.Regression.Linear.OrdinaryLeastSquares"/> documentation page for 
              <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/>.</para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\LinearNewtonMethodTest.cs" region="doc_linreg_sparse"/>
            </examples>
            
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod`2.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod`2"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod`2.Create(System.Int32,`0)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`2">
            <summary>
              Base class for L2-regularized L2-loss linear support vector classification (primal).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`2.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`2"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`2.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`2.#ctor(`0,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3">
            <summary>
              L2-regularized L2-loss linear support vector classification (primal).
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss support vector machine
              learning algorithm that operates in the primal form of the optimization
              problem. This method has been based on liblinear's <c>l2r_l2_svc_fun</c>
              problem specification, optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod">
              Trust-region Newton method</see>. This method might be faster than the often
              preferred <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>. </para>
              
            <para>
              Liblinear's solver <c>-s 2</c>: <c>L2R_L2LOSS_SVC</c>. A trust region newton
              algorithm for the primal of L2-regularized, L2-loss linear support vector 
              classification.
            </para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L2-regularized
              Support Vector Classification problems in the primal form (-s 2).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.1.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.1.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3.MaximumIterations">
            <summary>
              Gets or sets the maximum number of iterations that should
               be performed until the algorithm stops. Default is 1000.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearNewtonMethod`3.#ctor(`0,`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorMachineLearningConfigurationFunction">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning">
            <summary>
              One-against-one Multi-class Support Vector Machine Learning Algorithm
            </summary>
            
            <remarks>
            <para>
              This class can be used to train Kernel Support Vector Machines with
              any algorithm using a <c>one-against-one</c> strategy. The underlying 
              training algorithm can be configured by defining the <see cref="P:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Algorithm"/>
              property.</para>
              
            <para>
              One example of learning algorithm that can be used with this class is the
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization">Sequential Minimal Optimization
              </see> (SMO) algorithm.</para>
            </remarks>
            
            <example>
            <para>
              The following example shows how to learn a linear, multi-class support vector 
              machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
            
            <para>
              The following example shows how to learn a non-linear, multi-class support 
              vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
            <para>
              Support vector machines can have their weights calibrated in order to produce 
              probability estimates (instead of simple class separation distances). The
              following example shows how to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
              within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/> to generate a probabilistic
              SVM:</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning"/>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.ComputeError(System.Double[][],System.Int32[])">
            <summary>
              Computes the error ratio, the number of
              misclassifications divided by the total
              number of samples in a dataset.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.#ctor(Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Algorithm">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Convert(Accord.MachineLearning.VectorMachines.Learning.SupportVectorMachineLearningConfigurationFunction)">
            <summary>
              Converts <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorMachineLearningConfigurationFunction"/>
              into a lambda function that can be passed to the <see cref="P:Accord.MachineLearning.OneVsOneLearning`3.Learner"/>
              property of a <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/> learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Create(System.Int32,System.Int32)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Kernel">
            <summary>
              Gets or sets the kernel function to be used to learn the
              <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">kernel support 
              vector machines</see>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`2">
            <summary>
              One-against-one Multi-class Support Vector Machine Learning Algorithm
            </summary>
            
            <remarks>
            <para>
              This class can be used to train Kernel Support Vector Machines with
              any algorithm using a <c>one-against-one</c> strategy. The underlying 
              training algorithm can be configured by defining the <see cref="P:Accord.MachineLearning.OneVsOneLearning`3.Learner"/>
              property.</para>
              
            <para>
              One example of learning algorithm that can be used with this class is the
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">Sequential Minimal Optimization
              </see> (SMO) algorithm.</para>
            </remarks>
            
            <example>
            <para>
              The following example shows how to learn a linear, multi-class support vector 
              machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
            
            <para>
              The following example shows how to learn a non-linear, multi-class support 
              vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
            <para>
              Support vector machines can have their weights calibrated in order to produce 
              probability estimates (instead of simple class separation distances). The
              following example shows how to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
              within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> to generate a probabilistic
              SVM:</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`2.Create(System.Int32,System.Int32)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`2"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`2.#ctor(Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine{`0,`1})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`2"/> class.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseMulticlassSupportVectorLearning`4">
            <summary>
              Base class for multi-class support vector learning algorithms.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseMulticlassSupportVectorLearning`4.Kernel">
            <summary>
              Gets or sets the kernel function to be used to learn the
              <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">kernel support 
              vector machines</see>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseMulticlassSupportVectorLearning`3">
            <summary>
              Base class for multi-class support vector learning algorithms.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseMulticlassSupportVectorLearning`3.Kernel">
            <summary>
              Gets or sets the kernel function to be used to learn the
              <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">kernel support 
              vector machines</see>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1">
            <summary>
              One-against-one Multi-class Support Vector Machine Learning Algorithm
            </summary>
            
            <remarks>
            <para>
              This class can be used to train Kernel Support Vector Machines with
              any algorithm using a <c>one-against-one</c> strategy. The underlying 
              training algorithm can be configured by defining the <see cref="P:Accord.MachineLearning.OneVsOneLearning`3.Learner"/>
              property.</para>
              
            <para>
              One example of learning algorithm that can be used with this class is the
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">Sequential Minimal Optimization
              </see> (SMO) algorithm.</para>
            </remarks>
            
            <example>
            <para>
              The following example shows how to learn a linear, multi-class support vector 
              machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
            
            <para>
              The following example shows how to learn a non-linear, multi-class support 
              vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
            <para>
              Support vector machines can have their weights calibrated in order to produce 
              probability estimates (instead of simple class separation distances). The
              following example shows how to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
              within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> to generate a probabilistic
              SVM:</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1.Create(System.Int32,System.Int32)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1.#ctor(Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine{`0})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> class.
            </summary>
            
            <param name="machine">The existing machine to be learned.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.#ctor(Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine,System.Double[][],System.Int32[][])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.#ctor(Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.Algorithm">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.Convert(Accord.MachineLearning.VectorMachines.Learning.SupportVectorMachineLearningConfigurationFunction)">
            <summary>
              Converts <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorMachineLearningConfigurationFunction"/>
              into a lambda function that can be passed to the <see cref="P:Accord.MachineLearning.OneVsRestLearning`3.Learner"/>
              property of a <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning"/> learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.Create(System.Int32,System.Int32,System.Boolean)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning.Kernel">
            <summary>
              Gets or sets the kernel function to be used to learn the
              <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">kernel support 
              vector machines</see>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1">
            <summary>
              One-against-all Multi-label Support Vector Machine Learning Algorithm
            </summary>
            
            <remarks>
            <para>
              This class can be used to train Kernel Support Vector Machines with
              any algorithm using a <c>one-against-all</c> strategy. The underlying 
              training algorithm can be configured by defining the <see cref="P:Accord.MachineLearning.OneVsRestLearning`3.Learner"/>
              property.</para>
              
            <para>
              One example of learning algorithm that can be used with this class is the
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">Sequential Minimal Optimization
              </see> (SMO) algorithm.</para>
            </remarks>
            
            <example>
            <para>
              The following example shows how to learn a linear, multi-label (one-vs-rest) support 
              vector machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
            
            <para>
              The following example shows how to learn a non-linear, multi-label (one-vs-rest) 
              support vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
            <para>
              Support vector machines can have their weights calibrated in order to produce probability 
              estimates (instead of simple class separation distances). The following example shows how 
              to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/> within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> 
              to generate a probabilistic SVM:</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1.Create(System.Int32,System.Int32,System.Boolean)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1.#ctor(Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine{`0})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> class.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`2">
            <summary>
              One-against-all Multi-label Support Vector Machine Learning Algorithm
            </summary>
            
            <remarks>
            <para>
              This class can be used to train Kernel Support Vector Machines with
              any algorithm using a <c>one-against-all</c> strategy. The underlying 
              training algorithm can be configured by defining the <see cref="P:Accord.MachineLearning.OneVsRestLearning`3.Learner"/>
              property.</para>
              
            <para>
              One example of learning algorithm that can be used with this class is the
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">Sequential Minimal Optimization
              </see> (SMO) algorithm.</para>
            </remarks>
            
            <example>
            <para>
              The following example shows how to learn a linear, multi-label (one-vs-rest) support 
              vector machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
            
            <para>
              The following example shows how to learn a non-linear, multi-label (one-vs-rest) 
              support vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
              <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
            <para>
              Support vector machines can have their weights calibrated in order to produce probability 
              estimates (instead of simple class separation distances). The following example shows how 
              to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/> within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> 
              to generate a probabilistic SVM:</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`2.Create(System.Int32,System.Int32,System.Boolean)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`2"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`2.#ctor(Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine{`0,`1})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`2"/> class.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseMultilabelSupportVectorLearning`4">
            <summary>
              Base class for multi-label support vector learning algorithms.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseMultilabelSupportVectorLearning`4.Kernel">
            <summary>
              Gets or sets the kernel function to be used to learn the
              <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">kernel support 
              vector machines</see>.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning">
            <summary>
              One-class Support Vector Machine learning algorithm.
            </summary>
            
            <example>
              <para>The following example shows how to use an one-class SVM.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\OneclassSupportVectorLearningTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine,System.Double[][])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning.Create(System.Int32,Accord.Statistics.Kernels.IKernel{System.Double[]})">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning`1">
            <summary>
              One-class Support Vector Machine learning algorithm.
            </summary>
            
            <example>
              <para>The following example shows how to use an one-class SVM.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\OneclassSupportVectorLearningTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning`2">
            <summary>
              One-class Support Vector Machine learning algorithm.
            </summary>
            
            <example>
              <para>The following example shows how to use an one-class SVM.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\OneclassSupportVectorLearningTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.OneclassSupportVectorLearning`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3">
            <summary>
              One-class Support Vector Machine Learning Algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Model">
            <summary>
              Gets or sets the classifier being learned.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Kernel">
            <summary>
              Gets or sets the kernel function use to create a 
              kernel Support Vector Machine. If this property
              is set, <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.UseKernelEstimation"/> will be
              set to false.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.UseKernelEstimation">
            <summary>
              Gets or sets whether initial values for some kernel parameters
              should be estimated from the data, if possible. Default is true.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.#ctor(`0)">
            <summary>
              Constructs a new one-class support vector learning algorithm.
            </summary>
            
            <param name="machine">A support vector machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.#ctor">
            <summary>
              Constructs a new one-class support vector learning algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Lagrange">
            <summary>
              Gets the value for the Lagrange multipliers
              (alpha) for every observation vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Token">
            <summary>
              Gets or sets a cancellation token that can be used to
              stop the learning algorithm while it is running.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-2.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.01.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Shrinking">
            <summary>
              Gets or sets a value indicating whether to use 
              shrinking heuristics during learning. Default is true.
            </summary>
            
            <value>
              <c>true</c> to use shrinking; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Nu">
            <summary>
              Controls the number of outliers accepted by the algorithm. This
              value provides an upper bound on the fraction of training errors
              and a lower bound of the fraction of support vectors. Default is 0.5
            </summary>
            
            <remarks>
              The summary description is given in Chang and Lin,
              "LIBSVM: A Library for Support Vector Machines", 2013.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Create(System.Int32,`1)">
            <summary>
              Creates an instance of the model to be learned. Inheritors
              of this abstract class must define this method so new models
              can be created from the training data.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Learn(`2[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>
            A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseOneclassSupportVectorLearning`3.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent">
             <summary>
               L1-regularized logistic regression (probabilistic SVM) 
               learning algorithm (-s 6).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for probabilistic linear machines only. It provides a L1-
               regularized coordinate descent learning algorithm for optimizing the learning
               problem. The code has been based on liblinear's method <c>solve_l1r_lr</c> 
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 6</c>: <c>L1R_LR</c>. 
               A coordinate descent algorithm for L1-regularized
               logistic regression (probabilistic svm) problems.
             </para>
             
             <code>
               min_w \sum |wj| + C \sum log(1+exp(-yi w^T xi)),
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Yuan et al. (2011) and appendix of LIBLINEAR paper, Fan et al. (2008)</para>
             </remarks>
             
             <examples>
             <para>
               Probabilistic SVMs are exactly the same as logistic regression models 
               trained using a large-margin decision criteria. As such, any linear SVM 
               learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
               objects as well.</para>
               
             <para>
               The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
               from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
               exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
               documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticCoordinateDescentTest.cs" region="doc_logreg"/>
             </examples>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L1-regularized
              logistic regression (probabilistic linear vector machine).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent`2">
             <summary>
               L1-regularized logistic regression (probabilistic SVM) 
               learning algorithm (-s 6).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for probabilistic linear machines only. It provides a L1-
               regularized coordinate descent learning algorithm for optimizing the learning
               problem. The code has been based on liblinear's method <c>solve_l1r_lr</c> 
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 6</c>: <c>L1R_LR</c>. 
               A coordinate descent algorithm for L1-regularized
               logistic regression (probabilistic svm) problems.
             </para>
             
             <code>
               min_w \sum |wj| + C \sum log(1+exp(-yi w^T xi)),
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Yuan et al. (2011) and appendix of LIBLINEAR paper, Fan et al. (2008)</para>
             </remarks>
             
             <examples>
             <para>
               Probabilistic SVMs are exactly the same as logistic regression models 
               trained using a large-margin decision criteria. As such, any linear SVM 
               learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
               objects as well.</para>
               
             <para>
               The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
               from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
               exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
               documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticCoordinateDescentTest.cs" region="doc_logreg"/>
             </examples>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent`2.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L1-regularized
              logistic regression (probabilistic linear vector machine).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3">
            <summary>
              Base class for L1-regularized logistic regression (probabilistic SVM) learning algorithm (-s 6).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3"/> class.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.MaximumIterations">
            <summary>
              Gets or sets the maximum number of iterations that should
              be performed until the algorithm stops. Default is 1000.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.MaximumLineSearches">
            <summary>
              Gets or sets the maximum number of line searches
              that can be performed per iteration. Default is 20.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.MaximumNewtonIterations">
            <summary>
              Gets or sets the maximum number of inner iterations that can
              be performed by the inner solver algorithm. Default is 100.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.01.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.01.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticCoordinateDescent`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent">
             <summary>
               L2-regularized logistic regression (probabilistic support 
               vector machine) learning algorithm in the dual form (-s 7).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for probabilistic linear machines only. It provides a L2-
               regularized coordinate descent learning algorithm for optimizing the dual form 
               of the learning problem. The code has been based on liblinear's method 
               <c>solve_l2r_lr_dual</c> method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 7</c>: <c>L2R_LR_DUAL</c>. A coordinate descent 
               algorithm for the dual of L2-regularized logistic regression problems.
             </para>
             
             <code>
               min_\alpha  0.5(\alpha^T Q \alpha) + \sum \alpha_i log (\alpha_i) 
                 + (upper_bound_i - \alpha_i) log (upper_bound_i - \alpha_i),
                 
                s.t.      0 &lt;= \alpha_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where <c>Qij = yi yj xi^T xj</c> and</para>
              
             <code>
              upper_bound_i = Cp if y_i = 1
              upper_bound_i = Cn if y_i = -1
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 5 of Yu et al., MLJ 2010.</para>
             </remarks>
             
             <examples>
             <para>
               Probabilistic SVMs are exactly the same as logistic regression models 
               trained using a large-margin decision criteria. As such, any linear SVM 
               learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
               objects as well.</para>
               
             <para>
               The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
               from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
               exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
               documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticDualCoordinateDescentTest.cs" region="doc_logreg"/>
             </examples>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L2-regularized
              logistic regression (probabilistic linear SVMs) dual problems.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent`2">
             <summary>
               L2-regularized logistic regression (probabilistic support 
               vector machine) learning algorithm in the dual form (-s 7).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for probabilistic linear machines only. It provides a L2-
               regularized coordinate descent learning algorithm for optimizing the dual form 
               of the learning problem. The code has been based on liblinear's method 
               <c>solve_l2r_lr_dual</c> method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 7</c>: <c>L2R_LR_DUAL</c>. A coordinate descent 
               algorithm for the dual of L2-regularized logistic regression problems.
             </para>
             
             <code>
               min_\alpha  0.5(\alpha^T Q \alpha) + \sum \alpha_i log (\alpha_i) 
                 + (upper_bound_i - \alpha_i) log (upper_bound_i - \alpha_i),
                 
                s.t.      0 &lt;= \alpha_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where <c>Qij = yi yj xi^T xj</c> and</para>
              
             <code>
              upper_bound_i = Cp if y_i = 1
              upper_bound_i = Cn if y_i = -1
             </code>
             
             <para>
             Given: x, y, Cp, Cn, and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 5 of Yu et al., MLJ 2010.</para>
             </remarks>
             
             <examples>
             <para>
               Probabilistic SVMs are exactly the same as logistic regression models 
               trained using a large-margin decision criteria. As such, any linear SVM 
               learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
               objects as well.</para>
               
             <para>
               The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
               from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
               exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
               documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
               
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticDualCoordinateDescentTest.cs" region="doc_logreg"/>
             </examples>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent`2.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L2-regularized
              logistic regression (probabilistic linear SVMs) dual problems.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3">
            <summary>
              Base class for L2-regularized logistic regression (probabilistic support 
              vector machine) learning algorithm in the dual form (-s 7).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L2-regularized
              logistic regression (probabilistic linear SVMs) dual problems.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3.MaximumIterations">
            <summary>
              Gets or sets the maximum number of iterations that should
               be performed until the algorithm stops. Default is 1000.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3.MaximumNewtonIterations">
            <summary>
              Gets or sets the maximum number of inner iterations that can
              be performed by the inner solver algorithm. Default is 100.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.1.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.1.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticDualCoordinateDescent`3.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine{`1,`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod">
            <summary>
              L2-regularized L2-loss logistic regression (probabilistic 
              support vector machine) learning algorithm in the primal.
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss logistic regression (probabilistic
              support vector machine) learning algorithm that operates in the primal form of the
              optimization problem. This method has been based on liblinear's <c>l2r_lr_fun</c>
              problem specification, optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod">
              Trust-region Newton method</see>.</para>
            </remarks>
            
            <para>
              Liblinear's solver <c>-s 0</c>: <c>L2R_LR</c>. A trust region newton
              algorithm for the primal of L2-regularized, L2-loss logistic regression.
            </para>
            
            <examples>
            <para>
              Probabilistic SVMs are exactly the same as logistic regression models 
              trained using a large-margin decision criteria. As such, any linear SVM 
              learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
              objects as well.</para>
              
            <para>
              The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
              from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
              exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
              documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticNewtonMethodTest.cs" region="doc_logreg"/>
            </examples>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/> class.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod`1">
            <summary>
              L2-regularized L2-loss logistic regression (probabilistic 
              support vector machine) learning algorithm in the primal.
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss logistic regression (probabilistic
              support vector machine) learning algorithm that operates in the primal form of the
              optimization problem. This method has been based on liblinear's <c>l2r_lr_fun</c>
              problem specification, optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod">
              Trust-region Newton method</see>.</para>
            </remarks>
            
            <para>
              Liblinear's solver <c>-s 0</c>: <c>L2R_LR</c>. A trust region newton
              algorithm for the primal of L2-regularized, L2-loss logistic regression.
            </para>
            
            <examples>
            <para>
              Probabilistic SVMs are exactly the same as logistic regression models 
              trained using a large-margin decision criteria. As such, any linear SVM 
              learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
              objects as well.</para>
              
            <para>
              The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
              from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
              exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
              documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticNewtonMethodTest.cs" region="doc_logreg"/>
            </examples>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod`2">
            <summary>
              L2-regularized L2-loss logistic regression (probabilistic 
              support vector machine) learning algorithm in the primal.
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss logistic regression (probabilistic
              support vector machine) learning algorithm that operates in the primal form of the
              optimization problem. This method has been based on liblinear's <c>l2r_lr_fun</c>
              problem specification, optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod">
              Trust-region Newton method</see>.</para>
            </remarks>
            
            <para>
              Liblinear's solver <c>-s 0</c>: <c>L2R_LR</c>. A trust region newton
              algorithm for the primal of L2-regularized, L2-loss logistic regression.
            </para>
            
            <examples>
            <para>
              Probabilistic SVMs are exactly the same as logistic regression models 
              trained using a large-margin decision criteria. As such, any linear SVM 
              learning algorithm can be used to obtain <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>
              objects as well.</para>
              
            <para>
              The following example shows how to obtain a <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> 
              from a probabilistic linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>. It contains
              exactly the same data used in the <see cref="T:Accord.Statistics.Models.Regression.Fitting.IterativeReweightedLeastSquares"/>
              documentation page for <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.</para>
              
            <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\Probabilistic\ProbabilisticNewtonMethodTest.cs" region="doc_logreg"/>
            </examples>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticNewtonMethod`3">
            <summary>
              Base class for probabilistic Newton Method learning.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticNewtonMethod`3.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L2-regularized logistic 
              regression (probabilistic linear SVMs) primal problems (-s 0).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticNewtonMethod`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.01.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.01.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticNewtonMethod`3.MaximumIterations">
            <summary>
              Gets or sets the maximum number of iterations that should
               be performed until the algorithm stops. Default is 1000.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticNewtonMethod`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseProbabilisticNewtonMethod`3.#ctor(`0,`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration">
            <summary>
              Probabilistic Output Calibration for Linear machines.
            </summary>
            
            <remarks>
              <para>Instead of producing probabilistic outputs, Support Vector Machines
              express their decisions in the form of a distance from support vectors in
              feature space. In order to convert the SVM outputs into probabilities,
              Platt (1999) proposed the calibration of the SVM outputs using a sigmoid
              (Logit) link function. Later, Lin et al (2007) provided a corrected and
              improved version of Platt's probabilistic outputs. This class implements
              the later.</para>
              
              <para>This class is not an actual learning algorithm, but a calibrator.
              Machines passed as input to this algorithm should already have been trained
              by a proper learning algorithm such as <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">
              Sequential Minimal Optimization (SMO)</see>.</para>
              
            <para>
              This class can also be used in combination with <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
              or <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> to learn <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              using the <c>one-vs-one</c> or <c>one-vs-all</c> multi-class decision strategies, respectively.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                   John C. Platt. 1999. Probabilistic Outputs for Support Vector Machines and Comparisons to
                   Regularized Likelihood Methods. In ADVANCES IN LARGE MARGIN CLASSIFIERS (1999), pp. 61-74.</description></item>
                <item><description>
                  Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng. 2007. A note on Platt's probabilistic outputs
                  for support vector machines. Mach. Learn. 68, 3 (October 2007), 267-276. </description></item>
              </list></para>   
            </remarks>
            
            <example>
              <para>
              The following example shows how to calibrate a SVM that has
              been trained to perform a simple XOR function.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\ProbabilisticOutputCalibrationTest.cs" region="doc_learn" />
              
              <para>
              The next example shows how to solve a multi-class problem using a one-vs-one SVM 
              where the binary machines are learned using SMO and calibrated using Platt's scaling.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
              
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine{Accord.Statistics.Kernels.IKernel{System.Double[]},System.Double[]})">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
            <param name="machine">The support vector machine to be calibrated.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration.#ctor">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration`1">
            <summary>
              Probabilistic Output Calibration for Kernel machines.
            </summary>
            
            <remarks>
              <para>Instead of producing probabilistic outputs, Support Vector Machines
              express their decisions in the form of a distance from support vectors in
              feature space. In order to convert the SVM outputs into probabilities,
              Platt (1999) proposed the calibration of the SVM outputs using a sigmoid
              (Logit) link function. Later, Lin et al (2007) provided a corrected and
              improved version of Platt's probabilistic outputs. This class implements
              the later.</para>
              
              <para>This class is not an actual learning algorithm, but a calibrator.
              Machines passed as input to this algorithm should already have been trained
              by a proper learning algorithm such as <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">
              Sequential Minimal Optimization (SMO)</see>.</para>
              
            <para>
              This class can also be used in combination with <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
              or <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> to learn <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              using the <c>one-vs-one</c> or <c>one-vs-all</c> multi-class decision strategies, respectively.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                   John C. Platt. 1999. Probabilistic Outputs for Support Vector Machines and Comparisons to
                   Regularized Likelihood Methods. In ADVANCES IN LARGE MARGIN CLASSIFIERS (1999), pp. 61-74.</description></item>
                <item><description>
                  Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng. 2007. A note on Platt's probabilistic outputs
                  for support vector machines. Mach. Learn. 68, 3 (October 2007), 267-276. </description></item>
              </list></para>   
            </remarks>
            
            <example>
              <para>
              The following example shows how to calibrate a SVM that has
              been trained to perform a simple XOR function.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\ProbabilisticOutputCalibrationTest.cs" region="doc_learn" />
              
              <para>
              The next example shows how to solve a multi-class problem using a one-vs-one SVM 
              where the binary machines are learned using SMO and calibrated using Platt's scaling.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
              
              
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration`1.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine{`0})">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
            <param name="machine">The support vector machine to be calibrated.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration`1.#ctor">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration`2">
            <summary>
              Probabilistic Output Calibration for structured Kernel machines.
            </summary>
            
            <remarks>
              <para>Instead of producing probabilistic outputs, Support Vector Machines
              express their decisions in the form of a distance from support vectors in
              feature space. In order to convert the SVM outputs into probabilities,
              Platt (1999) proposed the calibration of the SVM outputs using a sigmoid
              (Logit) link function. Later, Lin et al (2007) provided a corrected and
              improved version of Platt's probabilistic outputs. This class implements
              the later.</para>
              
              <para>This class is not an actual learning algorithm, but a calibrator.
              Machines passed as input to this algorithm should already have been trained
              by a proper learning algorithm such as <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">
              Sequential Minimal Optimization (SMO)</see>.</para>
              
            <para>
              This class can also be used in combination with <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
              or <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> to learn <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              using the <c>one-vs-one</c> or <c>one-vs-all</c> multi-class decision strategies, respectively.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                   John C. Platt. 1999. Probabilistic Outputs for Support Vector Machines and Comparisons to
                   Regularized Likelihood Methods. In ADVANCES IN LARGE MARGIN CLASSIFIERS (1999), pp. 61-74.</description></item>
                <item><description>
                  Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng. 2007. A note on Platt's probabilistic outputs
                  for support vector machines. Mach. Learn. 68, 3 (October 2007), 267-276. </description></item>
              </list></para>   
            </remarks>
            
            <example>
              <para>
              The following example shows how to calibrate a SVM that has
              been trained to perform a simple XOR function.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\ProbabilisticOutputCalibrationTest.cs" region="doc_learn" />
              
              <para>
              The next example shows how to solve a multi-class problem using a one-vs-one SVM 
              where the binary machines are learned using SMO and calibrated using Platt's scaling.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
            </example>
              
              
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration`2.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine{`0,`1})">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
            <param name="machine">The support vector machine to be calibrated.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration`2.#ctor">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3">
            <summary>
              Probabilistic Output Calibration.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.#ctor(`0)">
            <summary>
              Initializes a new instance of Platt's Probabilistic Output Calibration algorithm.
            </summary>
            
            <param name="machine">The support vector machine to be calibrated.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.Iterations">
            <summary>
              Gets or sets the maximum number of
              iterations. Default is 100. 
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.Tolerance">
            <summary>
              Gets or sets the tolerance under which the
              answer must be found. Default is 1-e5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.StepSize">
            <summary>
              Gets or sets the minimum step size used 
              during line search. Default is 1e-10.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.Learn(`2[],System.Boolean[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="inputs">The model inputs.</param>
            <param name="outputs">The desired outputs associated with each <paramref name="inputs">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="outputs"/> given <paramref name="inputs"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.Run(System.Boolean)">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibrationBase`3.LogLikelihood(`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent">
             <summary>
               Coordinate descent algorithm for the L1 or L2-loss linear Support 
               Vector Regression (epsilon-SVR) learning problem in the dual form
               (-s 12 and -s 13).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L2-regularized, L1
               or L2-loss coordinate descent learning algorithm for optimizing the dual form of
               learning. The code has been based on liblinear's method <c>solve_l2r_l1l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 12</c>: <c>L2R_L2LOSS_SVR_DUAL</c> and <c>-s 13</c>: 
               <c>L2R_L1LOSS_SVR_DUAL</c>. A coordinate descent algorithm for L1-loss and 
               L2-loss linear epsilon-vector regression (epsilon-SVR).
             </para>
             
             <code>
               min_\beta  0.5\beta^T (Q + diag(lambda)) \beta - p \sum_{i=1}^l|\beta_i| + \sum_{i=1}^l yi\beta_i,
                 s.t.     -upper_bound_i &lt;= \beta_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where Qij = yi yj xi^T xj and
              D is a diagonal matrix </para>
            
             <para>
             In L1-SVM case:</para>
             <code>
                upper_bound_i = C
                lambda_i = 0
             </code>
             <para>
             In L2-SVM case:</para>
             <code>
                upper_bound_i = INF
                lambda_i = 1/(2*C)
             </code>
             
             <para>
             Given: x, y, p, C and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 4 of Ho and Lin, 2012.</para>
             </remarks>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Double[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent`2">
             <summary>
               Coordinate descent algorithm for the L1 or L2-loss linear Support 
               Vector Regression (epsilon-SVR) learning problem in the dual form
               (-s 12 and -s 13).
             </summary>
             
             <remarks>
             <para>
               This class implements a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> learning algorithm
               specifically crafted for linear machines only. It provides a L2-regularized, L1
               or L2-loss coordinate descent learning algorithm for optimizing the dual form of
               learning. The code has been based on liblinear's method <c>solve_l2r_l1l2_svc</c>
               method, whose original description is provided below.
             </para>
             
             <para>
               Liblinear's solver <c>-s 12</c>: <c>L2R_L2LOSS_SVR_DUAL</c> and <c>-s 13</c>: 
               <c>L2R_L1LOSS_SVR_DUAL</c>. A coordinate descent algorithm for L1-loss and 
               L2-loss linear epsilon-vector regression (epsilon-SVR).
             </para>
             
             <code>
               min_\beta  0.5\beta^T (Q + diag(lambda)) \beta - p \sum_{i=1}^l|\beta_i| + \sum_{i=1}^l yi\beta_i,
                 s.t.     -upper_bound_i &lt;= \beta_i &lt;= upper_bound_i,
             </code>
             
             <para>
              where Qij = yi yj xi^T xj and
              D is a diagonal matrix </para>
            
             <para>
             In L1-SVM case:</para>
             <code>
                upper_bound_i = C
                lambda_i = 0
             </code>
             <para>
             In L2-SVM case:</para>
             <code>
                upper_bound_i = INF
                lambda_i = 1/(2*C)
             </code>
             
             <para>
             Given: x, y, p, C and eps as the stopping tolerance</para>
            
             <para>
             See Algorithm 4 of Ho and Lin, 2012.</para>
             </remarks>
             
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
             <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearNewtonMethod"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3">
            <summary>
              Base class for Coordinate descent algorithm for the L1 or L2-loss linear Support 
              Vector Regression (epsilon-SVR) learning problem in the dual form (-s 12 and -s 13).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.#ctor">
            <summary>
              Constructs a new coordinate descent algorithm for L1-loss and L2-loss SVM dual problems.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.Loss">
            <summary>
              Gets or sets the <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.Loss"/> cost function that
              should be optimized. Default is 
              <see cref="F:Accord.MachineLearning.VectorMachines.Learning.Loss.L2"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.Lagrange">
            <summary>
              Gets the value for the Lagrange multipliers
              (alpha) for every observation vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.1.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.1.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionCoordinateDescent`3.#ctor(`0,`2[],System.Double[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod">
            <summary>
              L2-regularized L2-loss linear support vector regression
              (SVR) learning algorithm in the primal formulation (-s 11).
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss support vector regression (SVR)
              learning algorithm that operates in the primal form of the optimization problem.
              This method has been based on liblinear's <c>l2r_l2_svr_fun</c> problem specification,
              optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod"> Trust-region Newton method</see>.</para>
            </remarks>
            
            <para>
              Liblinear's solver <c>-s 11</c>: <c>L2R_L2LOSS_SVR</c>. A trust region newton algorithm
              for the primal of L2-regularized, L2-loss linear epsilon-vector regression (epsilon-SVR).
            </para>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Double[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod.Create(System.Int32,Accord.Statistics.Kernels.Linear)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod`2">
            <summary>
              L2-regularized L2-loss linear support vector regression
              (SVR) learning algorithm in the primal formulation (-s 11).
            </summary>
            
            <remarks>
            <para>
              This class implements a L2-regularized L2-loss support vector regression (SVR)
              learning algorithm that operates in the primal form of the optimization problem.
              This method has been based on liblinear's <c>l2r_l2_svr_fun</c> problem specification,
              optimized using a <see cref="T:Accord.Math.Optimization.TrustRegionNewtonMethod"> Trust-region Newton method</see>.</para>
            </remarks>
            
            <para>
              Liblinear's solver <c>-s 11</c>: <c>L2R_L2LOSS_SVR</c>. A trust region newton algorithm
              for the primal of L2-regularized, L2-loss linear epsilon-vector regression (epsilon-SVR).
            </para>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionCoordinateDescent"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod`2.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.LinearRegressionNewtonMethod`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionNewtonMethod`3">
            <summary>
              Base class for newton method for linear regression learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionNewtonMethod`3.#ctor">
            <summary>
              Constructs a new Newton method algorithm for L2-regularized
              support vector regression (SVR-SVMs) primal problems.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionNewtonMethod`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 0.01.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.01.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionNewtonMethod`3.MaximumIterations">
            <summary>
              Gets or sets the maximum number of iterations that should
               be performed until the algorithm stops. Default is 1000.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionNewtonMethod`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseLinearRegressionNewtonMethod`3.#ctor(`0,`2[],System.Double[])">
            <summary>
              Obsolete.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SelectionStrategy">
            <summary>
              Gets the selection strategy to be used in SMO.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.Learning.SelectionStrategy.Sequential">
            <summary>
              Uses the sequential selection strategy as
              suggested by Keerthi et al's algorithm 1.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.Learning.SelectionStrategy.WorstPair">
            <summary>
              Always select the worst violation pair
              to be optimized first, as suggested in
              Keerthi et al's algorithm 2.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.Learning.SelectionStrategy.SecondOrder">
            <summary>
              Use a second order selection algorithm, using
              the same algorithm as LibSVM's implementation.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class follows the original algorithm by Platt with additional modifications
              by Keerthi et al.</para>
              
            <para>
              This class can also be used in combination with <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
              or <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> to learn <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              using the <c>one-vs-one</c> or <c>one-vs-all</c> multi-class decision strategies, respectively.</para>
             
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization">
                  Wikipedia, The Free Encyclopedia. Sequential Minimal Optimization. Available on:
                  http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization </a></description></item>
                <item><description>
                  <a href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf">
                  John C. Platt, Sequential Minimal Optimization: A Fast Algorithm for Training Support
                  Vector Machines. 1998. Available on: http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf </a></description></item>
                <item><description>
                  <a href="http://www.cs.iastate.edu/~honavar/keerthi-svm.pdf">
                  S. S. Keerthi et al. Improvements to Platt's SMO Algorithm for SVM Classifier Design.
                  Technical Report CD-99-14. Available on: http://www.cs.iastate.edu/~honavar/keerthi-svm.pdf </a></description></item>
                <item><description>
                  <a href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf">
                  J. P. Lewis. A Short SVM (Support Vector Machine) Tutorial. Available on:
                  http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf </a></description></item>
                </list></para>  
            </remarks>
            
            <example>
              <para>The following example shows how to use a SVM to learn a simple XOR function.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_normal" />
              
              <para>The next example shows how to solve a multi-class problem using a one-vs-one SVM 
              where the binary machines are learned using SMO.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn" />
              
              <para>The same as before, but using a Gaussian kernel.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
              <para>
              The following example shows how to learn a simple binary SVM using
               a precomputed kernel matrix obtained from a Gaussian kernel.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_precomputed" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Create(System.Int32,Accord.Statistics.Kernels.IKernel{System.Double[]})">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Learn(System.Double[][],System.Double[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Learn(System.Double[][],System.Int32[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Learn(System.Double[][],System.Boolean[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Learn(System.Double[][],System.Boolean[],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            <returns>
            A model that has learned how to produce <paramref name="y" /> given <paramref name="x" />.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm.
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class follows the original algorithm by Platt with additional modifications
              by Keerthi et al.</para>
              
            <para>
              This class can also be used in combination with <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
              or <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> to learn <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              using the <c>one-vs-one</c> or <c>one-vs-all</c> multi-class decision strategies, respectively.</para>
             
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization">
                  Wikipedia, The Free Encyclopedia. Sequential Minimal Optimization. Available on:
                  http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization </a></description></item>
                <item><description>
                  <a href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf">
                  John C. Platt, Sequential Minimal Optimization: A Fast Algorithm for Training Support
                  Vector Machines. 1998. Available on: http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf </a></description></item>
                <item><description>
                  <a href="http://www.cs.iastate.edu/~honavar/keerthi-svm.pdf">
                  S. S. Keerthi et al. Improvements to Platt's SMO Algorithm for SVM Classifier Design.
                  Technical Report CD-99-14. Available on: http://www.cs.iastate.edu/~honavar/keerthi-svm.pdf </a></description></item>
                <item><description>
                  <a href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf">
                  J. P. Lewis. A Short SVM (Support Vector Machine) Tutorial. Available on:
                  http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf </a></description></item>
                </list></para>  
            </remarks>
            
            <example>
              <para>The following example shows how to use a SVM to learn a simple XOR function.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_normal" />
              
              <para>The next example shows how to solve a multi-class problem using a one-vs-one SVM 
              where the binary machines are learned using SMO.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn" />
              
              <para>The same as before, but using a Gaussian kernel.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
              <para>
              The following example shows how to learn a simple binary SVM using
               a precomputed kernel matrix obtained from a Gaussian kernel.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_precomputed" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`2">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm (for arbitrary data types).
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class follows the original algorithm by Platt with additional modifications
              by Keerthi et al.</para>
              
            <para>
              This class can also be used in combination with <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
              or <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/> to learn <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>s
              using the <c>one-vs-one</c> or <c>one-vs-all</c> multi-class decision strategies, respectively.</para>
             
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization">
                  Wikipedia, The Free Encyclopedia. Sequential Minimal Optimization. Available on:
                  http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization </a></description></item>
                <item><description>
                  <a href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf">
                  John C. Platt, Sequential Minimal Optimization: A Fast Algorithm for Training Support
                  Vector Machines. 1998. Available on: http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf </a></description></item>
                <item><description>
                  <a href="http://www.cs.iastate.edu/~honavar/keerthi-svm.pdf">
                  S. S. Keerthi et al. Improvements to Platt's SMO Algorithm for SVM Classifier Design.
                  Technical Report CD-99-14. Available on: http://www.cs.iastate.edu/~honavar/keerthi-svm.pdf </a></description></item>
                <item><description>
                  <a href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf">
                  J. P. Lewis. A Short SVM (Support Vector Machine) Tutorial. Available on:
                  http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf </a></description></item>
                </list></para>  
            </remarks>
            
            
            <example>
              <para>The following example shows how to use a SVM to learn a simple XOR function.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_normal" />
              
              <para>The next example shows how to solve a multi-class problem using a one-vs-one SVM 
              where the binary machines are learned using SMO.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn" />
              
              <para>The same as before, but using a Gaussian kernel.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
              
              <para>
              The following example shows how to learn a simple binary SVM using
               a precomputed kernel matrix obtained from a Gaussian kernel.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_precomputed" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3">
            <summary>
              Base class for Sequential Minimal Optimization.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3"/> class.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Epsilon">
            <summary>
              Epsilon for round-off errors. Default value is 1e-6.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-2.
            </summary>
            
            <remarks>
              The criterion for completing the model training process. The default is 0.01.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Strategy">
            <summary>
              Gets or sets the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SelectionStrategy">pair selection 
              strategy</see> to be used during optimization.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.CacheSize">
            <summary>
              Gets or sets the cache size to partially store the kernel 
              matrix. Default is the same number of input vectors, meaning
              the entire kernel matrix will be computed and cached in memory.
              If set to zero, the cache will be disabled and all operations will
              be computed as needed.
            </summary>
            
            <remarks>
              In order to know how many rows can fit under a amount of memory, you can use
              <see cref="M:Accord.Statistics.Kernels.KernelFunctionCache.GetNumberOfRowsForMaximumSizeInBytes(System.Int32)"/>.
              Be sure to also test the algorithm with the cache disabled, as sometimes the
              cost of the extra memory allocations needed by the cache will be higher than
              the cost of evaluating the kernel function, specially for fast kernels such
              as <see cref="T:Accord.Statistics.Kernels.Linear"/>.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Shrinking">
            <summary>
              Gets or sets a value indicating whether shrinking heuristics should be used. Default is false. Note: 
              this property can only be used when <see cref="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Strategy"/> is set to <see cref="F:Accord.MachineLearning.VectorMachines.Learning.SelectionStrategy.SecondOrder"/>.
            </summary>
            
            <value>
              <c>true</c> to use shrinking heuristics; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Lagrange">
            <summary>
              Gets the value for the Lagrange multipliers
              (alpha) for every observation vector.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.Compact">
            <summary>
              Gets or sets whether to produce compact models. Compact
              formulation is currently limited to linear models.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.ActiveExamples">
            <summary>
              Gets the indices of the active examples (examples which have
              the corresponding Lagrange multiplier different than zero).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.NonBoundExamples">
            <summary>
              Gets the indices of the non-bounded examples (examples which
              have the corresponding Lagrange multipliers between 0 and C).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.BoundedExamples">
            <summary>
              Gets the indices of the examples at the boundary (examples
              which have the corresponding Lagrange multipliers equal to C).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.InnerRun">
            <summary>
              Runs the learning algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.examineExample(System.Int32)">
            <summary>
             Chooses which multipliers to optimize using heuristics.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.takeStep(System.Int32,System.Int32)">
            <summary>
              Analytically solves the optimization problem for two Lagrange multipliers.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.computeNoBias(System.Int32)">
            <summary>
              Computes the SVM output for a given point.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimization`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Int32[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction">
            <summary>
              Exact support vector reduction through linear dependency elimination.
            </summary>
            
            <example>
              <para>
              The following example shows how to reduce the number of support vectors in
              a SVM by removing vectors which are linearly dependent between themselves.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SupportVectorReductionTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]})">
             <summary>
             Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction"/> class.
             </summary>
             <param name="machine">The machine to be reduced.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction`1">
            <summary>
              Exact support vector reduction through linear dependency elimination.
            </summary>
            
            <example>
              <para>
              The following example shows how to reduce the number of support vectors in
              a SVM by removing vectors which are linearly dependent between themselves.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SupportVectorReductionTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction`1.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]})">
             <summary>
             Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction"/> class.
             </summary>
             <param name="machine">The machine to be reduced.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction`2">
            <summary>
              Exact support vector reduction through linear dependency elimination.
            </summary>
            
            <example>
              <para>
              The following example shows how to reduce the number of support vectors in
              a SVM by removing vectors which are linearly dependent between themselves.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SupportVectorReductionTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction`2.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`1})">
             <summary>
             Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction"/> class.
             </summary>
             <param name="machine">The machine to be reduced.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3">
            <summary>
              Exact support vector reduction through linear dependency elimination.
            </summary>
            
            <example>
              <para>
              The following example shows how to reduce the number of support vectors in
              a SVM by removing vectors which are linearly dependent between themselves.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SupportVectorReductionTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3.Threshold">
            <summary>
            Gets or sets the minimum threshold that is used to determine
            whether a weight will be kept in the machine or not. Default
            is 1e-12.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3.#ctor(`0)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction"/> algorithm.
            </summary>
            
            <param name="machine">The machine to be reduced.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3.Learn">
            <summary>
            Learns a model that can map the given inputs to the given outputs.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3.InnerRun">
            <summary>
            Runs the learning algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3.Run">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReductionBase`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorReduction"/> algorithm.
            </summary>
            
            <param name="machine">The machine to be reduced.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1">
             <summary>
               One-against-one Multi-class Kernel Support Vector Machine Classifier.
             </summary>
             
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. One of the ways
               to extend the original SVM algorithm to multiple classes is to build a one-
               against-one scheme where multiple SVMs specialize to recognize each of the
               available classes. By using a competition scheme, the original multi-class
               classification problem is then reduced to <c>n*(n/2)</c> smaller binary problems.</para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
             </remarks>
            
             <example>
             <para>
               The following example shows how to learn a linear, multi-class support vector 
               machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-class support 
               vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce 
               probability estimates (instead of simple class separation distances). The
               following example shows how to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
               within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> to generate a probabilistic
               SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
            
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1.#ctor(System.Int32,System.Func{Accord.MachineLearning.VectorMachines.SupportVectorMachine{`0}})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/> class.
            </summary>
            <param name="classes">The number of classes in the multi-class classification problem.</param>
            <param name="initializer">A function to create the inner binary support vector machines.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1.#ctor(System.Int32,`0,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/> class.
            </summary>
            
            <param name="inputs">The number of inputs by the machine.</param>
            <param name="classes">The number of classes to be handled by the machine.</param>
            <param name="kernel">The kernel function to be used in the machine.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine">
             <summary>
               One-against-one Multi-class Kernel Support Vector Machine Classifier.
             </summary>
             
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. One of the ways
               to extend the original SVM algorithm to multiple classes is to build a one-
               against-one scheme where multiple SVMs specialize to recognize each of the
               available classes. By using a competition scheme, the original multi-class
               classification problem is then reduced to <c>n*(n/2)</c> smaller binary problems.</para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
             </remarks>
            
             <example>
             <para>
               The following example shows how to learn a linear, multi-class support vector 
               machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-class support 
               vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce 
               probability estimates (instead of simple class separation distances). The
               following example shows how to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
               within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/> to generate a probabilistic
               SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.#ctor(System.Int32,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine"/> class.
            </summary>
            
            <param name="inputs">The number of inputs by the machine.</param>
            <param name="classes">The number of classes to be handled by the machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.#ctor(System.Int32,Accord.Statistics.Kernels.IKernel,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine"/> class.
            </summary>
            
            <param name="inputs">The number of inputs by the machine.</param>
            <param name="classes">The number of classes to be handled by the machine.</param>
            <param name="kernel">The kernel function to be used in the machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine[][])">
            <summary>
              Constructs a new Multi-class Kernel Support Vector Machine
            </summary>
            
            <param name="machines">
              The machines to be used in each of the pair-wise class subproblems.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>
            A new object that is a copy of this instance.
            </returns>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.MachinesCount">
            <summary>
              Gets the total number of machines
              in this multi-class classifier.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Classes">
            <summary>
              Gets the number of classes.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Inputs">
            <summary>
              Gets the number of inputs of the machines.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Machines">
            <summary>
              Gets the subproblems classifiers.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[])">
             <summary>
               Computes the given input to produce the corresponding output.
             </summary>
             
             <param name="inputs">An input vector.</param>
             
             <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],System.Double@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="output">The output of the machine. If this is a 
              <see cref="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.IsProbabilistic">probabilistic</see> machine, the
              output is the probability of the positive class. If this is
              a standard machine, the output is the distance to the decision
              hyperplane in feature space.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],System.Double@,Accord.Compat.Tuple{System.Int32,System.Int32}[]@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="output">The output of the machine. If this is a 
              <see cref="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.IsProbabilistic">probabilistic</see> machine, the
              output is the probability of the positive class. If this is
              a standard machine, the output is the distance to the decision
              hyperplane in feature space.</param>
            <param name="decisionPath">The decision path followed by the Decision
            Directed Acyclic Graph used by the <see cref="F:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod.Elimination">
            elimination</see> method.</param>
            
            <returns>The decision label for the given input.</returns>
            
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],System.Double[]@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="responses">The model response for each class.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],Accord.MachineLearning.VectorMachines.MulticlassComputeMethod,System.Double[]@,System.Double@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="method">The <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod">
              multi-class classification method</see> to use.</param>
            <param name="responses">The model response for each class.</param>
            <param name="output">The output of the machine. If this is a 
              <see cref="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.IsProbabilistic">probabilistic</see> machine, the
              output is the probability of the positive class. If this is
              a standard machine, the output is the distance to the decision
              hyperplane in feature space.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],Accord.MachineLearning.VectorMachines.MulticlassComputeMethod,System.Double[]@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="method">The <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod">
              multi-class classification method</see> to use.</param>
            <param name="responses">The model response for each class.</param>
            
            <returns>The class decision for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],Accord.MachineLearning.VectorMachines.MulticlassComputeMethod,System.Double@)">
             <summary>
               Computes the given input to produce the corresponding output.
             </summary>
             
             <param name="inputs">An input vector.</param>
             <param name="method">The <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod">
               multi-class classification method</see> to use.</param>
             <param name="output">The output of the machine. If this is a 
               <see cref="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.IsProbabilistic">probabilistic</see> machine, the
               output is the probability of the positive class. If this is
               a standard machine, the output is the distance to the decision
               hyperplane in feature space.</param>
             
             <returns>The class decision for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],Accord.MachineLearning.VectorMachines.MulticlassComputeMethod)">
             <summary>
               Computes the given input to produce the corresponding output.
             </summary>
             
             <param name="inputs">An input vector.</param>
             <param name="method">The <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod">
               multi-class classification method</see> to use.</param>
             
             <returns>The class decision for the given input.</returns>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.IsProbabilistic">
            <summary>
              Gets whether this machine has been calibrated to
              produce probabilistic outputs (through the Probability(TInput)
              and Probabilities(TInput) methods).
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Save(System.IO.Stream)">
            <summary>
              Saves the machine to a stream.
            </summary>
            
            <param name="stream">The stream to which the machine is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Save(System.String)">
            <summary>
              Saves the machine to a file.
            </summary>
            
            <param name="path">The path to the file to which the machine is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Load(System.IO.Stream)">
            <summary>
              Loads a machine from a stream.
            </summary>
            
            <param name="stream">The stream from which the machine is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Load(System.String)">
            <summary>
              Loads a machine from a file.
            </summary>
            
            <param name="path">The path to the file from which the machine is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3">
             <summary>
               One-against-one Multi-class Kernel Support Vector Machine Classifier.
             </summary>
             
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. One of the ways
               to extend the original SVM algorithm to multiple classes is to build a one-
               against-one scheme where multiple SVMs specialize to recognize each of the
               available classes. By using a competition scheme, the original multi-class
               classification problem is then reduced to <c>n*(n/2)</c> smaller binary problems.</para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
             </remarks>
             
             <example>
             <para>
               The following example shows how to learn a linear, multi-class support vector 
               machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-class support 
               vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce 
               probability estimates (instead of simple class separation distances). The
               following example shows how to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/>
               within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/> to generate a probabilistic
               SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MulticlassSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Kernel">
            <summary>
              Gets or sets the kernel function used in all machines at once.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.SupportVectorCache">
            <summary>
            Gets or sets the minimum number of shared support vectors that a
            machine should have for kernel evaluation caching to be enabled.
            Default is 64.
            </summary>
            
            <value>The cache threshold.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Compress">
            <summary>
              If the inner machines have a linear kernel, compresses
              their support vectors into a single parameter vector for
              each machine.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.#ctor(System.Int32,System.Func{`0})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3"/> class.
            </summary>
            <param name="classes">The number of classes in the multi-class classification problem.</param>
            <param name="initializer">A function to create the inner binary support vector machines.</param>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.SupportVectorCount">
            <summary>
              Gets the total number of support vectors
              in the entire multi-class machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.SupportVectorUniqueCount">
            <summary>
              Gets the number of unique support 
              vectors in the multi-class machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.SupportVectorSharedCount">
            <summary>
              Gets the number of shared support
              vectors in the multi-class machine.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.distance(System.Int32,System.Int32,`2,Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine{`0,`1,`2}.Cache)">
            <summary>
              Compute SVM output with support vector sharing.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Decide(`2)">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Decide(`2[],System.Int32[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="result">The location where to store the class-labels.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Scores(`2,System.Double[])">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and each class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the result will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns></returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Reset">
            <summary>
              Resets the cache and machine statistics
              so they can be recomputed on next evaluation.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.GetLastKernelEvaluations">
             <summary>
               Gets the total kernel evaluations performed in the last call
               to Decide(TInput) and similar functions in the current thread.
             </summary>
            
             <returns>The number of total kernel evaluations.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.GetLastKernelHits">
             <summary>
               Gets the number of cache hits during in the last call
               to Decide(TInput) and similar functions in the current thread.
             </summary>
            
             <returns>The number of cache hits in the last decision.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Dispose">
            <summary>
              Performs application-defined tasks associated with
              freeing, releasing, or resetting unmanaged resources.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Dispose(System.Boolean)">
            <summary>
              Releases unmanaged and - optionally - managed resources
            </summary>
            
            <param name="disposing">
              <c>true</c> to release both managed and unmanaged resources;
              <c>false</c> to release only unmanaged resources.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`3.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>
            A new object that is a copy of this instance.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`2">
            <summary>
              One-against-one Multi-class Kernel Support Vector Machine Classifier.
            </summary>
            
            <remarks>
            <para>
              The Support Vector Machine is by nature a binary classifier. One of the ways
              to extend the original SVM algorithm to multiple classes is to build a one-
              against-one scheme where multiple SVMs specialize to recognize each of the
              available classes. By using a competition scheme, the original multi-class
              classification problem is then reduced to <c>n*(n/2)</c> smaller binary problems.</para>
            <para>
              Currently this class supports only Kernel machines as the underlying classifiers.
              If a Linear Support Vector Machine is needed, specify a Linear kernel in the
              constructor at the moment of creation. </para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                   http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                <item><description>
                  <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                   http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                </list></para>
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`2.#ctor(System.Int32,`0,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`2"/> class.
            </summary>
            <param name="classes">The number of classes in the multi-class classification problem.</param>
            <param name="inputs">The number of inputs (length of the input vectors) accepted by the machine.</param>
            <param name="kernel">The kernel function to be used.</param>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1">
             <summary>
               One-against-all Multi-label Kernel Support Vector Machine Classifier.
             </summary>
            
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. Multiple label
               problems are problems in which an input sample is allowed to belong to one
               or more classes. A way to implement multi-label classes in support vector
               machines is to build a one-against-all decision scheme where multiple SVMs
               are trained to detect each of the available classes. </para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
            
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
             </remarks>
             
             <example>
             <para>
               The following example shows how to learn a linear, multi-label (one-vs-rest) support 
               vector machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-label (one-vs-rest) 
               support vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce probability 
               estimates (instead of simple class separation distances). The following example shows how 
               to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/> within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> 
               to generate a probabilistic SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1.#ctor(System.Int32,System.Func{Accord.MachineLearning.VectorMachines.SupportVectorMachine{`0}})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/> class.
            </summary>
            <param name="classes">The number of classes in the multi-label classification problem.</param>
            <param name="initializer">A function to create the inner binary classifiers.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1.#ctor(System.Int32,`0,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/> class.
            </summary>
            <param name="inputs">The number of inputs by the machine.</param>
            <param name="classes">The number of classes to be handled by the machine.</param>
            <param name="kernel">The kernel function to be used in the machine.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine">
             <summary>
               One-against-all Multi-label Kernel Support Vector Machine Classifier.
             </summary>
            
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. Multiple label
               problems are problems in which an input sample is allowed to belong to one
               or more classes. A way to implement multi-label classes in support vector
               machines is to build a one-against-all decision scheme where multiple SVMs
               are trained to detect each of the available classes. </para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
            
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
             </remarks>
             
             <example>
             <para>
               The following example shows how to learn a linear, multi-label (one-vs-rest) support 
               vector machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-label (one-vs-rest) 
               support vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce probability 
               estimates (instead of simple class separation distances). The following example shows how 
               to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/> within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/> 
               to generate a probabilistic SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine"/>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.#ctor(System.Int32,System.Int32)">
             <summary>
             Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine"/> class.
             </summary>
             <param name="inputs">The number of inputs by the machine.</param>
             <param name="classes">The number of classes to be handled by the machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.#ctor(System.Int32,Accord.Statistics.Kernels.IKernel,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine"/> class.
            </summary>
            
            <param name="inputs">The number of inputs by the machine.</param>
            <param name="classes">The number of classes to be handled by the machine.</param>
            <param name="kernel">The kernel function to be used in the machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine[])">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine"/> class.
            </summary>
            <param name="machines">The existing machines for detecting each of the classes against all other classes.</param>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Item(System.Int32)">
            <summary>
              Gets the classifier for class <paramref name="index"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Save(System.IO.Stream)">
            <summary>
              Saves the machine to a stream.
            </summary>
            
            <param name="stream">The stream to which the machine is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Save(System.String)">
            <summary>
              Saves the machine to a file.
            </summary>
            
            <param name="path">The path to the file to which the machine is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Load(System.IO.Stream)">
            <summary>
              Loads a machine from a stream.
            </summary>
            
            <param name="stream">The stream from which the machine is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Load(System.String)">
            <summary>
              Loads a machine from a file.
            </summary>
            
            <param name="path">The path to the file from which the machine is to be deserialized.</param>
            
            <returns>The deserialized machine.</returns>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Classes">
            <summary>
              Gets the number of classes.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Inputs">
            <summary>
              Gets the number of inputs of the machines.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Machines">
            <summary>
              Gets the subproblems classifiers.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Compute(System.Double[],System.Double@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="output">The output for the given input.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Compute(System.Double[],System.Double[]@)">
            <summary>
              Computes the given input to produce the corresponding outputs.
            </summary>
            
            <param name="inputs">An input vector.</param>
            <param name="responses">The model response for each class.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine.Compute(System.Double[])">
            <summary>
              Computes the given input to produce the corresponding outputs.
            </summary>
            
            <param name="inputs">An input vector.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MultilabelProbabilityMethod">
            <summary>
              Probability computation strategies for <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine"/>
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.MultilabelProbabilityMethod.PerClass">
            <summary>
              Probabilities should be computed per-class, meaning the probabilities among all the classe should not need to sum
              up to one. This is the default when dealing with multi-label (as opposed to mult-class) classification problems.
            </summary>
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.MultilabelProbabilityMethod.SumsToOne">
            <summary>
              Probabilities should be normalized to sum up to one. This will be done using the <see cref="M:Accord.Math.Special.Softmax(System.Double[])"/>
              function considering the output probabilities of all classes.
            </summary>
        </member>
        <member name="F:Accord.MachineLearning.VectorMachines.MultilabelProbabilityMethod.SumsToOneWithEmphasisOnWinner">
            <summary>
              Probabilities should be normalized to sum up to one. However, in a one-vs-rest setting, one of the machines will 
              have been trained to specifically distinguish between the winning class and the rest of the classes. As such the
              output of this class will be used to determine the true probability of the winning class, and the complement of
              this probabilitiy will be divided among the restant of the losing classses. The probabilities of the losing classes
              will be determined using a softmax.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3">
             <summary>
               One-against-all Multi-label Kernel Support Vector Machine Classifier.
             </summary>
            
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. Multiple label
               problems are problems in which an input sample is allowed to belong to one
               or more classes. A way to implement multi-label classes in support vector
               machines is to build a one-against-all decision scheme where multiple SVMs
               are trained to detect each of the available classes. </para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
            
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
            
             </remarks>
            
             <example>
             <para>
               The following example shows how to learn a linear, multi-label (one-vs-rest) support 
               vector machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-label (one-vs-rest) 
               support vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce probability 
               estimates (instead of simple class separation distances). The following example shows how 
               to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/> within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> 
               to generate a probabilistic SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.SupportVectorCount">
             <summary>
               Gets the total number of support vectors
               in the entire multi-label machine.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.SupportVectorUniqueCount">
             <summary>
               Gets the number of unique support
               vectors in the multi-label machine.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.SupportVectorSharedCount">
             <summary>
               Gets the number of shared support
               vectors in the multi-label machine.
             </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Method">
            <summary>
              Gets or sets the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelProbabilityMethod"/> that should be used when computing probabilities
              using the <see cref="M:Accord.MachineLearning.MultilabelLikelihoodClassifierBase`1.Probabilities(`0)"/> and related methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.ParallelOptions">
            <summary>
              Gets or sets the parallelization options used
              when deciding the class of a new sample.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Compress">
            <summary>
              If the inner machines have a linear kernel, compresses
              their support vectors into a single parameter vector for
              each machine.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.distance(System.Int32,`2,Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine{`0,`1,`2}.Cache)">
             <summary>
               Compute SVM output with support vector sharing.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Reset">
             <summary>
               Resets the cache and machine statistics
               so they can be recomputed on next evaluation.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Decide(`2,System.Int32)">
            <summary>
            Computes whether a class label applies to an <paramref name="input" /> vector.
            </summary>
            <param name="input">The input vectors that should be classified as
            any of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="classIndex">The class label index to be tested.</param>
            <returns>
            A boolean value indicating whether the given <paramref name="classIndex">
            class label</paramref> applies to the <paramref name="input" /> vector.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Decide(`2,System.Boolean[])">
            <summary>
            Computes class-label decisions for the given <paramref name="input" />.
            </summary>
            <param name="input">The input vectors that should be classified as
            any of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="result">The location where to store the class-labels.</param>
            <returns>
            A set of class-labels that best describe the <paramref name="input" />
            vectors according to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Scores(`2,System.Boolean[]@,System.Double[])">
            <summary>
            Predicts a class label vector for the given input vector, returning a
            numerical score measuring the strength of association of the input vector
            to each of the possible classes.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="decision">The class labels associated with each input
            vector, as predicted by the classifier. If passed as null, the classifier
            will create a new array.</param>
            <param name="result">An array where the scores will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns></returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.LogLikelihoods(`2,System.Boolean[]@,System.Double[])">
            <summary>
            Predicts a class label vector for the given input vector, returning the
            log-likelihoods of the input vector belonging to each possible class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="decision">The class label predicted by the classifier.</param>
            <param name="result">An array where the log-likelihoods will be stored,
            avoiding unnecessary memory allocations.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Probabilities(`2,System.Boolean[]@,System.Double[])">
            <summary>
            Predicts a class label vector for the given input vector, returning the
            log-likelihoods of the input vector belonging to each possible class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="decision">The class label predicted by the classifier.</param>
            <param name="result">An array where the log-likelihoods will be stored,
            avoiding unnecessary memory allocations.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Score(`2,System.Int32)">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and a given
            <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
            <returns>System.Double.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Decide(`2[],System.Int32[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="result">An array where the scores will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Dispose">
             <summary>
               Performs application-defined tasks associated with
               freeing, releasing, or resetting unmanaged resources.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.Dispose(System.Boolean)">
             <summary>
               Releases unmanaged and - optionally - managed resources
             </summary>
            
             <param name="disposing">
               <c>true</c> to release both managed and unmanaged resources;
               <c>false</c> to release only unmanaged resources.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.GetLastKernelEvaluations">
             <summary>
               Gets the total kernel evaluations performed in the last call
               to Decide(TInput) and similar functions in the current thread.
             </summary>
            
             <returns>The number of total kernel evaluations.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.GetLastKernelHits">
             <summary>
               Gets the number of cache hits during in the last call
               to Decide(TInput) and similar functions in the current thread.
             </summary>
            
             <returns>The number of cache hits in the last decision.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3.#ctor(System.Int32,System.Func{`0})">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3"/> class.
            </summary>
            <param name="classes">The number of classes in the multi-label classification problem.</param>
            <param name="initializer">A function to create the inner binary classifiers.</param>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`2">
             <summary>
               One-against-all Multi-label Kernel Support Vector Machine Classifier.
             </summary>
            
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. Multiple label
               problems are problems in which an input sample is allowed to belong to one
               or more classes. A way to implement multi-label classes in support vector
               machines is to build a one-against-all decision scheme where multiple SVMs
               are trained to detect each of the available classes. </para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
            
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html </a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html </a></description></item>
                 </list></para>
             </remarks>
            
             <example>
             <para>
               The following example shows how to learn a linear, multi-label (one-vs-rest) support 
               vector machine using the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_ldcd" />
             
             <para>
               The following example shows how to learn a non-linear, multi-label (one-vs-rest) 
               support vector machine using the <see cref="T:Accord.Statistics.Kernels.Gaussian"/> kernel and the 
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/> algorithm. </para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_gaussian" />
               
             <para>
               Support vector machines can have their weights calibrated in order to produce probability 
               estimates (instead of simple class separation distances). The following example shows how 
               to use <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticOutputCalibration"/> within <see cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning`1"/> 
               to generate a probabilistic SVM:</para>
             <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\MultilabelSupportVectorLearningTest.cs" region="doc_learn_calibration" />
             </example>
             
             <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MultilabelSupportVectorLearning`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`2.#ctor(System.Int32,`0,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`3"/> class.
            </summary>
            <param name="classes">The number of classes in the multi-class classification problem.</param>
            <param name="inputs">The number of inputs (length of the input vectors) accepted by the machine.</param>
            <param name="kernel">The kernel function to be used.</param>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">
             <summary>
              Linear Support Vector Machine (SVM).
             </summary>
             
             <remarks>
             <para>
               This class implements a linear support vector machine classifier. For its kernel
               counterpart, which can produce non-linear decision boundaries, please check 
               <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1"/> and <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2"/>.</para>
               
             <para>
               Note: a linear SVM model can be converted to <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> and 
               <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>. This means that linear and logistic regressions
               can be created using any of the highly optimized LIBLINEAR learning algorithms
               such as <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearCoordinateDescent"/>, <see cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>,
               <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent"/> and <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent"/>.
               </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description><a href="http://en.wikipedia.org/wiki/Support_vector_machine">
                   http://en.wikipedia.org/wiki/Support_vector_machine </a></description></item>
                 <item><description><a href="http://www.kernel-machines.org/">
                   http://www.kernel-machines.org/ </a></description></item>
               </list></para>
             </remarks>
            
             <example>
               <para>
               The first example shows how to learn a linear SVM. However, since the
               problem being learned is not linearly separable, the classifier will
               not be able to produce a perfect decision boundary.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_linear" />
               
               <para>
               The second example shows how to learn an SVM using a  standard kernel 
               that operates on vectors of doubles. With kernels, it is possible to
               produce non-linear boundaries that perfectly separate the data.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_normal" />
               
               <para>
               The third example shows how to learn an SVM using a Sparse kernel that 
               operates on sparse vectors.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_sparse" />
             </example>
            
             <seealso cref="N:Accord.Statistics.Kernels"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/>
            
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.#ctor(System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> class.
            </summary>
            
            <param name="inputs">The number of inputs for this machine.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>
            A new object that is a copy of this instance.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.op_Explicit(Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression)~Accord.MachineLearning.VectorMachines.SupportVectorMachine">
            <summary>
            Performs an explicit conversion from <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> to <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.
            </summary>
            
            <param name="regression">The linear regression to be converted.</param>
            
            <returns>The result of the conversion.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.FromRegression(Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression)">
            <summary>
            Performs an explicit conversion from <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/> to <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.
            </summary>
            
            <param name="regression">The linear regression to be converted.</param>
            
            <returns>The result of the conversion.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.op_Explicit(Accord.Statistics.Models.Regression.LogisticRegression)~Accord.MachineLearning.VectorMachines.SupportVectorMachine">
            <summary>
            Performs an explicit conversion from <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> to <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.
            </summary>
            
            <param name="regression">The logistic regression to be converted.</param>
            
            <returns>The result of the conversion.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.FromLogisticRegression(Accord.Statistics.Models.Regression.LogisticRegression)">
            <summary>
            Performs an explicit conversion from <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/> to <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>.
            </summary>
            
            <param name="regression">The logistic regression to be converted.</param>
            
            <returns>The result of the conversion.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.FromWeights(System.Double[],System.Int32)">
            <summary>
              Creates a new linear <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> 
              with the given set of linear <paramref name="weights"/>.
            </summary>
            
            <param name="weights">The machine's linear coefficients.</param>
            <param name="interceptIndex">The index of the intercept term in the given weights vector.</param>
            
            <returns>
              A <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> whose linear coefficients
              are defined by the given <paramref name="weights"/> vector.
            </returns>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1">
             <summary>
              Sparse Kernel Support Vector Machine (kSVM)
             </summary>
            
             <remarks>
             <para>
               The original optimal hyperplane algorithm (SVM) proposed by Vladimir Vapnik in 1963 was a
               linear classifier. However, in 1992, Bernhard Boser, Isabelle Guyon and Vapnik suggested
               a way to create non-linear classifiers by applying the kernel trick (originally proposed
               by Aizerman et al.) to maximum-margin hyperplanes. The resulting algorithm is formally
               similar, except that every dot product is replaced by a non-linear kernel function.</para>
             <para>
               This allows the algorithm to fit the maximum-margin hyperplane in a transformed feature space.
               The transformation may be non-linear and the transformed space high dimensional; thus though
               the classifier is a hyperplane in the high-dimensional feature space, it may be non-linear in
               the original input space.</para>
            
             <para>
               The machines are also able to learn sequence classification problems in which the input vectors
               can have arbitrary length. For an example on how to do that, please see the documentation page
               for the <see cref="T:Accord.Statistics.Kernels.DynamicTimeWarping">DynamicTimeWarping kernel</see>.</para>
            
             <para>
               References:
               <list type="bullet">
                 <item><description><a href="http://en.wikipedia.org/wiki/Support_vector_machine">
                   http://en.wikipedia.org/wiki/Support_vector_machine </a></description></item>
                 <item><description><a href="http://www.kernel-machines.org/">
                   http://www.kernel-machines.org/ </a></description></item>
               </list></para>
             </remarks>
            
             <example>
               <para>
               The first example shows how to learn an SVM using a 
               standard kernel that operates on vectors of doubles.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_normal" />
               
               <para>
               The second example shows how to learn an SVM using a 
               Sparse kernel that operates on sparse vectors.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_sparse" />
             </example>
            
             <seealso cref="N:Accord.Statistics.Kernels"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
             <seealso cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/>
            
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1.#ctor(System.Int32,`0)">
             <summary>
             Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1"/> class.
             </summary>
            
             <param name="inputs">The number of inputs for this machine.</param>
             <param name="kernel">The kernel function to be used.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1.ToWeights">
             <summary>
               Converts a <see cref="T:Accord.Statistics.Kernels.Linear"/>-kernel machine into an array of
               linear coefficients. The first position in the array is the
               <see cref="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Threshold"/> value. If this
               machine is not linear, an exception will be thrown.
             </summary>
            
             <returns>
               An array of linear coefficients representing this machine.
             </returns>
            
             <exception cref="T:System.InvalidOperationException">
               Thrown if the <see cref="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Kernel">kernel function</see> is not <see cref="T:Accord.Statistics.Kernels.Linear"/>.
             </exception>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>
            A new object that is a copy of this instance.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2">
            <summary>
             Sparse Kernel Support Vector Machine (kSVM)
            </summary>
            
            <remarks>
            <para>
              The original optimal hyperplane algorithm (SVM) proposed by Vladimir Vapnik in 1963 was a
              linear classifier. However, in 1992, Bernhard Boser, Isabelle Guyon and Vapnik suggested
              a way to create non-linear classifiers by applying the kernel trick (originally proposed
              by Aizerman et al.) to maximum-margin hyperplanes. The resulting algorithm is formally
              similar, except that every dot product is replaced by a non-linear kernel function.</para>
            <para>
              This allows the algorithm to fit the maximum-margin hyperplane in a transformed feature space.
              The transformation may be non-linear and the transformed space high dimensional; thus though
              the classifier is a hyperplane in the high-dimensional feature space, it may be non-linear in
              the original input space.</para> 
              
            <para>
              The machines are also able to learn sequence classification problems in which the input vectors
              can have arbitrary length. For an example on how to do that, please see the documentation page 
              for the <see cref="T:Accord.Statistics.Kernels.DynamicTimeWarping">DynamicTimeWarping kernel</see>.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Support_vector_machine">
                  http://en.wikipedia.org/wiki/Support_vector_machine </a></description></item>
                <item><description><a href="http://www.kernel-machines.org/">
                  http://www.kernel-machines.org/ </a></description></item>
              </list></para>  
            </remarks>
            
            <example>
              <para>
              The first example shows how to learn an SVM using a 
              standard kernel that operates on vectors of doubles.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_normal" />
              
              <para>
              The second example shows how to learn an SVM using a 
              Sparse kernel that operates on sparse vectors.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\VectorMachines\SequentialMinimalOptimizationTest.cs" region="doc_xor_sparse" />
            </example>
            
            <seealso cref="N:Accord.Statistics.Kernels"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MultilabelSupportVectorMachine`1"/>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Kernel">
            <summary>
              Gets or sets the kernel used by this machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.IsProbabilistic">
            <summary>
              Gets whether this machine has been calibrated to
              produce probabilistic outputs (through the Probability(TInput)
              method).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.SupportVectors">
            <summary>
              Gets or sets the collection of support vectors used by this machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Weights">
            <summary>
              Gets or sets the collection of weights used by this machine.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Threshold">
            <summary>
              Gets or sets the threshold (bias) term for this machine.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.#ctor(System.Int32,`0)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2"/> class.
            </summary>
            
            <param name="inputs">The length of the input vectors expected by the machine.</param>
            <param name="kernel">The kernel function to be used.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Decide(`1)">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Score(`1[],System.Double[])">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and each class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the result will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns>System.Double[].</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.LogLikelihood(`1[],System.Double[])">
            <summary>
            Predicts a class label vector for the given input vectors, returning the
            log-likelihood that the input vector belongs to its predicted class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the log-likelihoods will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns>System.Double[].</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Compress">
            <summary>
              If this machine has a linear kernel, compresses all
              support vectors into a single parameter vector.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Compute(`1,System.Double@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <remarks>
              For a binary decision problem, the decision for the negative
              or positive class is typically computed by taking the sign of
              the machine's output.
            </remarks>
            
            <param name="inputs">An input vector.</param>
            <param name="output">The output of the machine. If this is a 
              <see cref="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.IsProbabilistic">probabilistic</see> machine, the
              output is the probability of the positive class. If this is
              a standard machine, the output is the distance to the decision
              hyperplane in feature space.</param>
            
            <returns>The decision label for the given input.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Compute(`1)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            
            <remarks>
              For a binary decision problem, the decision for the negative
              or positive class is typically computed by taking the sign of
              the machine's output.
            </remarks>
            
            <param name="inputs">An input vector.</param>
            
            <returns>The output for the given input. In a typical classification
            problem, the sign of this value should be considered as the class label.</returns>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.ToWeights">
            <summary>
              Converts a <see cref="T:Accord.Statistics.Kernels.Linear"/>-kernel
              machine into an array of linear coefficients. The first position
              in the array is the <see cref="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Threshold"/> value.
            </summary>
            
            <returns>
              An array of linear coefficients representing this machine.
            </returns>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Inputs">
            <summary>
              Gets the number of inputs accepted by this machine.
            </summary>
            
            <remarks>
              If the number of inputs is zero, this means the machine
              accepts a indefinite number of inputs. This is often the
              case for kernel vector machines using a sequence kernel.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.IsCompact">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.Clone">
            <summary>
            Creates a new object that is a copy of the current instance.
            </summary>
            <returns>
            A new object that is a copy of this instance.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.op_Explicit(Accord.MachineLearning.VectorMachines.SupportVectorMachine{`0,`1})~Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression">
            <summary>
            Performs an explicit conversion from <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> to <see cref="T:Accord.Statistics.Models.Regression.Linear.MultipleLinearRegression"/>.
            </summary>
            
            <param name="svm">The <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">linear Support Vector Machine</see> to be converted.</param>
            
            <returns>The result of the conversion.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.op_Explicit(Accord.MachineLearning.VectorMachines.SupportVectorMachine{`0,`1})~Accord.Statistics.Models.Regression.LogisticRegression">
            <summary>
            Performs an explicit conversion from <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> to <see cref="T:Accord.Statistics.Models.Regression.LogisticRegression"/>.
            </summary>
            
            <param name="svm">The <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">linear Support Vector Machine</see> to be converted.</param>
            
            <returns>The result of the conversion.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsOne`2">
            <summary>
              One-Vs-One construction for solving multi-class
              classification using a set of binary classifiers.
            </summary>
            
            <typeparam name="TBinary">The type for the binary classifier to be used.</typeparam>
            <typeparam name="TInput">The type for the classifier inputs. Default is double[].</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Indices">
            <summary>
              Gets the pair of class indices handled by each inner binary classification model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Models">
            <summary>
              Gets the inner binary classification models.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.ParallelOptions">
            <summary>
            Gets or sets the parallelization options for this algorithm.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Token">
            <summary>
            Gets or sets a cancellation token that can be used
            to cancel the algorithm while it is running.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Method">
            <summary>
              Gets or sets the multi-class classification method to be
              used when deciding for the class of a given input vector.
              Default is <see cref="F:Accord.MachineLearning.VectorMachines.MulticlassComputeMethod.Elimination"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Track">
             <summary>
               Gets or sets whether to track the decision path associated
               with each decision. The track will be available through the
               <see cref="M:Accord.MachineLearning.OneVsOne`2.GetLastDecisionPath"/> method. Default is true.
             </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.#ctor(System.Int32,System.Func{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.OneVsOne`2"/> class.
            </summary>
            
            <param name="classes">The number of classes in the multi-class classification problem.</param>
            <param name="initializer">A function to create the inner binary classifiers.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.GetLastDecisionPath">
            <summary>
              Gets the last decision path used during the last call to any of the
              model evaluation (Decide, Distance, LogLikelihood, Probability) methods
              in the current thread. This method is thread-safe and returns the value 
              obtained in the last call on the current thread. 
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.LastDecisionPath">
            <summary>
              Gets the last decision path without cloning.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.GetClassifierForClassPair(System.Int32,System.Int32)">
            <summary>
              Gets the inner binary classification model used to distinguish between
              the given pair of classes.
            </summary>
            <param name="classA">The class index for the first class.</param>
            <param name="classB">The class index for the second class.</param>
            <returns>A binary classifier that can distinguish between the given classes.</returns>
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Item(System.Int32,System.Int32)">
            <summary>
              Gets or sets the inner binary classification model used 
              to distinguish between the given pair of classes.
            </summary>
            <param name="classA">The class index for the first class.</param>
            <param name="classB">The class index for the second class.</param>
            <returns>A binary classifier that can distinguish between the given classes.</returns>
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Item(System.Int32)">
            <summary>
              Gets a inner binary classification model inside this <see cref="T:Accord.MachineLearning.OneVsOne`1"/>
              classifier, together with the pair of classes that it has been designed to
              distinguish.
            </summary>
            
            <param name="index">The index of the model (up to <see cref="P:Accord.MachineLearning.OneVsOne`2.Count"/>).</param>
            
        </member>
        <member name="P:Accord.MachineLearning.OneVsOne`2.Count">
            <summary>
              Gets the number of inner binary classification models used by
              this instance. It should correspond to <c>(c * (c - 1)) / 2</c>
              where <c>c</c> is the number of classes.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.Decide(`1)">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <returns>
            A class-label that best described <paramref name="input" /> according
            to this classifier.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.Decide(`1[],System.Int32[])">
            <summary>
            Computes a class-label decision for a given <paramref name="input" />.
            </summary>
            <param name="input">The input vector that should be classified into
            one of the <see cref="P:Accord.MachineLearning.ITransform.NumberOfOutputs" /> possible classes.</param>
            <param name="result">The location where to store the class-labels.</param>
            <returns>A class-label that best described <paramref name="input" /> according
            to this classifier.</returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.Scores(`1,System.Double[])">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and each class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the result will be stored,
            avoiding unnecessary memory allocations.</param>
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.LogLikelihoods(`1,System.Double[])">
            <summary>
            Predicts a class label vector for the given input vector, returning the
            log-likelihoods of the input vector belonging to each possible class.
            </summary>
            <param name="input">A set of input vectors.</param>
            <param name="result">An array where the probabilities will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns></returns>
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.LogLikelihood(`1,System.Int32)">
            <summary>
            Computes the log-likelihood that the given input vector
            belongs to the specified <paramref name="classIndex" />.
            </summary>
            <param name="input">The input vector.</param>
            <param name="classIndex">The index of the class whose score will be computed.</param>
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through all machines
              contained inside this multi-class support vector machine.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`2.System#Collections#IEnumerable#GetEnumerator">
            <summary>
              Returns an enumerator that iterates through all machines
              contained inside this multi-class support vector machine.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.OneVsOne`1">
            <summary>
              One-Vs-One construction for solving multi-class
              classification using a set of binary classifiers.
            </summary>
            
            <typeparam name="TBinary">The type for the binary classifier to be used.</typeparam>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.OneVsOne`1.#ctor(System.Int32,System.Func{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.OneVsOne`1"/> class.
            </summary>
            
            <param name="classes">The number of classes in the multi-class classification problem.</param>
            <param name="initializer">A function to create the inner binary classifiers.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.BootstrapFittingFunction">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/> instead.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Bootstrap">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/> instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bootstrap.B">
            <summary>
              Gets the number B of bootstrap samplings
              to be drawn from the population dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bootstrap.Samples">
            <summary>
              Gets the total number of samples in the population dataset.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bootstrap.Subsamples">
            <summary>
              Gets the bootstrap samples drawn from
              the population dataset as indices.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Bootstrap.Fitting">
            <summary>
              Gets or sets the model fitting function.
            </summary>
            <remarks>
              The fitting function should accept an array of integers containing the
              indexes for the training samples, an array of integers containing the
              indexes for the validation samples and should return information about
              the model fitted using those two subsets of the available data.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.Bootstrap.RunInParallel">
            <summary>
              Gets or sets a value indicating whether to use parallel
              processing through the use of multiple threads or not.
              Default is true.
            </summary>
            
            <value><c>true</c> to use multiple threads; otherwise, <c>false</c>.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.#ctor(System.Int32,System.Int32)">
            <summary>
              Creates a new Bootstrap estimation algorithm.
            </summary>
            
            <param name="size">The size of the complete dataset.</param>
            <param name="subsamples">The number B of bootstrap resamplings to perform.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>
              Creates a new Bootstrap estimation algorithm.
            </summary>
            
            <param name="size">The size of the complete dataset.</param>
            <param name="subsamples">The number B of bootstrap resamplings to perform.</param>
            <param name="subsampleSize">The number of samples in each subsample. Default
              is to use the total number of samples in the population dataset.</param>.
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.#ctor(System.Int32,System.Int32[][])">
            <summary>
              Creates a new Bootstrap estimation algorithm.
            </summary>
            
            <param name="size">The size of the complete dataset.</param>
            <param name="resamplings">The indices of the bootstrap samplings.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.CreatePartitions(System.Int32,System.Int32[]@,System.Int32[]@)">
            <summary>
              Gets the indices for the training and validation 
              sets for the specified validation fold index.
            </summary>
            
            <param name="index">The index of the validation fold.</param>
            <param name="trainingSet">The indices for the observations in the training set.</param>
            <param name="validationSet">The indices for the observations in the validation set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.Compute">
            <summary>
              Computes the cross validation algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.GetPartitionSize(System.Int32,System.Int32@,System.Int32@)">
            <summary>
              Gets the number of instances in training and validation
              sets for the specified validation fold index.
            </summary>
            
            <param name="index">The index of the bootstrap sample.</param>
            <param name="trainingCount">The number of instances in the training set.</param>
            <param name="validationCount">The number of instances in the validation set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.Bootstrap.Samplings(System.Int32,System.Int32,System.Int32)">
            <summary>
              Draws the bootstrap samples from the population.
            </summary>
            
            <param name="size">The size of the samples to be drawn.</param>
            <param name="resamplings">The number of samples to drawn.</param>
            <param name="subsampleSize">The size of the samples to be drawn.</param>
            
            <returns>The indices of the samples in the original set.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.BootstrapResult">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/> instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapResult.Settings">
            <summary>
              Gets the <see cref="T:Accord.MachineLearning.Bootstrap"/>   
              object used to generate this result.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapResult.Training">
            <summary>
              Gets the performance statistics for the training set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapResult.Validation">
            <summary>
              Gets the performance statistics for the validation set.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.BootstrapResult.Estimate">
            <summary>
              Gets the 0.632 bootstrap estimate.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapResult.#ctor(Accord.MachineLearning.Bootstrap,Accord.MachineLearning.BootstrapValues[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.BootstrapResult"/> class.
            </summary>
            
            <param name="owner">The <see cref="T:Accord.MachineLearning.Bootstrap"/> that is creating this result.</param>
            <param name="models">The models created during the cross-validation runs.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapResult.Save(System.IO.Stream)">
            <summary>
              Saves the result to a stream.
            </summary>
            
            <param name="stream">The stream to which the result is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapResult.Save(System.String)">
            <summary>
              Saves the result to a stream.
            </summary>
            
            <param name="path">The stream to which the result is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapResult.Load(System.IO.Stream)">
            <summary>
              Loads a result from a stream.
            </summary>
            
            <param name="stream">The stream from which the result is to be deserialized.</param>
            
            <returns>The deserialized result.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapResult.Load(System.String)">
            <summary>
              Loads a result from a stream.
            </summary>
            
            <param name="path">The path to the file from which the result is to be deserialized.</param>
            
            <returns>The deserialized result.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.BootstrapValues">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.Bootstrap`3"/> instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapValues.ValidationValue">
            <summary>
              Gets the validation value for the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapValues.ValidationVariance">
            <summary>
              Gets the variance of the validation 
              value for the model, if available.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapValues.TrainingValue">
            <summary>
              Gets the training value for the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapValues.TrainingVariance">
            <summary>
              Gets the variance of the training 
              value for the model, if available.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.BootstrapValues.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapValues.#ctor(System.Double,System.Double)">
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.BootstrapValues.#ctor(System.Double,System.Double,System.Double,System.Double)">
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            <param name="validationVariance">The variance of the validation values.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.KModes`1">
            <summary>
              k-Modes algorithm.
            </summary>
            
            <remarks>
              The k-Modes algorithm is a variant of the k-Means which instead of locating means attempts to locate 
              the modes of a set of points. As the algorithm does not require explicit numeric manipulation of the
              input points (such as addition and division to compute the means), the algorithm can be used with 
              arbitrary (generic) data structures.
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.KModes"/>
            <seealso cref="T:Accord.MachineLearning.KMeans"/>
            <seealso cref="T:Accord.MachineLearning.MeanShift"/>
            
            <example>
              How to perform clustering with K-Modes.
              <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\KModesTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Clusters">
            <summary>
              Gets the clusters found by K-modes.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.K">
            <summary>
              Gets the number of clusters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Dimension">
            <summary>
              Gets the dimensionality of the data space.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.ComputeError">
            <summary>
              Gets or sets whether the clustering distortion error (the
              average distance between all data points and the cluster
              centroids) should be computed at the end of the algorithm.
              The result will be stored in <see cref="P:Accord.MachineLearning.KModes`1.Error"/>. Default is true.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Distance">
            <summary>
              Gets or sets the distance function used
              as a distance metric between data points.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations to
              be performed by the method. If set to zero, no
              iteration limit will be imposed. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Tolerance">
            <summary>
              Gets or sets the relative convergence threshold
              for stopping the algorithm. Default is 1e-5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Iterations">
            <summary>
              Gets the number of iterations performed in the
              last call to this class' Compute methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Error">
            <summary>
              Gets the cluster distortion error (the average distance 
              between data points and the cluster centroids) after the 
              last call to this class' Compute methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KModes`1.Initialization">
            <summary>
              Gets or sets the strategy used to initialize the
              centroids of the clustering algorithm. Default is
              <see cref="F:Accord.MachineLearning.Seeding.KMeansPlusPlus"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KModes`1.#ctor(System.Int32,System.Func{`0[],`0[],System.Double})">
            <summary>
              Initializes a new instance of KModes algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>       
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KModes`1.#ctor(System.Int32,Accord.Math.Distances.IDistance{`0[]})">
            <summary>
              Initializes a new instance of KModes algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>       
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KModes`1.Compute(`0[][])">
            <summary>
              Divides the input data into K clusters. 
            </summary>     
            
            <param name="points">The data where to compute the algorithm.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KModes`1.Learn(`0[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
            <exception cref="T:System.ArgumentNullException">points</exception>
            <exception cref="T:System.ArgumentException">Not enough points. There should be more points than the number K of clusters.</exception>
        </member>
        <member name="M:Accord.MachineLearning.KModes`1.converged(`0[][],`0[][])">
            <summary>
              Determines if the algorithm has converged by comparing the
              centroids between two consecutive iterations.
            </summary>
            
            <param name="centroids">The previous centroids.</param>
            <param name="newCentroids">The new centroids.</param>
            
            <returns>Returns <see langword="true"/> if all centroids had a percentage change
               less than <see param="threshold"/>. Returns <see langword="false"/> otherwise.</returns>
               
        </member>
        <member name="T:Accord.MachineLearning.KModes">
            <summary>
              k-Modes algorithm.
            </summary>
            
            <remarks>
            <para>
              The k-Modes algorithm is a variant of the k-Means which instead of 
              locating means attempts to locate the modes of a set of points. As
              the algorithm does not require explicit numeric manipulation of the
              input points (such as addition and division to compute the means),
              the algorithm can be used with arbitrary (generic) data structures.</para>
            <para>
              This is the specialized, non-generic version of the K-Modes algorithm
              that is set to work on <see cref="T:System.Int32"/> arrays.</para>
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.KModes`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.KModes.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of K-Modes algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>    
            
        </member>
        <member name="T:Accord.MachineLearning.ModelStorageMode">
            <summary>
              Modes for storing models.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.ModelStorageMode.AllModels">
            <summary>
              Stores a model on each iteration. This is the most
              intensive method, but enables a quick restoration 
              of any point on the learning history.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.ModelStorageMode.MinimumOnly">
            <summary>
              Stores only the model which had shown the minimum 
              validation value in the training history. All other
              models are discarded and only their validation and
              training values will be registered.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.ModelStorageMode.MaximumOnly">
            <summary>
              Stores only the model which had shown the maximum 
              validation value in the training history. All other
              models are discarded and only their validation and
              training values will be registered.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.EarlyStopping`1">
            <summary>
              Early stopping training procedure.
            </summary>
            
            <remarks>
              The early stopping training procedure monitors a validation set
              during training to determine when a learning algorithm has stopped
              learning and started to overfit data. This class keeps an history
              of training and validation errors and will keep the best model found
              during learning.
            </remarks>
            
            <typeparam name="TModel">The type of the model to be trained.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations
              performed by the early stopping algorithm. Default
              is 0 (run until convergence).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.Tolerance">
            <summary>
              Gets or sets the minimum tolerance value used
              to determine convergence. Default is 1e-5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.History">
            <summary>
              Gets the history of training and validation values 
              registered at each iteration of the learning algorithm.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.MinValidationValue">
            <summary>
              Gets the model with minimum validation error found during learning.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.MaxValidationValue">
            <summary>
              Gets the model with maximum validation error found during learning.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.Mode">
            <summary>
              Gets or sets the storage policy for the procedure.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.EarlyStopping`1.IterationFunction">
            <summary>
              Gets or sets the iteration function for the procedure. This
              function will be called on each iteration and should run one
              iteration of the learning algorithm for the given model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.EarlyStopping`1.#ctor">
            <summary>
              Creates a new early stopping procedure object.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.EarlyStopping`1.Compute">
            <summary>
              Starts the model training, calling the <see cref="P:Accord.MachineLearning.EarlyStopping`1.IterationFunction"/>
              on each iteration.
            </summary>
            
            <returns>True if the model training has converged, false otherwise.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchRange">
            <summary>
              Range of parameters to be tested in a grid search.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchRange.Name">
            <summary>
              Gets or sets the name of the parameter from which the range belongs to.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchRange.Values">
            <summary>
              Gets or sets the range of values that should be tested for this parameter.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRange.#ctor(System.String,System.Double,System.Double,System.Double)">
            <summary>
              Constructs a new GridsearchRange object.
            </summary>
            
            <param name="name">The name for this parameter.</param>
            <param name="start">The starting value for this range.</param>
            <param name="end">The end value for this range.</param>
            <param name="step">The step size for this range.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRange.#ctor(System.String,System.Double[])">
            <summary>
              Constructs a new GridSearchRange object.
            </summary>
            
            <param name="name">The name for this parameter.</param>
            <param name="values">The array of values to try.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRange.GetParameters">
            <summary>
              Gets the array of GridSearchParameters to try.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchRangeCollection">
            <summary>
              GridSearchRange collection.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRangeCollection.#ctor(Accord.MachineLearning.GridSearchRange[])">
            <summary>
              Constructs a new collection of GridsearchRange objects.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRangeCollection.GetKeyForItem(Accord.MachineLearning.GridSearchRange)">
            <summary>
              Returns the identifying value for an item on this collection.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRangeCollection.Add(System.String,System.Double[])">
            <summary>
              Adds a parameter range to the end of the GridsearchRangeCollection.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchParameter">
            <summary>
              Contains the name and value of a parameter that should be used during fitting.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchParameter.Name">
            <summary>
              Gets the name of the parameter
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchParameter.Value">
            <summary>
              Gets the value of the parameter.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.#ctor(System.String,System.Double)">
            <summary>
              Constructs a new parameter.
            </summary>
            
            <param name="name">The name for the parameter.</param>
            <param name="value">The value for the parameter.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.Equals(System.Object)">
            <summary>
              Determines whether the specified object is equal
              to the current GridSearchParameter object.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.GetHashCode">
            <summary>
              Returns the hash code for this GridSearchParameter
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.op_Equality(Accord.MachineLearning.GridSearchParameter,Accord.MachineLearning.GridSearchParameter)">
            <summary>
              Compares two GridSearchParameters for equality.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.op_Inequality(Accord.MachineLearning.GridSearchParameter,Accord.MachineLearning.GridSearchParameter)">
            <summary>
              Compares two GridSearchParameters for inequality.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.ToString">
            <summary>
              Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String" /> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.op_Implicit(Accord.MachineLearning.GridSearchParameter)~System.Double">
            <summary>
            Performs an implicit conversion from <see cref="T:Accord.MachineLearning.GridSearchParameter"/> to <see cref="T:System.Double"/>.
            </summary>
            
            <param name="param">The parameter to be converted.</param>
            
            <returns>The value of the parameter's <see cref="P:Accord.MachineLearning.GridSearchParameter.Value"/>.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchParameterCollection">
            <summary>
              Grid search parameter collection.
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.Performance.GridSearch"/>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameterCollection.#ctor(Accord.MachineLearning.GridSearchParameter[])">
            <summary>
              Constructs a new collection of GridsearchParameter objects.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameterCollection.#ctor(System.Collections.Generic.IEnumerable{Accord.MachineLearning.GridSearchParameter})">
            <summary>
              Constructs a new collection of GridsearchParameter objects.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameterCollection.GetKeyForItem(Accord.MachineLearning.GridSearchParameter)">
            <summary>
              Returns the identifying value for an item on this collection.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidationValues`1">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationValues`1.Model">
            <summary>
              Gets the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationValues`1.ValidationValue">
            <summary>
              Gets the validation value for the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationValues`1.ValidationVariance">
            <summary>
              Gets the variance of the validation 
              value for the model, if available.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationValues`1.TrainingValue">
            <summary>
              Gets the training value for the model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationValues`1.TrainingVariance">
            <summary>
              Gets the variance of the training 
              value for the model, if available.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationValues`1.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues`1.#ctor(System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues`1.#ctor(System.Double,System.Double,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            <param name="validationVariance">The variance of the validation values.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues`1.#ctor(`0,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="model">The fitted model.</param>
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues`1.#ctor(`0,System.Double,System.Double,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="model">The fitted model.</param>
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            <param name="validationVariance">The variance of the validation values.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidationResult`1">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationResult`1.Settings">
            <summary>
              Gets the <see cref="T:Accord.MachineLearning.CrossValidation`1"/>   
              object used to generate this result.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationResult`1.Training">
            <summary>
              Gets the performance statistics for the training set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationResult`1.Validation">
            <summary>
              Gets the performance statistics for the validation set.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationResult`1.Models">
            <summary>
              Gets the models created for each fold of the cross validation.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationResult`1.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationResult`1.#ctor(Accord.MachineLearning.CrossValidation{`0},Accord.MachineLearning.CrossValidationValues{`0}[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.CrossValidationResult`1"/> class.
            </summary>
            
            <param name="owner">The <see cref="T:Accord.MachineLearning.CrossValidation`1"/> that is creating this result.</param>
            <param name="models">The models created during the cross-validation runs.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationResult`1.Save(System.IO.Stream)">
            <summary>
              Saves the result to a stream.
            </summary>
            
            <param name="stream">The stream to which the result is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationResult`1.Save(System.String)">
            <summary>
              Saves the result to a stream.
            </summary>
            
            <param name="path">The stream to which the result is to be serialized.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationResult`1.Load(System.IO.Stream)">
            <summary>
              Loads a result from a stream.
            </summary>
            
            <param name="stream">The stream from which the result is to be deserialized.</param>
            
            <returns>The deserialized result.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationResult`1.Load(System.String)">
            <summary>
              Loads a result from a stream.
            </summary>
            
            <param name="path">The path to the file from which the result is to be deserialized.</param>
            
            <returns>The deserialized result.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidationValues">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues.#ctor(System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues.#ctor(System.Double,System.Double,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            <param name="validationVariance">The variance of the validation values.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues.#ctor(System.Object,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="model">The fitted model.</param>
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues.#ctor(System.Object,System.Double,System.Double,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="model">The fitted model.</param>
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            <param name="validationVariance">The variance of the validation values.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues.Create``1(``0,System.Double,System.Double,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="model">The fitted model.</param>
            <param name="trainingValue">The training value for the model.</param>
            <param name="validationValue">The validation value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            <param name="validationVariance">The variance of the validation values.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationValues.Create``1(``0,System.Double,System.Double)">
            <summary>
              Creates a new Cross-Validation Values class.
            </summary>
            
            <param name="model">The fitted model.</param>
            <param name="trainingValue">The training value for the model.</param>
            <param name="trainingVariance">The variance of the training values.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidationStatistics">
            <summary>
              Summary statistics for a cross-validation trial.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.Values">
            <summary>
              Gets the values acquired during the cross-validation.
              Most often those will be the errors for each folding.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.Variances">
            <summary>
              Gets the variance for each value acquired during the cross-validation.
              Most often those will be the error variance for each folding.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.Sizes">
            <summary>
              Gets the number of samples used to compute the variance
              of the values acquired during the cross-validation.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.Mean">
            <summary>
              Gets the mean of the performance statistics.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.Variance">
            <summary>
              Gets the variance of the performance statistics.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.StandardDeviation">
            <summary>
              Gets the standard deviation of the performance statistics.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.PooledVariance">
            <summary>
              Gets the pooled variance of the performance statistics.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.PooledStandardDeviation">
            <summary>
              Gets the pooled standard deviation of the performance statistics.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidationStatistics.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationStatistics.#ctor(System.Int32[],System.Double[])">
            <summary>
              Create a new cross-validation statistics class.
            </summary>
            
            <param name="sizes">The number of samples used to compute the statistics.</param>
            <param name="statistics">The performance statistics gathered during the run.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidationStatistics.#ctor(System.Int32[],System.Double[],System.Double[])">
            <summary>
              Create a new cross-validation statistics class.
            </summary>
            
            <param name="sizes">The number of samples used to compute the statistics.</param>
            <param name="statistics">The performance statistics gathered during the run.</param>
            <param name="variances">The variance of the statistics gathered during the run, if available.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidation">
            <summary>
              k-Fold cross-validation. Please only use the static methods contained in this class,
              the rest are marked as obsolete.
            </summary>
            
            <remarks>
            <para>
              Cross-validation is a technique for estimating the performance of a predictive
              model. It can be used to measure how the results of a statistical analysis will
              generalize to an independent data set. It is mainly used in settings where the
              goal is prediction, and one wants to estimate how accurately a predictive model
              will perform in practice.</para>
            <para>
              One round of cross-validation involves partitioning a sample of data into
              complementary subsets, performing the analysis on one subset (called the
              training set), and validating the analysis on the other subset (called the
              validation set or testing set). To reduce variability, multiple rounds of 
              cross-validation are performed using different partitions, and the validation 
              results are averaged over the rounds.</para> 
              
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">
                  Wikipedia, The Free Encyclopedia. Cross-validation (statistics). Available on:
                  http://en.wikipedia.org/wiki/Cross-validation_(statistics) </a></description></item>
              </list></para> 
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.#ctor(System.Int32)">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.#ctor(System.Int32,System.Int32)">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.#ctor(System.Int32[],System.Int32,System.Int32)">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.#ctor(System.Int32[],System.Int32)">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.CrossValidation`2"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.Splittings(System.Int32,System.Int32)">
            <summary>
              Obsolete. Please use <see cref="M:Accord.Statistics.Classes.Random(System.Int32,System.Int32)"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.Splittings(System.Int32[],System.Int32,System.Int32)">
            <summary>
              Obsolete. Please use Classes.Random(labels, classes, folds) instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation.Create``4(System.Int32,Accord.MachineLearning.Performance.CreateLearnerFromSubset{``1,``2,``3},Accord.MachineLearning.Performance.LearnNewModel{``1,``2,``3,``0},Accord.MachineLearning.Performance.ComputeLoss{``3,Accord.MachineLearning.Performance.SetResult{``0}},``2[],``3[])">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.Performance.CrossValidation`4"/> algorithm.
            </summary>
            
            <typeparam name="TModel">The type of the machine learning model whose parameters should be searched.</typeparam>
            <typeparam name="TLearner">The type of the learning algorithm used to learn <typeparamref name="TModel"/>.</typeparam>
            <typeparam name="TInput">The type of the input data. Default is double[].</typeparam>
            <typeparam name="TOutput">The type of the output data. Default is int.</typeparam>
            
            <param name="k">The number of folds in the k-fold cross-validation. Default is 10.</param>
            <param name="learner">A function that can create a <typeparamref name="TModel"/> given training parameters.</param>
            <param name="loss">A function that can measure how far model predictions are from the expected ground-truth.</param>
            <param name="fit">A function that specifies how to create a new model using the teacher learning algorirhm.</param>
            <param name="x">The input data to be used during training.</param>
            <param name="y">The output data to be used during training.</param>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
            </example>
            
            <returns>A grid-search algorithm that has been configured with the given parameters.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidationFittingFunction`1">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> instead.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.CrossValidation`1">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.CrossValidation`3"/> instead.
            </summary>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\CrossValidationTest.cs" region="doc_learn_hmm" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\DecisionTrees\DecisionTreeTest.cs" region="doc_cross_validation" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\Bayes\NaiveBayesTest.cs" region="doc_cross_validation" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidation`1.Fitting">
            <summary>
              Gets or sets the model fitting function.
            </summary>
            <remarks>
              The fitting function should accept an array of integers containing the
              indexes for the training samples, an array of integers containing the
              indexes for the validation samples and should return information about
              the model fitted using those two subsets of the available data.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidation`1.Folds">
            <summary>
              Gets the array of data set indexes contained in each fold.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidation`1.Indices">
            <summary>
             Gets the array of fold indices for each point in the data set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidation`1.K">
            <summary>
              Gets the number of folds in the k-fold cross validation.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidation`1.Samples">
            <summary>
              Gets the total number of data samples in the data set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.CrossValidation`1.RunInParallel">
            <summary>
              Gets or sets a value indicating whether to use parallel
              processing through the use of multiple threads or not.
              Default is true.
            </summary>
            
            <value><c>true</c> to use multiple threads; otherwise, <c>false</c>.</value>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.#ctor(System.Int32)">
            <summary>
              Creates a new k-fold cross-validation algorithm.
            </summary>
            
            <param name="size">The total number samples in the entire dataset.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.#ctor(System.Int32,System.Int32)">
            <summary>
              Creates a new k-fold cross-validation algorithm.
            </summary>
            
            <param name="size">The total number samples in the entire dataset.</param>
            <param name="folds">The number of folds, usually denoted as <c>k</c> (default is 10).</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.#ctor(System.Int32[],System.Int32,System.Int32)">
            <summary>
              Creates a new k-fold cross-validation algorithm.
            </summary>
            
            <param name="labels">A vector containing class labels.</param>
            <param name="classes">The number of different classes in <paramref name="labels"/>.</param>
            <param name="folds">The number of folds, usually denoted as <c>k</c> (default is 10).</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.#ctor(System.Int32[],System.Int32)">
            <summary>
              Creates a new k-fold cross-validation algorithm.
            </summary>
            
            <param name="indices">An already created set of fold indices for each sample in a dataset.</param>
            <param name="folds">The total number of folds referenced in the <paramref name="indices"/> parameter.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.CreatePartitions(System.Int32,System.Int32[]@,System.Int32[]@)">
            <summary>
              Gets the indices for the training and validation 
              sets for the specified validation fold index.
            </summary>
            
            <param name="validationFoldIndex">The index of the validation fold.</param>
            <param name="trainingSet">The indices for the observations in the training set.</param>
            <param name="validationSet">The indices for the observations in the validation set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.GetPartitionSize(System.Int32,System.Int32@,System.Int32@)">
            <summary>
              Gets the number of instances in training and validation
              sets for the specified validation fold index.
            </summary>
            
            <param name="validationFoldIndex">The index of the validation fold.</param>
            <param name="trainingCount">The number of instances in the training set.</param>
            <param name="validationCount">The number of instances in the validation set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.CrossValidation`1.Compute">
            <summary>
              Computes the cross validation algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.GaussianMixtureModel">
            <summary>
              Gaussian mixture model clustering.
            </summary>
            
            <remarks>
              Gaussian Mixture Models are one of most widely used model-based 
              clustering methods. This specialized class provides a wrap-up
              around the
              <see cref="T:Accord.Statistics.Distributions.Multivariate.MultivariateMixture`1">
              Mixture&lt;NormalDistribution&gt;</see> distribution and provides
              mixture initialization using the K-Means clustering algorithm.
            </remarks>
            
            <example>
              <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\GaussianMixtureModelTest.cs" region="doc_learn" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.KMeans"/> 
            <seealso cref="T:Accord.MachineLearning.MeanShift"/> 
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations to
              be performed by the method. If set to zero, no
              iteration limit will be imposed. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Tolerance">
            <summary>
              Gets or sets the convergence criterion for the
              Expectation-Maximization algorithm. Default is 1e-3.
            </summary>
            
            <value>The convergence threshold.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.ComputeLabels">
            <summary>
              Gets or sets whether cluster labels should be computed
              at the end of the learning iteration. Setting to <c>False</c>
              might save a few computations in case they are not necessary.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.ComputeLogLikelihood">
            <summary>
              Gets or sets whether the log-likelihood should be computed
              at the end of the learning iteration. Setting to <c>False</c>
              might save a few computations in case they are not necessary.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.LogLikelihood">
            <summary>
              Gets the log-likelihood of the model at the last iteration.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Initializations">
            <summary>
              Gets or sets how many random initializations to try. 
              Default is 3.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Iterations">
            <summary>
              Gets how many iterations have been performed in the last call
              to <see cref="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][])"/>.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.UseLogarithm">
            <summary>
              Gets or sets whether to make computations using the log
              -domain. This might improve accuracy on large datasets.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Options">
            <summary>
              Gets or sets the fitting options for the component
              Gaussian distributions of the mixture model.
            </summary>
            
            <value>The fitting options for inner Gaussian distributions.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Gaussians">
            <summary>
              Gets the Gaussian components of the mixture model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> class.
            </summary>
            
            <param name="components">
              The number of clusters in the clustering problem. This will be
              used to set the number of components in the mixture model.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.#ctor(Accord.MachineLearning.KMeans)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> class.
            </summary>
            
            <param name="kmeans">
              The initial solution as a K-Means clustering.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.#ctor(Accord.Statistics.Distributions.Univariate.Mixture{Accord.Statistics.Distributions.Univariate.NormalDistribution})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> class.
            </summary>
            
            <param name="mixture">
              The initial solution as a mixture of normal distributions.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.#ctor(Accord.Statistics.Distributions.Multivariate.MultivariateMixture{Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> class.
            </summary>
            
            <param name="mixture">
              The initial solution as a mixture of normal distributions.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][])">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],System.Double[])">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Learn(System.Double[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(System.Double[][],System.Double[])">
            <summary>
              Initializes the model with initial values obtained 
              through a run of the K-Means clustering algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(Accord.MachineLearning.KMeans)">
            <summary>
              Initializes the model with initial values obtained 
              through a run of the K-Means clustering algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(Accord.Statistics.Distributions.Univariate.NormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(System.Double[],Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(System.Double[],Accord.Statistics.Distributions.Univariate.NormalDistribution[])">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(Accord.Statistics.Distributions.Multivariate.MultivariateMixture{Accord.Statistics.Distributions.Multivariate.MultivariateNormalDistribution})">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(Accord.Statistics.Distributions.Univariate.Mixture{Accord.Statistics.Distributions.Univariate.NormalDistribution})">
            <summary>
              Initializes the model with initial values.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.ToMixtureDistribution">
            <summary>
              Gets a copy of the mixture distribution modeled by this Gaussian Mixture Model.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],Accord.MachineLearning.GaussianMixtureModelOptions)">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],System.Double)">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Clusters">
            <summary>
              Gets the collection of clusters currently modeled by the
              clustering algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.GaussianMixtureModelOptions">
            <summary>
              Options for Gaussian Mixture Model fitting.
            </summary>
            
            <remarks>
              This class provides different options that can be passed to a 
              <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> object when calling its
              <see cref="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],Accord.MachineLearning.GaussianMixtureModelOptions)"/>
              method.
            </remarks>
            
            <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.Threshold">
            <summary>
              Gets or sets the convergence criterion for the
              Expectation-Maximization algorithm. Default is 1e-3.
            </summary>
            
            <value>The convergence threshold.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.Iterations">
            <summary>
              Gets or sets the maximum number of iterations
              to be performed by the Expectation-Maximization
              algorithm. Default is zero (iterate until convergence).
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.Logarithm">
            <summary>
              Gets or sets whether to make computations using the log
              -domain. This might improve accuracy on large datasets.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.Weights">
            <summary>
              Gets or sets the sample weights. If set to null,
              the data will be assumed equal weights. Default
              is null.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.NormalOptions">
            <summary>
              Gets or sets the fitting options for the component
              Gaussian distributions of the mixture model.
            </summary>
            
            <value>The fitting options for inner Gaussian distributions.</value>
            
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.ParallelOptions">
            <summary>
              Gets or sets parallelization options.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModelOptions.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModelOptions"/> class.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.KNearestNeighbors">
            <summary>
              K-Nearest Neighbor (k-NN) algorithm.
            </summary>
            
            <remarks>
            <para> The k-nearest neighbor algorithm (k-NN) is a method for classifying objects
              based on closest training examples in the feature space. It is amongst the simplest
              of all machine learning algorithms: an object is classified by a majority vote of
              its neighbors, with the object being assigned to the class most common amongst its 
              k nearest neighbors (k is a positive integer, typically small).</para>
              
            <para>If k = 1, then the object is simply assigned to the class of its nearest neighbor.</para>
            
            <para>
              References:
              <list type="bullet">
                <item><description>
                  Wikipedia contributors. "K-nearest neighbor algorithm." Wikipedia, The
                  Free Encyclopedia. Wikipedia, The Free Encyclopedia, 10 Oct. 2012. Web.
                  9 Nov. 2012. http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm </description></item>
              </list>
            </para>
            </remarks>
            
            <example>
            <para>
              The first example shows how to create and use a k-Nearest Neighbor algorithm to classify
              a set of numeric vectors in a multi-class decision problem involving 3 classes. It also shows
              how to compute class decisions for a new sample and how to measure the performance of a classifier.</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_learn" />
              <code source="Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_serialization" />
            
            <para>
              The second example show how to use a different distance metric when computing k-NN:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_learn_distance" />
            
            <para>
              The k-Nearest neighbor algorithm implementation in the framework can also be used with any instance 
              data type. For such cases, the framework offers a generic version of the classifier. The third example
              shows how to use the generic kNN classifier to perform the direct classification of actual text samples:</para>
              <code source="Unit Tests\Accord.Tests.MachineLearning\KNearestNeighbors\KNearestNeighborsTest.cs" region="doc_learn_text" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.KNearestNeighbors`1"/>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.#ctor">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.#ctor(System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.#ctor(System.Int32,Accord.Math.Distances.IMetric{System.Double[]})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.Scores(System.Double[],System.Double[])">
            <summary>
            Computes a numerical score measuring the association between
            the given <paramref name="input" /> vector and each class.
            </summary>
            <param name="input">The input vector.</param>
            <param name="result">An array where the result will be stored,
            avoiding unnecessary memory allocations.</param>
            <returns>System.Double[].</returns>
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.GetNearestNeighbors(System.Double[],System.Int32[]@)">
            <summary>
              Gets the top <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K"/> points that are the closest
              to a given <paramref name="input">reference point</paramref>.
            </summary>
            
            <param name="input">The query point whose neighbors will be found.</param>
            <param name="labels">The label for each neighboring point.</param>
            
            <returns>
              An array containing the top <see cref="P:Accord.MachineLearning.BaseKNearestNeighbors`3.K"/> points that are 
              at the closest possible distance to <paramref name="input"/>.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.FromTree(Accord.Collections.KDTree{System.Int32},System.Int32,System.Int32,System.Double[][],System.Int32[])">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/> algorithm from an existing
              <see cref="T:Accord.Collections.KDTree`1"/>. The tree must have been created using the input
              points and the point's class labels as the associated node information.
            </summary>
            
            <param name="tree">The <see cref="T:Accord.Collections.KDTree`1"/> containing the input points and their integer labels.</param>
            <param name="k">The number of nearest neighbors to be used in the decision.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            <param name="inputs">The input data points.</param>
            <param name="outputs">The associated labels for the input points.</param>
            
            <returns>A <see cref="T:Accord.MachineLearning.KNearestNeighbors"/> algorithm initialized from the tree.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.Learn(System.Double[][],System.Int32[],System.Double[])">
            <summary>
              Learns a model that can map the given inputs to the given outputs.
            </summary>
            
            <param name="x">The model inputs.</param>
            <param name="y">The desired outputs associated with each <paramref name="x">inputs</paramref>.</param>
            <param name="weights">The weight of importance for each input-output pair (if supported by the learning algorithm).</param>
            
            <returns>A model that has learned how to produce <paramref name="y"/> given <paramref name="x"/>.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.#ctor(System.Int32,System.Double[][],System.Int32[])">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
            <param name="k">The number of nearest neighbors to be used in the decision.</param>
            
            <param name="inputs">The input data points.</param>
            <param name="outputs">The associated labels for the input points.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.#ctor(System.Int32,System.Int32,System.Double[][],System.Int32[])">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
            <param name="k">The number of nearest neighbors to be used in the decision.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            
            <param name="inputs">The input data points.</param>
            <param name="outputs">The associated labels for the input points.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.#ctor(System.Int32,System.Int32,System.Double[][],System.Int32[],Accord.Math.Distances.IMetric{System.Double[]})">
            <summary>
              Creates a new <see cref="T:Accord.MachineLearning.KNearestNeighbors"/>.
            </summary>
            
            <param name="k">The number of nearest neighbors to be used in the decision.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            <param name="inputs">The input data points.</param>
            <param name="outputs">The associated labels for the input points.</param>
            <param name="distance">The distance measure to use.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.KNearestNeighbors.ClassCount">
            <summary>
              Gets the number of class labels
              handled by this classifier.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.Compute(System.Double[])">
            <summary>
              Computes the most likely label of a new given point.
            </summary>
            
            <param name="input">A point to be classified.</param>
            
            <returns>The most likely label for the given point.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.Compute(System.Double[],System.Double@)">
            <summary>
              Computes the most likely label of a new given point.
            </summary>
            
            <param name="input">A point to be classified.</param>
            <param name="response">A value between 0 and 1 giving 
            the strength of the classification in relation to the
            other classes.</param>
            
            <returns>The most likely label for the given point.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.KNearestNeighbors.Compute(System.Double[],System.Double[]@)">
            <summary>
              Computes the most likely label of a new given point.
            </summary>
            
            <param name="input">A point to be classified.</param>
            <param name="scores">The distance score for each possible class.</param>
            
            <returns>The most likely label for the given point.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitSetValidation">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetValidation.#ctor(System.Int32,System.Double)">
            <summary>
              Creates a new split-set validation algorithm.
            </summary>
            
            <param name="size">The total number of available samples.</param>
            <param name="proportion">The desired proportion of samples in the training
            set in comparison with the testing set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetValidation.#ctor(System.Int32,System.Double,System.Int32[])">
            <summary>
              Creates a new split-set validation algorithm.
            </summary>
            
            <param name="size">The total number of available samples.</param>
            <param name="proportion">The desired proportion of samples in the training
            set in comparison with the testing set.</param>
            <param name="outputs">The output labels to be balanced between the sets.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitSetStatistics`1">
            <summary>
              Summary statistics for a Split-set validation trial.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetStatistics`1.Model">
            <summary>
              Gets the model created with the 
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.SplitSetStatistics`1.Value">
            <summary>
              Gets the values acquired during the cross-validation.
              Most often those will be the errors for each folding.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetStatistics`1.Variance">
            <summary>
              Gets the variance for each value acquired during the cross-validation.
              Most often those will be the error variance for each folding.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetStatistics`1.Size">
            <summary>
              Gets the number of samples used to compute the variance
              of the values acquired during the validation.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetStatistics`1.StandardDeviation">
            <summary>
              Gets the standard deviation of the performance statistic.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetStatistics`1.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetStatistics`1.#ctor(`0,System.Int32,System.Double,System.Double)">
            <summary>
              Create a new split-set statistics class.
            </summary>
            
            <param name="model">The generated model.</param>
            <param name="size">The number of samples used to compute the statistic.</param>
            <param name="value">The performance statistic gathered during the run.</param>
            <param name="variance">The variance of the performance statistic during the run.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitSetStatistics">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/> instead.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetStatistics.#ctor(System.Object,System.Int32,System.Double,System.Double)">
            <summary>
              Create a new split-set statistics class.
            </summary>
            
            <param name="model">The generated model.</param>
            <param name="size">The number of samples used to compute the statistic.</param>
            <param name="value">The performance statistic gathered during the run.</param>
            <param name="variance">The variance of the performance statistic during the run.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetStatistics.Create``1(``0,System.Int32,System.Double,System.Double)">
            <summary>
              Create a new split-set statistics class.
            </summary>
            
            <param name="model">The generated model.</param>
            <param name="size">The number of samples used to compute the statistic.</param>
            <param name="value">The performance statistic gathered during the run.</param>
            <param name="variance">The variance of the performance statistic during the run.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitSetResult`1">
            <summary>
              Obsolete. Please refer to <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`2"/> instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetResult`1.Settings">
            <summary>
              Gets the <see cref="T:Accord.MachineLearning.CrossValidation`1"/>   
              object used to generate this result.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetResult`1.Training">
            <summary>
              Gets the performance statistics for the training set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetResult`1.Validation">
            <summary>
              Gets the performance statistics for the validation set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetResult`1.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetResult`1.#ctor(Accord.MachineLearning.SplitSetValidation{`0},Accord.MachineLearning.SplitSetStatistics{`0},Accord.MachineLearning.SplitSetStatistics{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.SplitSetValidation`1"/> class.
            </summary>
            
            <param name="owner">The <see cref="T:Accord.MachineLearning.SplitSetValidation`1"/> that is creating this result.</param>
            <param name="training">The training set statistics.</param>
            <param name="testing">The testing set statistics.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitValidationFittingFunction`1">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/> instead.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitValidationEvaluateFunction`1">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/> instead.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.SplitSetValidation`1">
            <summary>
              Obsolete. Please use <see cref="T:Accord.MachineLearning.Performance.SplitSetValidation`3"/> instead.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.Indices">
            <summary>
              Gets the group labels assigned to each of the data samples.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.Proportion">
            <summary>
              Gets the desired proportion of cases in
              the training set in comparison to the
              testing set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.IsStratified">
            <summary>
              Gets or sets a value indicating whether the prevalence of
              an output label should be balanced between training and
              testing sets.
            </summary>
            
            <value>
            	<c>true</c> if this instance is stratified; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.ValidationSet">
            <summary>
              Gets the indices of elements in the validation set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.TrainingSet">
            <summary>
              Gets the indices of elements in the training set.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.Fitting">
            <summary>
              Get or sets the model fitting function.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.SplitSetValidation`1.Evaluation">
            <summary>
              Gets or sets the performance estimation function.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetValidation`1.#ctor(System.Int32,System.Double)">
            <summary>
              Creates a new split-set validation algorithm.
            </summary>
            
            <param name="size">The total number of available samples.</param>
            <param name="proportion">The desired proportion of samples in the training
            set in comparison with the testing set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetValidation`1.#ctor(System.Int32,System.Double,System.Int32[])">
            <summary>
              Creates a new split-set validation algorithm.
            </summary>
            
            <param name="size">The total number of available samples.</param>
            <param name="proportion">The desired proportion of samples in the training
            set in comparison with the testing set.</param>
            <param name="outputs">The output labels to be balanced between the sets.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.SplitSetValidation`1.Compute">
            <summary>
              Computes the split-set validation algorithm.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchFittingFunction`1">
            <summary>
              Delegate for grid search fitting functions.
            </summary>
            
            <typeparam name="TModel">The type of the model to fit.</typeparam>
            
            <param name="parameters">The collection of parameters to be used in the fitting process.</param>
            <param name="error">The error (or any other performance measure) returned by the model.</param>
            <returns>The model fitted to the data using the given parameters.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearch`1">
             <summary>
               Grid search procedure for automatic parameter tuning.
             </summary>
             
             <remarks>
               Grid Search tries to find the best combination of parameters across
               a range of possible values that produces the best fit model. If there
               are two parameters, each with 10 possible values, Grid Search will try
               an exhaustive evaluation of the model using every combination of points,
               resulting in 100 model fits.
             </remarks>
             
             <typeparam name="TModel">The type of the model to be tuned.</typeparam>
             
             <example>
               How to fit a Kernel Support Vector Machine using Grid Search.
               <code>
               // Example binary data
               double[][] inputs =
               {
                   new double[] { -1, -1 },
                   new double[] { -1,  1 },
                   new double[] {  1, -1 },
                   new double[] {  1,  1 }
               };
            
               int[] xor = // xor labels
               {
                   -1, 1, 1, -1
               };
            
               // Declare the parameters and ranges to be searched
               GridSearchRange[] ranges = 
               {
                   new GridSearchRange("complexity", new double[] { 0.00000001, 5.20, 0.30, 0.50 } ),
                   new GridSearchRange("degree",     new double[] { 1, 10, 2, 3, 4, 5 } ),
                   new GridSearchRange("constant",   new double[] { 0, 1, 2 } )
               };
            
            
               // Instantiate a new Grid Search algorithm for Kernel Support Vector Machines
               var gridsearch = new GridSearch&lt;KernelSupportVectorMachine>(ranges);
            
               // Set the fitting function for the algorithm
               gridsearch.Fitting = delegate(GridSearchParameterCollection parameters, out double error)
               {
                   // The parameters to be tried will be passed as a function parameter.
                   int degree = (int)parameters["degree"].Value;
                   double constant = parameters["constant"].Value;
                   double complexity = parameters["complexity"].Value;
            
                   // Use the parameters to build the SVM model
                   Polynomial kernel = new Polynomial(degree, constant);
                   KernelSupportVectorMachine ksvm = new KernelSupportVectorMachine(kernel, 2);
            
                   // Create a new learning algorithm for SVMs
                   SequentialMinimalOptimization smo = new SequentialMinimalOptimization(ksvm, inputs, xor);
                   smo.Complexity = complexity;
            
                   // Measure the model performance to return as an out parameter
                   error = smo.Run();
            
                   return ksvm; // Return the current model
               };
            
            
               // Declare some out variables to pass to the grid search algorithm
               GridSearchParameterCollection bestParameters; double minError;
            
               // Compute the grid search to find the best Support Vector Machine
               KernelSupportVectorMachine bestModel = gridsearch.Compute(out bestParameters, out minError);
               </code>
             </example>
             
        </member>
        <member name="P:Accord.MachineLearning.GridSearch`1.ParallelOptions">
            <summary>
            Gets or sets the parallelization options for this algorithm.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GridSearch`1.Token">
            <summary>
            Gets or sets a cancellation token that can be used
            to cancel the algorithm while it is running.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearch`1.#ctor(Accord.MachineLearning.GridSearchRange[])">
            <summary>
              Constructs a new Grid search algorithm.
            </summary>
            
            <param name="parameterRanges">The range of parameters to search.</param>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearch`1.Fitting">
            <summary>
              A function that fits a model using the given parameters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearch`1.ParameterRanges">
            <summary>
              The range of parameters to consider during search.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearch`1.Compute(Accord.MachineLearning.GridSearchParameterCollection@,System.Double@)">
            <summary>
              Searches for the best combination of parameters that results in the most accurate model.
            </summary>
            
            <param name="bestParameters">The best combination of parameters found by the grid search.</param>
            <param name="error">The minimum error of the best model found by the grid search.</param>
            <returns>The best model found during the grid search.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearch`1.Compute">
            <summary>
              Searches for the best combination of parameters that results in the most accurate model.
            </summary>
            
            <returns>The results found during the grid search.</returns>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchResult`1">
            <summary>
              Contains results from the grid-search procedure.
            </summary>
            
            <typeparam name="TModel">The type of the model to be tuned.</typeparam>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Parameters">
            <summary>
              Gets all combination of parameters tried.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Models">
            <summary>
              Gets all models created during the search.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Errors">
            <summary>
              Gets the error for each of the created models.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Index">
            <summary>
              Gets the index of the best found model
              in the <see cref="P:Accord.MachineLearning.GridSearchResult`1.Models"/> collection.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Model">
            <summary>
              Gets the best model found.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Parameter">
            <summary>
              Gets the best parameter combination found.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Error">
            <summary>
              Gets the minimum error found.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.GridSearchResult`1.Count">
            <summary>
              Gets the size of the grid used in the grid-search.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchResult`1.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GridSearchResult`1"/> class.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GridSearchResult`1.#ctor(System.Int32,Accord.MachineLearning.GridSearchParameterCollection[],`0[],System.Double[],System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GridSearchResult`1"/> class.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.Seeding">
            <summary>
              Initialization schemes for clustering algorithms.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.Seeding.Fixed">
            <summary>
              Do not perform initialization.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.Seeding.Uniform">
            <summary>
              Randomly sample points to become centroids.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.Seeding.KMeansPlusPlus">
            <summary>
              Use the kmeans++ seeding algorithm for generating initial centroids.
            </summary>
            
        </member>
        <member name="F:Accord.MachineLearning.Seeding.PamBuild">
            <summary>
              Use the PAM BUILD algorithm for generating initial centroids.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.KMeans">
             <summary>
               Lloyd's k-Means clustering algorithm.
             </summary>
             
             <remarks>
             <para>
               In statistics and machine learning, k-means clustering is a method
               of cluster analysis which aims to partition n observations into k 
               clusters in which each observation belongs to the cluster with the
               nearest mean.</para>
             <para>
               It is similar to the expectation-maximization algorithm for mixtures
               of Gaussians in that they both attempt to find the centers of natural
               clusters in the data as well as in the iterative refinement approach
               employed by both algorithms.</para> 
             
             <para>
               The algorithm is composed of the following steps:
               <list type="number">
                 <item><description>
                     Place K points into the space represented by the objects that are
                     being clustered. These points represent initial group centroids.
                 </description></item>
                 <item><description>
                     Assign each object to the group that has the closest centroid.
                 </description></item>
                 <item><description>
                     When all objects have been assigned, recalculate the positions
                     of the K centroids.
                 </description></item>
                 <item><description>
                     Repeat Steps 2 and 3 until the centroids no longer move. This
                     produces a separation of the objects into groups from which the
                     metric to be minimized can be calculated.
                 </description></item>
               </list></para>
             
             <para>
               This particular implementation uses the squared Euclidean distance
               as a similarity measure in order to form clusters. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   Wikipedia, The Free Encyclopedia. K-means clustering. Available on:
                   http://en.wikipedia.org/wiki/K-means_clustering </description></item>
                 <item><description>
                   Matteo Matteucci. A Tutorial on Clustering Algorithms. Available on:
                   http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/kmeans.html </description></item>
               </list></para>
             </remarks>
             
             <example>
             <para>
               How to perform clustering with K-Means.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\KMeansTest.cs" region="doc_learn" />
               
             <para>
               How to perform clustering with K-Means applying different weights to different columns (dimensions) in the data.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\KMeansTest.cs" region="doc_learn_weights" />
               
             <para>
               How to perform clustering with K-Means with mixed discrete, continuous and categorical data.</para>
               <code source="Unit Tests\Accord.Tests.MachineLearning\Clustering\KMeansTest.cs" region="doc_learn_mixed" />
               
             <para>
               The following example demonstrates how to use the K-Means algorithm for color clustering. It is the same code which can be 
               found in the <a href="https://github.com/accord-net/framework/wiki/Sample-applications#clustering-k-means-and-meanshift">
               color clustering sample application</a>.</para>
               
             <code source="Unit Tests\Accord.Tests.Vision\ColorClusteringTest.cs" region="doc_kmeans" />
             
             <para>
               The original image is shown below:</para>
             
               <img src="..\images\kmeans-start.png" />
               
             <para>
               The resulting image will be:</para>
             
               <img src="..\images\kmeans-end.png" />
             
             </example>
             
             <seealso cref="T:Accord.MachineLearning.KModes`1"/>
             <seealso cref="T:Accord.MachineLearning.MeanShift"/>
             <seealso cref="T:Accord.MachineLearning.GaussianMixtureModel"/>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Clusters">
            <summary>
              Gets the clusters found by K-means.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Centroids">
            <summary>
              Gets or sets the cluster centroids. 
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.K">
            <summary>
              Gets the number of clusters.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Dimension">
            <summary>
              Gets the dimensionality of the data space.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Distance">
            <summary>
              Gets or sets the distance function used
              as a distance metric between data points.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.ComputeCovariances">
            <summary>
              Gets or sets whether covariance matrices for the clusters should 
              be computed at the end of an iteration. Default is true.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.ComputeError">
            <summary>
              Gets or sets whether the clustering distortion error (the
              average distance between all data points and the cluster
              centroids) should be computed at the end of the algorithm.
              The result will be stored in <see cref="P:Accord.MachineLearning.KMeans.Error"/>. Default is true.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.MaxIterations">
            <summary>
              Gets or sets the maximum number of iterations to
              be performed by the method. If set to zero, no
              iteration limit will be imposed. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Tolerance">
            <summary>
              Gets or sets the relative convergence threshold
              for stopping the algorithm. Default is 1e-5.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Iterations">
            <summary>
              Gets the number of iterations performed in the
              last call to this class' Compute methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Error">
            <summary>
              Gets the cluster distortion error after the 
              last call to this class' Compute methods.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeans.UseSeeding">
            <summary>
              Gets or sets the strategy used to initialize the
              centroids of the clustering algorithm. Default is
              <see cref="F:Accord.MachineLearning.Seeding.KMeansPlusPlus"/>.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.#ctor(System.Int32,System.Func{System.Double[],System.Double[],System.Double})">
            <summary>
              Initializes a new instance of KMeans algorithm
            </summary>
            
            <param name="k">The number of clusters to divide input data.</param>       
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the K-Means algorithm
            </summary>
            
            <param name="k">The number of clusters to divide the input data into.</param>    
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.#ctor(System.Int32,Accord.Math.Distances.IDistance{System.Double[]})">
            <summary>
              Initializes a new instance of the KMeans algorithm
            </summary>
            
            <param name="k">The number of clusters to divide the input data into.</param>    
            <param name="distance">The distance function to use. Default is to use the 
            <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Randomize(System.Double[][])">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            
            <param name="points">The data to randomize the algorithm.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Learn(System.Double[][],System.Double[])">
            <summary>
            Learns a model that can map the given inputs to the desired outputs.
            </summary>
            <param name="x">The model inputs.</param>
            <param name="weights">The weight of importance for each input sample.</param>
            <returns>A model that has learned how to produce suitable outputs
            given the input data <paramref name="x" />.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][])">
            <summary>
              Divides the input data into K clusters. 
            </summary>
            
            <param name="data">The data where to compute the algorithm.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][],System.Double[])">
            <summary>
              Divides the input data into K clusters. 
            </summary>
            
            <param name="data">The data where to compute the algorithm.</param>
            <param name="weights">The weight associated with each data point.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.KMeans.ComputeInformation(System.Double[][])">
            <summary>
            Computes the information about each cluster (covariance, proportions and error).
            </summary>
            
            <param name="data">The data points.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.ComputeInformation(System.Double[][],System.Int32[])">
            <summary>
            Computes the information about each cluster (covariance, proportions and error).
            </summary>
            
            <param name="data">The data points.</param>
            <param name="labels">The assigned labels.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.compute(System.Double[][],System.Double[],System.Double)">
            <summary>
              Divides the input data into K clusters. 
            </summary>
            
            <param name="data">The data where to compute the algorithm.</param>
            <param name="weights">The weight to consider for each data sample. This is used in weighted K-Means</param>
            <param name="weightSum">The total sum of the weights in <paramref name="weights"/>.</param>
              
        </member>
        <member name="M:Accord.MachineLearning.KMeans.converged(System.Double[][],System.Double[][])">
            <summary>
              Determines if the algorithm has converged by comparing the
              centroids between two consecutive iterations.
            </summary>
            
            <param name="centroids">The previous centroids.</param>
            <param name="newCentroids">The new centroids.</param>
            
            <returns>Returns <see langword="true"/> if all centroids had a percentage change
               less than <see param="threshold"/>. Returns <see langword="false"/> otherwise.</returns>
               
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][],System.Double@)">
            <summary>
              Divides the input data into K clusters. 
            </summary>  
            
            <param name="data">The data where to compute the algorithm.</param>
            <param name="error">
              The average square distance from the
              data points to the clusters' centroids.
            </param>
            
        </member>
        <member name="T:Accord.MachineLearning.QLearning">
            <summary>
            QLearning learning algorithm.
            </summary>
            
            <remarks>The class provides implementation of Q-Learning algorithm, known as
            off-policy Temporal Difference control.</remarks>
            
            <example>
            <para>
              The following example shows how to learn a model using reinforcement learning through the
              Q-learning algorithm. The following code has been inherited from the AForge.NET Framework,
              and has not been modified ever since. If you have better ideas on how to improve its 
              interface, please share it in the project's issue tracker at 
              <a href="https://github.com/accord-net/framework/issues">https://github.com/accord-net/framework/issues</a>.
              If you would like, and if your ideas are feasible and encouraging enough, you can be named an
              official contributor of the project. If you would like, you could opt to "inherit" the reinforcement learning 
              portion of the project such that you could be free to commit, modify and, more importantly, authorship
              those modules directly from your own GitHub account without having to wait for Pull Request approvals.
              You can be listed as an official author of the Accord.NET Framework, making it possible to list the
              creation or shared authorship of the reinforcement learning project in your CV.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\QLearningTest.cs" region="doc_main" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.Sarsa"/>
            
        </member>
        <member name="P:Accord.MachineLearning.QLearning.StatesCount">
            <summary>
            Amount of possible states.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.QLearning.ActionsCount">
            <summary>
            Amount of possible actions.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.QLearning.ExplorationPolicy">
            <summary>
            Exploration policy.
            </summary>
            
            <remarks>Policy, which is used to select actions.</remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.QLearning.LearningRate">
            <summary>
            Learning rate, [0, 1].
            </summary>
            
            <remarks>The value determines the amount of updates Q-function receives
            during learning. The greater the value, the more updates the function receives.
            The lower the value, the less updates it receives.</remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.QLearning.DiscountFactor">
            <summary>
            Discount factor, [0, 1].
            </summary>
            
            <remarks>Discount factor for the expected summary reward. The value serves as
            multiplier for the expected reward. So if the value is set to 1,
            then the expected summary reward is not discounted. If the value is getting
            smaller, then smaller amount of the expected reward is used for actions'
            estimates update.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.QLearning.#ctor(System.Int32,System.Int32,Accord.MachineLearning.IExplorationPolicy)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.QLearning"/> class.
            </summary>
            
            <param name="states">Amount of possible states.</param>
            <param name="actions">Amount of possible actions.</param>
            <param name="explorationPolicy">Exploration policy.</param>
            
            <remarks>Action estimates are randomized in the case of this constructor
            is used.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.QLearning.#ctor(System.Int32,System.Int32,Accord.MachineLearning.IExplorationPolicy,System.Boolean)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.QLearning"/> class.
            </summary>
            
            <param name="states">Amount of possible states.</param>
            <param name="actions">Amount of possible actions.</param>
            <param name="explorationPolicy">Exploration policy.</param>
            <param name="randomize">Randomize action estimates or not.</param>
            
            <remarks>The <b>randomize</b> parameter specifies if initial action estimates should be randomized
            with small values or not. Randomization of action values may be useful, when greedy exploration
            policies are used. In this case randomization ensures that actions of the same type are not chosen always.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.QLearning.GetAction(System.Int32)">
            <summary>
            Get next action from the specified state.
            </summary>
            
            <param name="state">Current state to get an action for.</param>
            
            <returns>Returns the action for the state.</returns>
            
            <remarks>The method returns an action according to current
            <see cref="P:Accord.MachineLearning.QLearning.ExplorationPolicy">exploration policy</see>.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.QLearning.UpdateState(System.Int32,System.Int32,System.Double,System.Int32)">
            <summary>
            Update Q-function's value for the previous state-action pair.
            </summary>
            
            <param name="previousState">Previous state.</param>
            <param name="action">Action, which leads from previous to the next state.</param>
            <param name="reward">Reward value, received by taking specified action from previous state.</param>
            <param name="nextState">Next state.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.RANSAC`1">
            <summary>
              Multipurpose RANSAC algorithm.
            </summary>
            
            <typeparam name="TModel">The model type to be trained by RANSAC.</typeparam>
            
            <remarks>
            <para>
              RANSAC is an abbreviation for "RANdom SAmple Consensus". It is an iterative
              method to estimate parameters of a mathematical model from a set of observed
              data which contains outliers. It is a non-deterministic algorithm in the sense
              that it produces a reasonable result only with a certain probability, with this
              probability increasing as more iterations are allowed.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                  P. D. Kovesi. MATLAB and Octave Functions for Computer Vision and Image Processing.
                  School of Computer Science and Software Engineering, The University of Western Australia.
                  Available in: http://www.csse.uwa.edu.au/~pk/research/matlabfns </description></item>
                <item><description>
                  Wikipedia, The Free Encyclopedia. RANSAC. Available on:
                  http://en.wikipedia.org/wiki/RANSAC </description></item>
              </list>
            </para>
            </remarks>
            
            <example>
            <code source="Unit Tests\Accord.Tests.MachineLearning\RansacTest.cs" region="doc_learn" />
            </example>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Fitting">
            <summary>
              Model fitting function.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Degenerate">
            <summary>
              Degenerative set detection function.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Distances">
            <summary>
              Distance function.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Threshold">
            <summary>
              Gets or sets the minimum distance between a data point and
              the model used to decide whether the point is an inlier or not.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Samples">
            <summary>
              Gets or sets the minimum number of samples from the data
              required by the fitting function to fit a model.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.MaxSamplings">
            <summary>
              Maximum number of attempts to select a 
              non-degenerate data set. Default is 100.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.MaxEvaluations">
            <summary>
              Maximum number of trials. Default is 1000.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.TrialsNeeded">
            <summary>
            Gets the current estimate of trials needed.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.TrialsPerformed">
            <summary>
            Gets the current number of trials performed.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Probability">
            <summary>
              Gets or sets the probability of obtaining a random
              sample of the input points that contains no outliers.
              Default is 0.99.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.#ctor(System.Int32)">
            <summary>
              Constructs a new RANSAC algorithm.
            </summary>
            
            <param name="minSamples">
              The minimum number of samples from the data
              required by the fitting function to fit a model.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.#ctor(System.Int32,System.Double)">
            <summary>
              Constructs a new RANSAC algorithm.
            </summary>
            
            <param name="minSamples">
              The minimum number of samples from the data
              required by the fitting function to fit a model.
            </param>
            <param name="threshold">
              The minimum distance between a data point and
              the model used to decide whether the point is
              an inlier or not.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.#ctor(System.Int32,System.Double,System.Double)">
            <summary>
              Constructs a new RANSAC algorithm.
            </summary>
            
            <param name="minSamples">
              The minimum number of samples from the data
              required by the fitting function to fit a model.
            </param>
            <param name="threshold">
              The minimum distance between a data point and
              the model used to decide whether the point is
              an inlier or not.
            </param>
            <param name="probability">
              The probability of obtaining a random sample of
              the input points that contains no outliers.
            </param>
            
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.Compute(System.Int32)">
            <summary>
              Computes the model using the RANSAC algorithm.
            </summary>
            
            <param name="size">The total number of points in the data set.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.Compute(System.Int32,System.Int32[]@)">
            <summary>
              Computes the model using the RANSAC algorithm.
            </summary>
            
            <param name="size">The total number of points in the data set.</param>
            <param name="inliers">The indexes of the outlier points in the data set.</param>
            
        </member>
        <member name="T:Accord.MachineLearning.Sarsa">
            <summary>
            Sarsa learning algorithm.
            </summary>
            
            <remarks>The class provides implementation of Sarsa algorithm, known as
            on-policy Temporal Difference control.</remarks>
            
            <example>
            <para>
              The following example shows how to learn a model using reinforcement learning through the
              Sarsa algorithm. The following code has been inherited from the AForge.NET Framework,
              and has not been modified ever since. If you have better ideas on how to improve its 
              interface, please share it in the project's issue tracker at 
              <a href="https://github.com/accord-net/framework/issues">https://github.com/accord-net/framework/issues</a>.
              If you would like, and if your ideas are feasible and encouraging enough, you can be named an
              official contributor of the project. If you would like, you could opt to "inherit" the reinforcement learning 
              portion of the project such that you could be free to commit, modify and, more importantly, authorship
              those modules directly from your own GitHub account without having to wait for Pull Request approvals.
              You can be listed as an official author of the Accord.NET Framework, making it possible to list the
              creation or shared authorship of the reinforcement learning project in your CV.</para>
            <code source="Unit Tests\Accord.Tests.MachineLearning\SarsaTest.cs" region="doc_main" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.QLearning"/>
            
        </member>
        <member name="P:Accord.MachineLearning.Sarsa.StatesCount">
            <summary>
            Amount of possible states.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Sarsa.ActionsCount">
            <summary>
            Amount of possible actions.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.Sarsa.ExplorationPolicy">
            <summary>
            Exploration policy.
            </summary>
            
            <remarks>Policy, which is used to select actions.</remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.Sarsa.LearningRate">
            <summary>
            Learning rate, [0, 1].
            </summary>
            
            <remarks>The value determines the amount of updates Q-function receives
            during learning. The greater the value, the more updates the function receives.
            The lower the value, the less updates it receives.</remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.Sarsa.DiscountFactor">
            <summary>
            Discount factor, [0, 1].
            </summary>
            
            <remarks>Discount factor for the expected summary reward. The value serves as
            multiplier for the expected reward. So if the value is set to 1,
            then the expected summary reward is not discounted. If the value is getting
            smaller, then smaller amount of the expected reward is used for actions'
            estimates update.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.Sarsa.#ctor(System.Int32,System.Int32,Accord.MachineLearning.IExplorationPolicy)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Sarsa"/> class.
            </summary>
            
            <param name="states">Amount of possible states.</param>
            <param name="actions">Amount of possible actions.</param>
            <param name="explorationPolicy">Exploration policy.</param>
            
            <remarks>Action estimates are randomized in the case of this constructor
            is used.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.Sarsa.#ctor(System.Int32,System.Int32,Accord.MachineLearning.IExplorationPolicy,System.Boolean)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.Sarsa"/> class.
            </summary>
            
            <param name="states">Amount of possible states.</param>
            <param name="actions">Amount of possible actions.</param>
            <param name="explorationPolicy">Exploration policy.</param>
            <param name="randomize">Randomize action estimates or not.</param>
            
            <remarks>The <b>randomize</b> parameter specifies if initial action estimates should be randomized
            with small values or not. Randomization of action values may be useful, when greedy exploration
            policies are used. In this case randomization ensures that actions of the same type are not chosen always.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.Sarsa.GetAction(System.Int32)">
            <summary>
            Get next action from the specified state.
            </summary>
            
            <param name="state">Current state to get an action for.</param>
            
            <returns>Returns the action for the state.</returns>
            
            <remarks>The method returns an action according to current
            <see cref="P:Accord.MachineLearning.Sarsa.ExplorationPolicy">exploration policy</see>.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.Sarsa.UpdateState(System.Int32,System.Int32,System.Double,System.Int32,System.Int32)">
            <summary>
            Update Q-function's value for the previous state-action pair.
            </summary>
            
            <param name="previousState">Curren state.</param>
            <param name="previousAction">Action, which lead from previous to the next state.</param>
            <param name="reward">Reward value, received by taking specified action from previous state.</param>
            <param name="nextState">Next state.</param>
            <param name="nextAction">Next action.</param>
            
            <remarks>Updates Q-function's value for the previous state-action pair in
            the case if the next state is non terminal.</remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.Sarsa.UpdateState(System.Int32,System.Int32,System.Double)">
            <summary>
            Update Q-function's value for the previous state-action pair.
            </summary>
            
            <param name="previousState">Curren state.</param>
            <param name="previousAction">Action, which lead from previous to the next state.</param>
            <param name="reward">Reward value, received by taking specified action from previous state.</param>
            
            <remarks>Updates Q-function's value for the previous state-action pair in
            the case if the next state is terminal.</remarks>
            
        </member>
        <member name="T:Accord.MachineLearning.Tools">
            <summary>
              Set of machine learning tools.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Tools.Tokenize(System.String[])">
            <summary>
              Splits the given text into individual atomic words, 
              irrespective of punctuation and other marks.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Tools.Tokenize(System.String)">
            <summary>
              Splits the given text into individual atomic words, 
              irrespective of punctuation and other marks.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.Tools.GetNumberOfInputs``1(``0[])">
            <summary>
              Estimates the number of columns (dimensions) in a set of data.
            </summary>
            
            <typeparam name="TInput">The type of the t input.</typeparam>
            
            <param name="x">The input data.</param>
            
            <returns>The number of columns (data dimensions) in the data.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Tools.ToConfusionMatrix``2(Accord.MachineLearning.Performance.CrossValidationResult{``0,``1,System.Int32},``1[],System.Int32[])">
            <summary>
              Generates a <see cref="T:Accord.Statistics.Analysis.GeneralConfusionMatrix"/> from a set of cross-validation results.
            </summary>
            
            <typeparam name="TModel">The type of the model being evaluated.</typeparam>
            <typeparam name="TInput">The type of the inputs accepted by the model.</typeparam>
            
            <param name="cv">The cross-validation result.</param>
            <param name="inputs">The inputs fed to the cross-validation object.</param>
            <param name="outputs">The outputs fed to the cross-validation object.</param>
            
            <returns>A <see cref="T:Accord.Statistics.Analysis.GeneralConfusionMatrix"/> that captures the performance of the model across all validation folds.</returns>
            
        </member>
        <member name="M:Accord.MachineLearning.Tools.ToConfusionMatrix``2(Accord.MachineLearning.Performance.CrossValidationResult{``0,``1,System.Boolean},``1[],System.Boolean[])">
            <summary>
              Generates a <see cref="T:Accord.Statistics.Analysis.ConfusionMatrix"/> from a set of cross-validation results.
            </summary>
            
            <typeparam name="TModel">The type of the model being evaluated.</typeparam>
            <typeparam name="TInput">The type of the inputs accepted by the model.</typeparam>
            
            <param name="cv">The cross-validation result.</param>
            <param name="inputs">The inputs fed to the cross-validation object.</param>
            <param name="outputs">The outputs fed to the cross-validation object.</param>
            
            <returns>A <see cref="T:Accord.Statistics.Analysis.ConfusionMatrix"/> that captures the performance of the model across all validation folds.</returns>
            
        </member>
        <member name="T:Accord.Collections.VPTree`1">
            <summary>
              Vantage-Point Tree.
            </summary>
            
            <typeparam name="TPoint">The type for the position vector of each node.</typeparam>
            
        </member>
        <member name="M:Accord.Collections.VPTree`1.#ctor(Accord.Math.Distances.IDistance{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.VPTree`1"/> class.
            </summary>
            
            <param name="distance">The distance to use when comparing points.</param>
            
        </member>
        <member name="M:Accord.Collections.VPTree`1.FromData(`0[],Accord.Math.Distances.IDistance{`0},System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="T:Accord.Collections.VPTree`2">
            <summary>
              Vantage-Point Tree.
            </summary>
            
            <typeparam name="TPoint">The type for the position vector of each node.</typeparam>
            <typeparam name="TData">The type for the value stored at each node.</typeparam>
            
        </member>
        <member name="M:Accord.Collections.VPTree`2.#ctor(Accord.Math.Distances.IDistance{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.VPTree`2"/> class.
            </summary>
            
            <param name="distance">The distance to use when comparing points.</param>
            
        </member>
        <member name="M:Accord.Collections.VPTree`2.FromData(`0[],`1[],Accord.Math.Distances.IDistance{`0},System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="values">The corresponding values at each data point.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree`2"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree`2.buildFromPoints(`0[],`1[],System.Int32,System.Int32,System.Boolean)">
            <summary>
             Function that (recursively) fills the tree 
            </summary>
        </member>
        <member name="T:Accord.Collections.KDTreeBase`1">
            <summary>
              Base class for K-dimensional trees.
            </summary>
            
            <typeparam name="TNode">The class type for the nodes of the tree.</typeparam>
            
        </member>
        <member name="P:Accord.Collections.KDTreeBase`1.Dimensions">
             <summary>
               Gets the number of dimensions expected
               by the input points of this tree.
             </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeBase`1.Distance">
             <summary>
               Gets or set the distance function used to
               measure distances amongst points on this tree
             </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeBase`1.Count">
             <summary>
               Gets the number of elements contained in this
               tree. This is also the number of tree nodes.
             </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeBase`1.Leaves">
             <summary>
               Gets the number of leaves contained in this
               tree. This can be used to calibrate approximate
               nearest searchers.
             </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.#ctor(System.Int32)">
             <summary>
               Creates a new <see cref="T:Accord.Collections.KDTree`1"/>.
             </summary>
            
             <param name="dimensions">The number of dimensions in the tree.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.#ctor(System.Int32,`0)">
             <summary>
               Creates a new <see cref="T:Accord.Collections.KDTree`1"/>.
             </summary>
            
             <param name="dimension">The number of dimensions in the tree.</param>
             <param name="Root">The Root node, if already existent.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.#ctor(System.Int32,`0,System.Int32,System.Int32)">
             <summary>
               Creates a new <see cref="T:Accord.Collections.KDTree`1"/>.
             </summary>
            
             <param name="dimension">The number of dimensions in the tree.</param>
             <param name="Root">The Root node, if already existent.</param>
             <param name="count">The number of elements in the Root node.</param>
             <param name="leaves">The number of leaves linked through the Root node.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.Nearest(System.Double[],System.Double,System.Int32)">
             <summary>
               Retrieves the nearest points to a given point within a given radius.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="radius">The search radius.</param>
             <param name="maximum">The maximum number of neighbors to retrieve.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.Nearest(System.Double[],System.Double)">
             <summary>
               Retrieves the nearest points to a given point within a given radius.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="radius">The search radius.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.Nearest(System.Double[],System.Int32)">
             <summary>
               Retrieves a fixed number of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="neighbors">The number of neighbors to retrieve.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.Nearest(System.Double[])">
             <summary>
               Retrieves the nearest point to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.Nearest(System.Double[],System.Double@)">
             <summary>
               Retrieves the nearest point to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="distance">The distance from the <paramref name="position"/>
               to its nearest neighbor found in the tree.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.ApproximateNearest(System.Double[],System.Int32,System.Double)">
             <summary>
               Retrieves a fixed percentage of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="neighbors">The number of neighbors to retrieve.</param>
             <param name="percentage">The maximum percentage of leaf nodes that
             can be visited before the search finishes with an approximate answer.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.ApproximateNearest(System.Double[],System.Double,System.Double@)">
             <summary>
               Retrieves a percentage of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="percentage">The maximum percentage of leaf nodes that
             can be visited before the search finishes with an approximate answer.</param>
             <param name="distance">The distance between the query point and its nearest neighbor.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.ApproximateNearest(System.Double[],System.Double)">
             <summary>
               Retrieves a percentage of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="percentage">The maximum percentage of leaf nodes that
             can be visited before the search finishes with an approximate answer.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.ApproximateNearest(System.Double[],System.Int32,System.Int32)">
             <summary>
               Retrieves a fixed number of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="neighbors">The number of neighbors to retrieve.</param>
             <param name="maxLeaves">The maximum number of leaf nodes that can
             be visited before the search finishes with an approximate answer.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.ApproximateNearest(System.Double[],System.Int32)">
             <summary>
               Retrieves a fixed number of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="maxLeaves">The maximum number of leaf nodes that can
             be visited before the search finishes with an approximate answer.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.GetNodesInsideRegion(Accord.Math.Hyperrectangle)">
            <summary>
              Retrieves a list of all points inside a given region.
            </summary>
            
            <param name="region">The region.</param>
            
            <returns>A list of all nodes contained in the region.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.CreateRoot(System.Double[][],System.Boolean,System.Int32@)">
             <summary>
               Creates the Root node for a new <see cref="T:Accord.Collections.KDTree`1"/> given
               a set of data points and their respective stored values.
             </summary>
            
             <param name="points">The data points to be inserted in the tree.</param>
             <param name="leaves">Return the number of leaves in the Root subtree.</param>
             <param name="inPlace">Whether the given <paramref name="points"/> vector
               can be ordered in place. Passing true will change the original order of
               the vector. If set to false, all operations will be performed on an extra
               copy of the vector.</param>
            
             <returns>The Root node for a new <see cref="T:Accord.Collections.KDTree`1"/>
               contained the given <paramref name="points"/>.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.nearest(`0,System.Double[],System.Double,System.Collections.Generic.ICollection{Accord.Collections.NodeDistance{`0}})">
             <summary>
               Radius search.
             </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.nearest(`0,System.Double[],Accord.Collections.KDTreeNodeCollection{`0})">
             <summary>
               k-nearest neighbors search.
             </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.AddNode(System.Double[])">
             <summary>
               Inserts a value into the tree at the desired position.
             </summary>
            
             <param name="position">A double-vector with the same number of elements as dimensions in the tree.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.Clear">
             <summary>
               Removes all nodes from this tree.
             </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeBase`1.CopyTo(`0[],System.Int32)">
             <summary>
               Copies the entire tree to a compatible one-dimensional <see cref="T:System.Array"/>, starting
               at the specified <paramref name="arrayIndex">index</paramref> of the <paramref name="array">
               target array</paramref>.
             </summary>
            
             <param name="array">The one-dimensional <see cref="T:System.Array"/> that is the destination of the
                elements copied from tree. The <see cref="T:System.Array"/> must have zero-based indexing.</param>
             <param name="arrayIndex">The zero-based index in <paramref name="array"/> at which copying begins.</param>
            
        </member>
        <member name="T:Accord.Collections.KDTreeNodeList`1">
            <summary>
              List of k-dimensional tree nodes.
            </summary>
            
            <typeparam name="T">The type of the value being stored.</typeparam>
            
            <remarks>
              This class is used to store neighbor nodes when running one of the
              search algorithms for <see cref="T:Accord.Collections.KDTree`1">k-dimensional trees</see>.
            </remarks>
            
            <seealso cref="T:Accord.Collections.KDTree`1"/>
            <seealso cref="T:Accord.Collections.NodeDistance`1"/>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeList`1.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.KDTreeNodeList`1"/>
              class that is empty.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeList`1.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.KDTreeNodeList`1"/>
              class that is empty and has the specified capacity.
            </summary>
            
        </member>
        <member name="T:Accord.Collections.SPCell">
            <summary>
              Region of space in a Space-Partitioning Tree. Represents an axis-aligned 
              bounding box stored as a center with half-dimensions to represent the boundaries 
              of this quad tree.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPCell.Dimension">
            <summary>
              Gets the dimensions of the space delimited
              by this spatial cell.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPCell.Corner">
            <summary>
              Gets or sets the starting point of this spatial cell.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPCell.Width">
            <summary>
              Gets or sets the width of this spatial cell.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPCell.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.SPCell"/> class.
            </summary>
            
            <param name="dimension">The number of dimensions of the space.</param>
            
        </member>
        <member name="M:Accord.Collections.SPCell.#ctor(System.Double[],System.Double[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.SPCell"/> class.
            </summary>
            
            <param name="corner">The starting point of this spatial cell.</param>
            <param name="width">The widths of this spatial cell.</param>
            
        </member>
        <member name="M:Accord.Collections.SPCell.Contains(System.Double[])">
            <summary>
              Determines whether a point lies inside this cell.
            </summary>
            
            <param name="point">The point.</param>
            
            <returns>True if the point is contained inside this cell; otherwise, false.</returns>
            
        </member>
        <member name="T:Accord.Collections.SPTreeNode">
            <summary>
              Node for a <see cref="T:Accord.Collections.SPTree">Space-Partitioning Tree</see>.
            </summary>
            
            <seealso cref="T:Accord.Collections.SPTree"/>
            <seealso cref="T:Accord.Collections.VPTree"/>
            <seealso cref="T:Accord.Collections.KDTree"/>
            
        </member>
        <member name="M:Accord.Collections.SPTreeNode.#ctor(Accord.Collections.SPTree,Accord.Collections.SPTreeNode,System.Int32,System.Double[],System.Double[])">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.SPTreeNode"/> class.
            </summary>
            
            <param name="owner">The tree that this node belongs to.</param>
            <param name="parent">The parent node for this node. Can be null if this node is the root.</param>
            <param name="corner">The starting point of the spatial cell.</param>
            <param name="width">The widths of the spatial cell.</param>
            <param name="index">The index of this node in the children collection of its parent node.</param>
            
        </member>
        <member name="P:Accord.Collections.SPTreeNode.Position">
            <summary>
              Gets the position associated with this node.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPTreeNode.CenterOfMass">
            <summary>
              Gets the center of mass of this node.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPTreeNode.Value">
            <summary>
              Gets or sets the value associated with this node.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPTreeNode.Region">
            <summary>
              Gets or sets the space region delimited by this node.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPTreeNode.IsEmpty">
            <summary>
              Gets whether this node is empty and does
              not contain any points or children.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTreeNode.Add(System.Double[])">
            <summary>
              Inserts a point in the Space-Partitioning tree.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTreeNode.IsCorrect">
            <summary>
              Checks whether the current tree is correct.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTreeNode.GetDepth">
            <summary>
              Gets the current depth of this node (distance from the root).
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTreeNode.ComputeNonEdgeForces(System.Double[],System.Double,System.Double[],System.Double@)">
            <summary>
              Compute non-edge forces using Barnes-Hut algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTreeNode.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="T:Accord.Collections.NodeDistance`1">
            <summary>
              Node-distance pair.
            </summary>
            
            <typeparam name="TNode">The class type for the nodes of the tree.</typeparam>
            
        </member>
        <member name="P:Accord.Collections.NodeDistance`1.Node">
            <summary>
              Gets the node in this pair.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.NodeDistance`1.Distance">
            <summary>
              Gets the distance of the node from the query point.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.#ctor(`0,System.Double)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.NodeDistance`1"/>.
            </summary>
            
            <param name="node">The node value.</param>
            <param name="distance">The distance value.</param>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.Equals(System.Object)">
            <summary>
              Determines whether the specified <see cref="T:System.Object"/>
              is equal to this instance.
            </summary>
            
            <param name="obj">The <see cref="T:System.Object"/> to compare
              with this instance.</param>
            
            <returns>
              <c>true</c> if the specified <see cref="T:System.Object"/> is 
              equal to this instance; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.GetHashCode">
            <summary>
              Returns a hash code for this instance.
            </summary>
            
            <returns>
              A hash code for this instance, suitable for use in hashing
              algorithms and data structures like a hash table. 
            </returns>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.op_Equality(Accord.Collections.NodeDistance{`0},Accord.Collections.NodeDistance{`0})">
            <summary>
              Implements the equality operator.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.op_Inequality(Accord.Collections.NodeDistance{`0},Accord.Collections.NodeDistance{`0})">
            <summary>
              Implements the inequality operator.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.op_LessThan(Accord.Collections.NodeDistance{`0},Accord.Collections.NodeDistance{`0})">
            <summary>
              Implements the lesser than operator.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.op_GreaterThan(Accord.Collections.NodeDistance{`0},Accord.Collections.NodeDistance{`0})">
            <summary>
              Implements the greater than operator.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.Equals(Accord.Collections.NodeDistance{`0})">
            <summary>
              Determines whether the specified <see cref="T:Accord.Collections.NodeDistance`1"/>
              is equal to this instance.
            </summary>
            
            <param name="other">The <see cref="T:Accord.Collections.NodeDistance`1"/> to compare
              with this instance.</param>
            
            <returns>
              <c>true</c> if the specified <see cref="T:Accord.Collections.NodeDistance`1"/> is 
              equal to this instance; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.CompareTo(Accord.Collections.NodeDistance{`0})">
            <summary>
              Compares this instance to another node, returning an integer
              indicating whether this instance has a distance that is less
              than, equal to, or greater than the other node's distance.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.CompareTo(System.Object)">
            <summary>
              Compares this instance to another node, returning an integer
              indicating whether this instance has a distance that is less
              than, equal to, or greater than the other node's distance.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.NodeDistance`1.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="T:Accord.Collections.KDTree`1">
            <summary>
              K-dimensional tree.
            </summary>
            
            <typeparam name="T">The type of the value being stored.</typeparam>
            
            <remarks>
            <para>
              A k-d tree (short for k-dimensional tree) is a space-partitioning data structure 
              for organizing points in a k-dimensional space. k-d trees are a useful data structure
              for several applications, such as searches involving a multidimensional search key 
              (e.g. range searches and nearest neighbor searches). k-d trees are a special case 
              of binary space partitioning trees.</para>
              
            <para>
              The k-d tree is a binary tree in which every node is a k-dimensional point. Every non-
              leaf node can be thought of as implicitly generating a splitting hyperplane that divides
              the space into two parts, known as half-spaces. Points to the left of this hyperplane 
              represent the left subtree of that node and points right of the hyperplane are represented
              by the right subtree. The hyperplane direction is chosen in the following way: every node 
              in the tree is associated with one of the k-dimensions, with the hyperplane perpendicular 
              to that dimension's axis. So, for example, if for a particular split the "x" axis is chosen,
              all points in the subtree with a smaller "x" value than the node will appear in the left 
              subtree and all points with larger "x" value will be in the right subtree. In such a case, 
              the hyperplane would be set by the x-value of the point, and its normal would be the unit 
              x-axis.</para>
            
            <para>
              References:
              <list type="bullet">
                <item><description>
                  Wikipedia, The Free Encyclopedia. K-d tree. Available on:
                  http://en.wikipedia.org/wiki/K-d_tree </description></item>
                <item><description>
                  Moore, Andrew W. "An intoductory tutorial on kd-trees." (1991).
                  Available at: http://www.autonlab.org/autonweb/14665/version/2/part/5/data/moore-tutorial.pdf </description></item>
              </list></para>
            </remarks>
            
            <example>
            <code lang="cs">
            // This is the same example found in Wikipedia page on
            // k-d trees: http://en.wikipedia.org/wiki/K-d_tree
            
            // Suppose we have the following set of points:
            
            double[][] points =
            {
                new double[] { 2, 3 },
                new double[] { 5, 4 },
                new double[] { 9, 6 },
                new double[] { 4, 7 },
                new double[] { 8, 1 },
                new double[] { 7, 2 },
            };
            
            
            // To create a tree from a set of points, we use
            KDTree&lt;int> tree = KDTree.FromData&lt;int>(points);
            
            // Now we can manually navigate the tree
            KDTreeNode&lt;int> node = tree.Root.Left.Right;
            
            // Or traverse it automatically
            foreach (KDTreeNode&lt;int> n in tree)
            {
                double[] location = n.Position;
                Assert.AreEqual(2, location.Length);
            }
            
            // Given a query point, we can also query for other
            // points which are near this point within a radius
            
            double[] query = new double[] { 5, 3 };
            
            // Locate all nearby points within an euclidean distance of 1.5
            // (answer should be be a single point located at position (5,4))
            KDTreeNodeCollection&lt;int> result = tree.Nearest(query, radius: 1.5); 
                        
            // We can also use alternate distance functions
            tree.Distance = Accord.Math.Distance.Manhattan;
            
            // And also query for a fixed number of neighbor points
            // (answer should be the points at (5,4), (7,2), (2,3))
            KDTreeNodeCollection&lt;int> neighbors = tree.Nearest(query, neighbors: 3);
            </code>
            <code lang="vb">
            ' This is the same example found in Wikipedia page on
            ' k-d trees: http://en.wikipedia.org/wiki/K-d_tree
            
            ' Suppose we have the following set of points:
            
            Dim points =
            {
                New Double() { 2, 3 },
                New Double() { 5, 4 },
                New Double() { 9, 6 },
                New Double() { 4, 7 },
                New Double() { 8, 1 },
                New Double() { 7, 2 }
            }
            
            ' To create a tree from a set of points, we use
            Dim tree = KDTree.FromData(Of Integer)(points)
            
            ' Now we can manually navigate the tree
            Dim node = tree.Root.Left.Right
            
            ' Or traverse it automatically
            For Each n As KDTreeNode(Of Integer) In tree
                Dim location = n.Position
                Console.WriteLine(location.Length)
            Next
            
            ' Given a query point, we can also query for other
            ' points which are near this point within a radius
            '
            Dim query = New Double() {5, 3}
            
            ' Locate all nearby points within an Euclidean distance of 1.5
            ' (answer should be a single point located at position (5,4))
            '
            Dim result = tree.Nearest(query, radius:=1.5)
            
            ' We can also use alternate distance functions
            tree.Distance = Function(a, b) Accord.Math.Distance.Manhattan(a, b)
            
            ' And also query for a fixed number of neighbor points
            ' (answer should be the points at (5,4), (7,2), (2,3))
            '
            Dim neighbors = tree.Nearest(query, neighbors:=3)
            </code>
            </example>
            
            <seealso cref="T:Accord.MachineLearning.KNearestNeighbors"/>
            
        </member>
        <member name="M:Accord.Collections.KDTree`1.#ctor(System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTree`1"/>.
            </summary>
            
            <param name="dimensions">The number of dimensions in the tree.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree`1.#ctor(System.Int32,Accord.Collections.KDTreeNode{`0})">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTree`1"/>.
            </summary>
            
            <param name="dimension">The number of dimensions in the tree.</param>
            <param name="Root">The Root node, if already existent.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree`1.#ctor(System.Int32,Accord.Collections.KDTreeNode{`0},System.Int32,System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTree`1"/>.
            </summary>
            
            <param name="dimension">The number of dimensions in the tree.</param>
            <param name="Root">The Root node, if already existent.</param>
            <param name="count">The number of elements in the Root node.</param>
            <param name="leaves">The number of leaves linked through the Root node.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree`1.Add(System.Double[],`0)">
            <summary>
              Inserts a value in the tree at the desired position.
            </summary>
            
            <param name="position">A double-vector with the same number of elements as dimensions in the tree.</param>
            <param name="value">The value to be inserted.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree`1.CreateRoot(System.Double[][],`0[],System.Boolean,System.Int32@)">
            <summary>
              Creates the Root node for a new <see cref="T:Accord.Collections.KDTree`1"/> given
              a set of data points and their respective stored values.
            </summary>
            
            <param name="points">The data points to be inserted in the tree.</param>
            <param name="values">The values associated with each point.</param>
            <param name="leaves">Return the number of leaves in the Root subtree.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>The Root node for a new <see cref="T:Accord.Collections.KDTree`1"/>
              contained the given <paramref name="points"/>.</returns>
            
        </member>
        <member name="T:Accord.Collections.KDTree">
            <summary>
              Convenience class for k-dimensional tree static methods. To 
              create a new KDTree, specify the generic parameter as in
              <see cref="T:Accord.Collections.KDTree`1"/>.
            </summary>
            
            <remarks>
              Please check the documentation page for <see cref="T:Accord.Collections.KDTree`1"/>
              for examples, usage and actual remarks about kd-trees.
            </remarks>
            
            <seealso cref="T:Accord.Collections.KDTree`1"/>
            <seealso cref="T:Accord.Collections.SPTree"/>
            <seealso cref="T:Accord.Collections.VPTree"/>
            
        </member>
        <member name="M:Accord.Collections.KDTree.#ctor(System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTree"/>.
            </summary>
            
            <param name="dimensions">The number of dimensions in the tree.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree.#ctor(System.Int32,Accord.Collections.KDTreeNode)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTree"/>.
            </summary>
            
            <param name="dimension">The number of dimensions in the tree.</param>
            <param name="root">The root node, if already existent.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree.#ctor(System.Int32,Accord.Collections.KDTreeNode,System.Int32,System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTree"/>.
            </summary>
            
            <param name="dimension">The number of dimensions in the tree.</param>
            <param name="root">The root node, if already existent.</param>
            <param name="count">The number of elements in the root node.</param>
            <param name="leaves">The number of leaves linked through the root node.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree.Add(System.Double[])">
            <summary>
              Adds a new point to this tree.
            </summary>
            
            <param name="position">A double-vector with the same number of elements as dimensions in the tree.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTree.FromData``1(System.Double[][],System.Boolean)">
            <summary>
              Creates a new k-dimensional tree from the given points.
            </summary>
            
            <typeparam name="T">The type of the value to be stored.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>A <see cref="T:Accord.Collections.KDTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTree.FromData(System.Double[][],System.Boolean)">
            <summary>
              Creates a new k-dimensional tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>A <see cref="T:Accord.Collections.KDTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTree.FromData``1(System.Double[][],``0[],System.Boolean)">
            <summary>
              Creates a new k-dimensional tree from the given points.
            </summary>
            
            <typeparam name="T">The type of the value to be stored.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="values">The corresponding values at each data point.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>A <see cref="T:Accord.Collections.KDTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTree.FromData(System.Double[][],Accord.Math.Distances.IMetric{System.Double[]},System.Boolean)">
            <summary>
              Creates a new k-dimensional tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>A <see cref="T:Accord.Collections.KDTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTree.FromData``1(System.Double[][],``0[],Accord.Math.Distances.IMetric{System.Double[]},System.Boolean)">
            <summary>
              Creates a new k-dimensional tree from the given points.
            </summary>
            
            <typeparam name="T">The type of the value to be stored.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="values">The corresponding values at each data point.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>A <see cref="T:Accord.Collections.KDTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTree.FromData``1(System.Double[][],Accord.Math.Distances.IMetric{System.Double[]},System.Boolean)">
            <summary>
              Creates a new k-dimensional tree from the given points.
            </summary>
            
            <typeparam name="T">The type of the value to be stored.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether the given <paramref name="points"/> vector
              can be ordered in place. Passing true will change the original order of
              the vector. If set to false, all operations will be performed on an extra
              copy of the vector.</param>
            
            <returns>A <see cref="T:Accord.Collections.KDTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="T:Accord.Collections.KDTreeNode">
            <summary>
              K-dimensional tree node (for <see cref="T:Accord.Collections.KDTree"/>).
            </summary>
            
            <seealso cref="T:Accord.Collections.SPTreeNode"/>
            <seealso cref="T:Accord.Collections.VPTreeNode`1"/>
            
        </member>
        <member name="T:Accord.Collections.KDTreeNode`1">
            <summary>
              K-dimensional tree node (for <see cref="T:Accord.Collections.KDTree`1"/>).
            </summary>
            
            <seealso cref="T:Accord.Collections.SPTreeNode"/>
            <seealso cref="T:Accord.Collections.VPTreeNode`1"/>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNode`1.Value">
            <summary>
              Gets or sets the value being stored at this node.
            </summary>
            
        </member>
        <member name="T:Accord.Collections.KDTreeNodeBase`1">
            <summary>
              Base class for K-dimensional tree nodes.
            </summary>
            
            <typeparam name="TNode">The class type for the nodes of the tree.</typeparam>
            
            <seealso cref="T:Accord.Collections.KDTreeNode"/>
            <seealso cref="T:Accord.Collections.KDTreeNode`1"/>
            <seealso cref="T:Accord.Collections.BinaryNode`1"/>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeBase`1.Position">
            <summary>
              Gets or sets the position of 
              the node in spatial coordinates.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeBase`1.Axis">
            <summary>
              Gets or sets the dimension index of the split. This value is a
              index of the <see cref="P:Accord.Collections.KDTreeNodeBase`1.Position"/> vector and as such should
              be higher than zero and less than the number of elements in <see cref="P:Accord.Collections.KDTreeNodeBase`1.Position"/>.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeBase`1.ToString">
            <summary>
              Returns a <see cref="T:System.String"/> that represents this instance.
            </summary>
            
            <returns>
              A <see cref="T:System.String"/> that represents this instance.
            </returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeBase`1.CompareTo(`0)">
            <summary>
            Compares the current object with another object of the same type.
            </summary>
            <param name="other">An object to compare with this object.</param>
            <returns>
            A value that indicates the relative order of the objects being compared. The return value has the following meanings: Value Meaning Less than zero This object is less than the <paramref name="other" /> parameter.Zero This object is equal to <paramref name="other" />. Greater than zero This object is greater than <paramref name="other" />.
            </returns>
        </member>
        <member name="M:Accord.Collections.KDTreeNodeBase`1.Equals(`0)">
            <summary>
            Indicates whether the current object is equal to another object of the same type.
            </summary>
            <param name="other">An object to compare with this object.</param>
            <returns>
            true if the current object is equal to the <paramref name="other" /> parameter; otherwise, false.
            </returns>
        </member>
        <member name="T:Accord.Collections.KDTreeNodeCollection`1">
            <summary>
              Collection of k-dimensional tree nodes.
            </summary>
            
            <typeparam name="TNode">The class type for the nodes of the tree.</typeparam>
            
            <remarks>
              This class is used to store neighbor nodes when running one of the
              search algorithms for <see cref="T:Accord.Collections.KDTree`1">k-dimensional trees</see>.
            </remarks>
            
            <seealso cref="T:Accord.Collections.KDTree`1"/>
            <seealso cref="T:Accord.Collections.NodeDistance`1"/>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Capacity">
            <summary>
              Gets or sets the maximum number of elements on this 
              collection, if specified. A value of zero indicates
              this instance has no upper limit of elements.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Minimum">
            <summary>
              Gets the minimum distance between a node
              in this collection and the query point.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Maximum">
            <summary>
              Gets the maximum distance between a node
              in this collection and the query point.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Farthest">
            <summary>
              Gets the farthest node in the collection (with greatest distance).
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Nearest">
            <summary>
              Gets the nearest node in the collection (with smallest distance).
            </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.#ctor(System.Int32)">
            <summary>
              Creates a new <see cref="T:Accord.Collections.KDTreeNodeCollection`1"/> with a maximum size.
            </summary>
            
            <param name="size">The maximum number of elements allowed in this collection.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.Add(`0,System.Double)">
            <summary>
              Attempts to add a value to the collection. If the list is full
              and the value is more distant than the farthest node in the
              collection, the value will not be added.
            </summary>
            
            <param name="value">The node to be added.</param>
            <param name="distance">The node distance.</param>
            
            <returns>Returns true if the node has been added; false otherwise.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.AddFarthest(`0,System.Double)">
            <summary>
              Attempts to add a value to the collection. If the list is full
              and the value is more distant than the farthest node in the
              collection, the value will not be added.
            </summary>
            
            <param name="value">The node to be added.</param>
            <param name="distance">The node distance.</param>
            
            <returns>Returns true if the node has been added; false otherwise.</returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.add(System.Double,`0)">
            <summary>
              Adds the specified item to the collection.
            </summary>
            
            <param name="distance">The distance from the node to the query point.</param>
            <param name="item">The item to be added.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.Clear">
            <summary>
              Removes all elements from this collection.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Item(System.Int32)">
            <summary>
              Gets the <see cref="T:Accord.Collections.NodeDistance`1"/>
              at the specified index. Note: this method will iterate over the entire collection
              until the given position is found.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.Count">
            <summary>
              Gets the number of elements in this collection.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.KDTreeNodeCollection`1.IsReadOnly">
            <summary>
              Gets a value indicating whether this instance is read only.
              For this collection, always returns false.
            </summary>
            
            <value>
            	<c>true</c> if this instance is read only; otherwise, <c>false</c>.
            </value>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.GetEnumerator">
            <summary>
              Returns an enumerator that iterates through this collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object 
              that can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>
              Returns an enumerator that iterates through this collection.
            </summary>
            
            <returns>
              An <see cref="T:System.Collections.IEnumerator"/> object that
              can be used to iterate through the collection.
            </returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.Contains(Accord.Collections.NodeDistance{`0})">
            <summary>
              Determines whether this instance contains the specified item.
            </summary>
            
            <param name="item">The object to locate in the collection. 
              The value can be null for reference types.</param>
            
            <returns>
              <c>true</c> if the item is found in the collection; otherwise, <c>false</c>.
            </returns>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.CopyTo(Accord.Collections.NodeDistance{`0}[],System.Int32)">
            <summary>
              Copies the entire collection to a compatible one-dimensional <see cref="T:System.Array"/>, starting
              at the specified <paramref name="arrayIndex">index</paramref> of the <paramref name="array">target
              array</paramref>.
            </summary>
            
            <param name="array">The one-dimensional <see cref="T:System.Array"/> that is the destination of the
               elements copied from tree. The <see cref="T:System.Array"/> must have zero-based indexing.</param>
            <param name="arrayIndex">The zero-based index in <paramref name="array"/> at which copying begins.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.Add(Accord.Collections.NodeDistance{`0})">
            <summary>
              Adds the specified item to this collection.
            </summary>
            
            <param name="item">The item.</param>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.Remove(Accord.Collections.NodeDistance{`0})">
            <summary>
              Not supported.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.RemoveFarthest">
            <summary>
              Removes the farthest tree node from this collection.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.KDTreeNodeCollection`1.RemoveNearest">
            <summary>
              Removes the nearest tree node from this collection.
            </summary>
            
        </member>
        <member name="T:Accord.Collections.SPTree">
            <summary>
              Space-Partitioning Tree.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.SPTree.Dimension">
            <summary>
              Gets the dimension of the space covered by this tree.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTree.#ctor(System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.Collections.SPTree"/> class.
            </summary>
            
            <param name="dimensions">The dimensions of the space partitioned by the tree.</param>
            
        </member>
        <member name="M:Accord.Collections.SPTree.FromData(System.Double[][])">
            <summary>
              Creates a new space-partitioning tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            
            <returns>A <see cref="T:Accord.Collections.SPTree"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.SPTree.Add(System.Double[])">
            <summary>
              Inserts a point in the Space-Partitioning tree.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTree.ComputeNonEdgeForces(System.Double[],System.Double,System.Double[],System.Double@)">
            <summary>
             Computes non-edge forces using Barnes-Hut algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.SPTree.ComputeEdgeForces(System.Double[][],System.Int32[],System.Int32[],System.Double[],System.Double[][])">
            <summary>
              Computes edge forces.
            </summary>
            
        </member>
        <member name="T:Accord.Collections.VPTree">
            <summary>
              Vantage-Point Tree.
            </summary>
            
            <seealso cref="T:Accord.Collections.SPTree"/>
            <seealso cref="T:Accord.Collections.VPTree"/>
            <seealso cref="T:Accord.Collections.KDTree"/>
            
        </member>
        <member name="M:Accord.Collections.VPTree.FromData(System.Double[][],System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree.FromData(System.Double[],System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree.FromData(System.Double[][],Accord.Math.Distances.IDistance,System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree.FromData``1(``0[],Accord.Math.Distances.IDistance{``0},System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <typeparam name="TPoint">The type for the position vectors.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree`1"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree.FromData``1(System.Double[][],``0[],System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <typeparam name="TData">The type of the value to be stored.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="values">The corresponding values at each data point.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree`2"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree.FromData``2(``0[],``1[],Accord.Math.Distances.IDistance{``0},System.Boolean)">
            <summary>
              Creates a new vantage-point tree from the given points.
            </summary>
            
            <typeparam name="TPoint">The type for the position vectors.</typeparam>
            <typeparam name="TData">The type of the value to be stored.</typeparam>
            
            <param name="points">The points to be added to the tree.</param>
            <param name="values">The corresponding values at each data point.</param>
            <param name="distance">The distance function to use.</param>
            <param name="inPlace">Whether to perform operations in place, altering the
              original array of points instead of creating an extra copy.</param>
            
            <returns>A <see cref="T:Accord.Collections.VPTree`2"/> populated with the given data points.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTree.#ctor(Accord.Math.Distances.IDistance)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.VPTree"/> class.
            </summary>
            
            <param name="distance">The distance to use when comparing points. Default is 
              <see cref="M:Accord.Math.Distance.Euclidean(System.Double[],System.Double[])"/>.</param>
            
        </member>
        <member name="M:Accord.Collections.VPTree.#ctor">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.VPTree"/> class.
            </summary>
            
        </member>
        <member name="T:Accord.Collections.VPTreeBase`2">
            <summary>
              Base class for <see cref="T:Accord.Collections.VPTree">Vantage-Point Trees</see>.
            </summary>
            
            <typeparam name="TPoint">The type for the position vector of each node.</typeparam>
            <typeparam name="TNode">The class type for the nodes of the tree.</typeparam>
            
            <seealso cref="T:Accord.Collections.VPTree"/>
            <seealso cref="T:Accord.Collections.VPTree`2"/>
            <seealso cref="T:Accord.Collections.VPTree`1"/>
            
        </member>
        <member name="P:Accord.Collections.VPTreeBase`2.Distance">
             <summary>
               Gets or set the distance function used to
               measure distances amongst points on this tree
             </summary>
            
        </member>
        <member name="P:Accord.Collections.VPTreeBase`2.Radius">
            <summary>
              Gets or sets the radius of the nodes in the tree.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.VPTreeBase`2.#ctor(Accord.Math.Distances.IDistance{`0})">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.Collections.VPTreeBase`2"/> class.
            </summary>
            
            <param name="distance">The distance to use when comparing points.</param>
            
        </member>
        <member name="M:Accord.Collections.VPTreeBase`2.Nearest(`0,System.Int32)">
             <summary>
               Retrieves a fixed point of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="neighbors">The number of neighbors to retrieve.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="M:Accord.Collections.VPTreeBase`2.Nearest(`0,System.Int32,System.Collections.Generic.List{Accord.Collections.NodeDistance{`1}})">
             <summary>
               Retrieves a fixed point of nearest points to a given point.
             </summary>
            
             <param name="position">The queried point.</param>
             <param name="neighbors">The number of neighbors to retrieve.</param>
             <param name="results">The list where to store results.</param>
            
             <returns>A list of neighbor points, ordered by distance.</returns>
            
        </member>
        <member name="T:Accord.Collections.VPTreeNode`2">
            <summary>
              Node of a <see cref="T:Accord.Collections.VPTree"/>.
            </summary>
            
            <typeparam name="TPoint">The type for the position vector (e.g. double[]).</typeparam>
            <typeparam name="TData">The type for the value stored at the node.</typeparam>
            
        </member>
        <member name="P:Accord.Collections.VPTreeNode`2.Value">
            <summary>
              Gets or sets a value associated with this node.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.VPTreeNode`2.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="T:Accord.Collections.VPTreeNodeBase`2">
            <summary>
              Base class for <see cref="T:Accord.Collections.VPTree"/> nodes.
            </summary>
            
            <typeparam name="TPoint">The type for the position vector (e.g. double[]).</typeparam>
            <typeparam name="TNode">The class type for the nodes of the tree.</typeparam>
            
        </member>
        <member name="P:Accord.Collections.VPTreeNodeBase`2.Position">
            <summary>
              Gets or sets the current position for this Vantage-Point Tree Node.
            </summary>
            
        </member>
        <member name="P:Accord.Collections.VPTreeNodeBase`2.Threshold">
            <summary>
              Gets or sets the threshold radius for this node.
            </summary>
            
        </member>
        <member name="M:Accord.Collections.VPTreeNodeBase`2.Equals(`1)">
            <summary>
            Indicates whether the current object is equal to another object of the same type.
            </summary>
            <param name="other">An object to compare with this object.</param>
            <returns>
            true if the current object is equal to the <paramref name="other" /> parameter; otherwise, false.
            </returns>
        </member>
        <member name="M:Accord.Collections.VPTreeNodeBase`2.ToString">
            <summary>
            Returns a <see cref="T:System.String" /> that represents this instance.
            </summary>
            <returns>
            A <see cref="T:System.String" /> that represents this instance.
            </returns>
        </member>
        <member name="T:Accord.Collections.VPTreeNode`1">
            <summary>
              Node of a <see cref="T:Accord.Collections.VPTree"/>.
            </summary>
            
            <typeparam name="TPoint">The type for the position vector (e.g. double[]).</typeparam>
            
        </member>
        <member name="T:Accord.IO.LibSvmSolverType">
            <summary>
              Solver types allowed in LibSVM/Liblinear model files.
            </summary>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.Unknown">
            <summary>
              Unknown solver type.
            </summary>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedLogisticRegression">
            <summary>
              L2-regularized logistic regression in the primal (-s 0, L2R_LR).
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedL2LossSvcDual">
            <summary>
              L2-regularized L2-loss support vector classification
              in the dual (-s 1, L2R_L2LOSS_SVC_DUAL, the default).
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedL2LossSvc">
            <summary>
              L2-regularized L2-loss support vector classification
              in the primal (-s 2, L2R_L2LOSS_SVC).
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticNewtonMethod"/>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedL1LossSvcDual">
            <summary>
              L2-regularized L1-loss support vector classification
              in the dual (-s 3, L2R_L1LOSS_SVC_DUAL).
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.LinearDualCoordinateDescent"/>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.MulticlassSvmCrammerSinger">
            <summary>
              Support vector classification by 
              Crammer and Singer (-s 4, MCSVM_CS).
            </summary>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L1RegularizedL2LossSvc">
            <summary>
              L1-regularized L2-loss support vector 
              classification (-s 5, L1R_L2LOSS_SVC).
            </summary>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L1RegularizedLogisticRegression">
            <summary>
              L1-regularized logistic regression (-s 6, L1R_LR).
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticCoordinateDescent"/>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedLogisticRegressionDual">
            <summary>
              L2-regularized logistic regression in the dual (-s 7, L2R_LR_DUAL).
            </summary>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.ProbabilisticDualCoordinateDescent"/>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedL2LossSvr">
            <summary>
              L2-regularized L2-loss support vector regression 
              in the primal (-s 11, L2R_L2LOSS_SVR).
            </summary>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedL2LossSvrDual">
            <summary>
              L2-regularized L2-loss support vector regression 
              in the dual (-s 12, L2R_L2LOSS_SVR_DUAL).
            </summary>
            
        </member>
        <member name="F:Accord.IO.LibSvmSolverType.L2RegularizedL1LossSvrDual">
            <summary>
              L2-regularized L1-loss support vector regression 
              in the dual (-s 13, L2R_L1LOSS_SVR_DUAL).
            </summary>
            
        </member>
        <member name="T:Accord.IO.LibSvmModel">
            <summary>
              Reads <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">support vector machines</see>
              created from LibSVM or Liblinear. Not all solver types are supported.
            </summary>
            
            <remarks>
            <para>
              This class can be used to import LibSVM or LibLINEAR models into .NET
              and use them to make predictions in .NET/C# applications.</para>
              
            <para>
              If you are looking for ways to load and save SVM models in the Accord.NET
              Framework without necessarily being compatible with LibSVM or LIBLINEAR,
              please use the <see cref="T:Accord.IO.Serializer"/> class instead.</para>
            </remarks>
            
            <example>
            <code source="Unit Tests\Accord.Tests.MachineLearning\IO\LibSvmModelTest.cs" region="doc_read" />
            </example>
            
            <seealso cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/>
            <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization"/>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Solver">
            <summary>
              Gets or sets the solver type used to create the model.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.NumberOfClasses">
            <summary>
              Gets or sets the number of classes that
              this classification model can handle.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Classes">
            <summary>
              Obsolete. Please use NumberOfClasses instead.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Bias">
            <summary>
              Gets or sets whether an initial double value should
              be appended in the beginning of every feature vector.
              If set to a negative number, this functionality is
              disabled. Default is 0.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.NumberOfInputs">
            <summary>
              Gets or sets the number of dimensions (features) 
              the classification or regression model can handle.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Dimension">
            <summary>
              Obsolete. Please use NumberOfInputs instead.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Labels">
            <summary>
              Gets or sets the class label for each class
              this classification model expects to handle.
            </summary>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Weights">
            <summary>
              Gets or sets the vector of linear weights used
              by this model, if it is a compact model. If this
              is not a compact model, this will be set to <c>null</c>.
            </summary>
            
            <seealso cref="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.IsCompact"/>
            
        </member>
        <member name="P:Accord.IO.LibSvmModel.Vectors">
            <summary>
              Gets or sets the set of support vectors used
              by this model. If the model is compact, this
              will be set to <c>null</c>.
            </summary>
            
            <seealso cref="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine`2.IsCompact"/>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.#ctor">
            <summary>
              Creates a new <see cref="T:Accord.IO.LibSvmModel"/> object.
            </summary>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.CreateMachine">
            <summary>
              Creates a <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> that
              attends the requisites specified in this model.
            </summary>
            
            <returns>A <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine"/> that represents this model.</returns>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.CreateAlgorithm">
            <summary>
              Creates a <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ILinearSupportVectorMachineLearning"> support
              vector machine learning algorithm</see> that attends the 
              requisites specified in this model.
            </summary>
            
            <returns>
              A <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ILinearSupportVectorMachineLearning"/> that represents this model.
            </returns>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.Save(System.String)">
            <summary>
              Saves this model to disk using LibSVM's model format.
            </summary>
            
            <param name="path">The path where the file should be written.</param>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.Save(System.IO.Stream)">
            <summary>
              Saves this model to disk using LibSVM's model format.
            </summary>
            
            <param name="stream">The stream where the file should be written.</param>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.Load(System.String)">
            <summary>
              Loads a model specified using LibSVM's model format from disk.
            </summary>
            
            <param name="path">The file path from where the model should be loaded.</param>
            
            <returns>The <see cref="T:Accord.IO.LibSvmModel"/> stored on <paramref name="path"/>.</returns>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.Load(System.IO.Stream)">
            <summary>
              Loads a model specified using LibSVM's model format from a stream.
            </summary>
            
            <param name="stream">The stream from where the model should be loaded.</param>
            
            <returns>The <see cref="T:Accord.IO.LibSvmModel"/> stored on <paramref name="stream"/>.</returns>
            
        </member>
        <member name="M:Accord.IO.LibSvmModel.FromMachine(Accord.MachineLearning.VectorMachines.SupportVectorMachine{Accord.Statistics.Kernels.Linear})">
            <summary>
              Creates a <see cref="T:Accord.IO.LibSvmModel"/> from an existing <see cref="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine`1"/>.
            </summary>
            
            <param name="svm">The vector machine from which a libSVM model definition should be created.</param>
            
            <returns>
              A <see cref="T:Accord.IO.LibSvmModel"/> class representing a support vector machine in LibSVM format.
            </returns>
            
        </member>
    </members>
</doc>
